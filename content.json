{"meta":{"title":"zen's blog","subtitle":null,"description":null,"author":"ZEN","url":"http://ymlog.cn","root":"/"},"pages":[{"title":"tags","date":"2020-06-16T07:31:52.000Z","updated":"2020-06-16T07:31:52.426Z","comments":true,"path":"tags/index.html","permalink":"http://ymlog.cn/tags/index.html","excerpt":"","text":""},{"title":"Category","date":"2020-07-06T09:33:38.445Z","updated":"2020-04-16T04:08:55.000Z","comments":true,"path":"category/index.html","permalink":"http://ymlog.cn/category/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-07-08T01:40:15.000Z","updated":"2020-07-08T01:40:46.834Z","comments":true,"path":"link/index.html","permalink":"http://ymlog.cn/link/index.html","excerpt":"","text":""}],"posts":[{"title":"1","slug":"1","date":"2020-07-10T08:17:54.000Z","updated":"2020-07-10T08:17:54.446Z","comments":true,"path":"2020/07/10/1/","link":"","permalink":"http://ymlog.cn/2020/07/10/1/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"解决Hexo+Github网络图片无法加载问题","slug":"解决Hexo-Github网络图片无法加载问题","date":"2020-07-08T05:03:47.000Z","updated":"2020-07-08T05:14:26.182Z","comments":true,"path":"2020/07/08/解决Hexo-Github网络图片无法加载问题/","link":"","permalink":"http://ymlog.cn/2020/07/08/%E8%A7%A3%E5%86%B3Hexo-Github%E7%BD%91%E7%BB%9C%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/","excerpt":"","text":"如下图是我将Hexo搬到Github上时，网络图片加载不出来的情况，图片链接是完好的： 解决方法： https://github.com/Troy-Yang/hexo-lazyload-image 1、安装hexo-lazyload-image npm install hexo-lazyload-image --save 2、修改project里的主_config.yml配置 lazyload: enable: true onlypost: false # optional loadingImg: # optional eg ./images/loading.gif isSPA: false # optional 3、设置图片样式，只需要设置一个图片样式 &lt;img no-lazy src=\"abc.png\" /&gt;","categories":[{"name":"报错","slug":"报错","permalink":"http://ymlog.cn/categories/%E6%8A%A5%E9%94%99/"}],"tags":[]},{"title":"Docker中Django迁移无效","slug":"Docker中Django迁移无效","date":"2020-07-08T02:12:54.000Z","updated":"2020-07-08T05:02:21.498Z","comments":true,"path":"2020/07/08/Docker中Django迁移无效/","link":"","permalink":"http://ymlog.cn/2020/07/08/Docker%E4%B8%ADDjango%E8%BF%81%E7%A7%BB%E6%97%A0%E6%95%88/","excerpt":"","text":"django-admin startproject projectcd projectpython manage.py startapp api 可以看到，虽然执行了python manage.py makemigrations，但是models.py中定义的模型并没有迁移到数据库中，网上找了很久，发现是要再后面加上APP名，即python manage.py makemigrations api 我的文件目录是这样的： [root@ project]# tree -L 2.├── api│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ ├── models.py│ ├── __pycache__│ ├── tests.py│ ├── urls.py│ └── views.py├── manage.py└── project ├── asgi.py ├── __init__.py ├── __pycache__ ├── settings.py ├── urls.py └── wsgi.p","categories":[{"name":"报错","slug":"报错","permalink":"http://ymlog.cn/categories/%E6%8A%A5%E9%94%99/"}],"tags":[]},{"title":"SSH——用户密钥未在远程主机注册","slug":"SSH—用户密钥未在远程主机注册","date":"2020-07-06T03:43:16.000Z","updated":"2020-07-06T03:57:26.488Z","comments":true,"path":"2020/07/06/SSH—用户密钥未在远程主机注册/","link":"","permalink":"http://ymlog.cn/2020/07/06/SSH%E2%80%94%E7%94%A8%E6%88%B7%E5%AF%86%E9%92%A5%E6%9C%AA%E5%9C%A8%E8%BF%9C%E7%A8%8B%E4%B8%BB%E6%9C%BA%E6%B3%A8%E5%86%8C/","excerpt":"","text":"如图： 刚开始以为是上传的公钥不对，结果生成了几次公钥，发现还是老样子。后来去检查/etc/ssh/sshd_config配置文件，没检查出什么问题，于是从其他主机（能用私钥登录的主机）上复制了SSH的配置文件到本故障主机，然后重启SSHD服务，再用私钥连接，还是出现以上问题！ 查看/var/log/secure日志文件： Authentication refused: bad ownership or modes for file /root/.ssh/authorized_keys 发现是权限不匹配的问题 解决： https://www.bo56.com/ssh%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E8%AE%BE%E7%BD%AE%E6%97%B6authentication-refused-bad-ownership-or-modes%E9%94%99%E8%AF%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/ sshd为了安全，对属主的目录和文件权限有所要求。如果权限不对，则ssh的免密码登陆不生效。用户目录权限为 755 或者 700，就是不能是77x。.ssh目录权限一般为755或者700。rsa_id.pub 及authorized_keys权限一般为644rsa_id权限必须为600","categories":[{"name":"报错","slug":"报错","permalink":"http://ymlog.cn/categories/%E6%8A%A5%E9%94%99/"}],"tags":[]},{"title":"Dockerfile制作Nginx容器","slug":"Produce-the-docker-image-about-nginx","date":"2020-06-29T02:59:50.000Z","updated":"2020-07-08T05:08:23.044Z","comments":true,"path":"2020/06/29/Produce-the-docker-image-about-nginx/","link":"","permalink":"http://ymlog.cn/2020/06/29/Produce-the-docker-image-about-nginx/","excerpt":"念两句诗飞絮飞花何处是，层冰积雪摧残，疏疏一树五更寒。爱他明月好，憔悴也相关。最是繁丝摇落后，转教人忆春山。湔裙梦断续应难。西风多少恨，吹不散眉弯。","text":"念两句诗飞絮飞花何处是，层冰积雪摧残，疏疏一树五更寒。爱他明月好，憔悴也相关。最是繁丝摇落后，转教人忆春山。湔裙梦断续应难。西风多少恨，吹不散眉弯。 困难 容器启动流程 Sed替换等命令 CMD和EntryPoint的异同 动态指定全局、局部参数 优化哪些方面 脚本能够正确的读取参数，且正确的写入到配置文件!!! 需求Docker镜像制作/容器运行1、制作一个Nginx镜像，遵循镜像可迁移、可复制原则、镜像、层级、体积最小化原则2、要求启动能支持指定Nginx进程的监听端口3、首页输出一个hello world4、容器支持开机启动、异常能自拉起5、能够任意指定Nginx的公共参数，包括global、http等全局模块的参数；6、通过启动指定Nginx优化参数，实现首页性能并发超2万（4核服务器）。 思考1、制作Nginx容器？一开始的时候，以为是要从CentOS7中一步一步用命令安装Nginx，后来发现这样不太合理[中间层不够精简]，就用了Nginx的官方镜像。 2、动态指定参数?方法一：模板！如果想要修改端口，那么就必须在Nginx服务起来之前改才有效(了解Docker容器启动流程对完成这一步很有帮助，下面会讲到Docker启动流程)。Nginx官方的template支持该端口，在宿主机编写nginx.conf.template模板，然后复制到容器的/etc/nginx/tempalte/目录，容器会自动把template模板语法填入变量，然后生成conf配置文件且放到容器的/etc/nginx/conf.d/ 方法二：脚本！脚本必须是容器启动时执行的脚本，一般就是EntryPoint的执行脚本。通过在docker run -e ENV=XXX的时候指明环境变量，然后再脚本中调用环境变量，通过sed替换配置文件，然后启动nginx，来达到修改端口，这种方法也可以修改Nginx的其他参数。 3、Nginx优化？维度1：网络 提高连接数 选择响应模型 Gzip sendfile tcp_nopush （1）提高连接并发 worker_processes # Nginx进程worker_connections # 每个进程的最大连接数 官方建议Nignx进程数目和CPU核心数相同， 这样可以减少上下文切换带来的消耗，但是Nginx接受响应的机制是：当有一个请求过来时，先抢到的worker就处理这个请求，也就意味着，worker数量越多，Nginx并发就越高，同时需要考虑进程切换带来的损耗，把上下文切换损耗、Worker进程并发维持在一个合理的值？ CPU数量为2先设置Worker数量为2，查看并发： [root@cmd ~]# for i in &#123;1..3&#125;;do ./hey -c 20000 -z 5s http://localhost:8080 | grep Request; done Requests/sec: 18919.2902 Requests/sec: 20607.1078 Requests/sec: 21383.8651 设置Worker数量为4，查看并发： [root@cmd ~]# for i in &#123;1..3&#125;;do ./hey -c 20000 -z 5s http://localhost:8080 | grep Request; done Requests/sec: 20987.5554 Requests/sec: 20566.2954 Requests/sec: 21486.3096 设置Worker数量为8，查看并发： [root@cmd ~]# for i in &#123;1..3&#125;;do ./hey -c 20000 -z 5s http://localhost:8080 | grep Request; done Requests/sec: 18960.3266 Requests/sec: 19998.3097 Requests/sec: 19924.4970 可见适当提高Worker的数量确实可以提高并发，但是并不明显，而且如果Worker数量过多，甚至会减少并发。 （2）改变请求响应机制 events&#123; use epoll;&#125; （3）Gzip相关原本打算开Gzip的，这个对大文件有效，但是对于小文件，开了Gzip反而会消耗CPU资源[当然这个消耗也很小]，会得不偿失。 （4）零拷贝 sendfile on; https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html可以直接在内核中完成文件传输如果应用程序可以直接访问网络接口存储，那么在应用程序访问数据之前存储总线就不需要被遍历，数据传输所引起的开销将会是最小的。应用程序或者运行在用户模式下的库函数可以直接访问硬件设备的存储，操作系统内核除了进行必要的虚拟存储配置工作之外，不参与数据传输过程中的其它任何事情。直接 I/O 使得数据可以直接在应用程序和外围设备之间进行传输，完全不需要操作系统内核页缓存的支持。 （5）Nopush这个选项Nginx默认关闭，我们选择打开。在sendfile开启情况下，tcp_nopush可以提高网络包的传输效率，所有资源一起打包然后发送，但没有实时性。 tcp_nopush on; 维度2：磁盘（1）加缓存 proxy_cache_path /tmp/cache levels=1:2 keys_zone=code_cache:10m max_size=10g inactive=60m use_temp_path=off; 还是2核CPU，2个Worker：【不加tcp_nopush】 [root@cmd ~]# for i in &#123;1..3&#125;;do ./hey -c 30000 -z 5s http://127.0.0.1:80 | grep Request;done Requests/sec: 52213.8096 Requests/sec: 53834.7774 Requests/sec: 55434.2433 可以看到加了缓存之后，并发涨了2.5倍。 （2）减读写因为日志写入需要占用大量的IO，所以关闭了日志写入，如果不想做的太极端，可以调整写入级别，尽量只写入少量日志。 （3）调整最大文件打开数目 ulimit -n 65535 # 同时连接的数量受限于系统上可用的文件描述符的数量worker_rlimit_nofile # 将此值增加到大于worker_processes * worker_connections的值 维度3：CPU绑定Worker进程到指定CPU worker_processes 4; # 4核CPU的配置worker_cpu_affinity 0001 0010 0100 1000; # 将每个Worker进程绑定到一个CPU 作用不大！ 总结：如果不加缓存，磁盘会成为瓶颈，加了缓存，CPU会成为瓶颈。 [1,2 分别是两颗CPU] 实践 Version 1 【镜像制作】 Version 2 【指定参数，优化并发】 Version 3 【指定参数，优化并发】 Version 4 【任意参数指定，进一步提升并发】 Version 1 制作Nginx镜像 修改监听端口 能正常访问 指定任意参数 Nginx优化 为什么一开始注释掉了CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;] ———— 因为不注释就会导致容器拉起异常！原因是因为容器开机会执行docker-entrypoint脚本，然而我的EntryPoint脚本中并没有写”exec $@”，就不会把Nginx放到前台执行，导致了容器执行完脚本直接退出。刚开始用的解决办法是把Nginx进程直接写到check.sh中，通过EntryPoint执行，这样也能保证前台有Nginx任务，docker容器不至于异常退出。 Docker容器进程需要放在前台执行，如果那么脚本执行完前台没有任务，那么容器会自动退出。容器启动时会加载CMD命令，如果有EntryPoint，那么就加载EntryPoint，CMD作为参数传给EntryPoint。 这个健康检查脚本应该没什么用，如果一号进程退出了，容器就挂了，给自己的健康检查也就做不了了，后来换成了再docker run的时候加上–restart=always参数，并且保证docker daemon能够开机自启。 Version 2 尝试在命令行着替换部分参数，用的是容器内部读取环境变量的方法 还是未能完成全部参数的动态指定 优化了Nginx并发 Version 3 未能实现全部配置可自定义 优化了Nginx并发 [root@nginx ~ ]#cat start.sh # &lt;====这是个容器开机启动脚本append()&#123; echo \"$&#123;1&#125;\" &gt;&gt; /etc/nginx/nginx.conf&#125;rm /etc/nginx/nginx.conf -rf# WORK_PROGRESSES=4# WORKER_CPU_AFFINITY=\"0001 0010 0100 1000\"# WORKER_RLIMIT_NOFILE=65535# WORKER_CONNECTIONS=65535append \"user nginx;\"append \"worker_processes $&#123;WORK_PROGRESSES&#125;;\"append \"worker_cpu_affinity $&#123;WORKER_CPU_AFFINITY&#125;;\"append \"worker_rlimit_nofile $&#123;WORKER_RLIMIT_NOFILE&#125;;\"append \"pid /var/run/nginx.pid;\"append \"events &#123; use epoll; worker_connections $&#123;WORKER_CONNECTIONS&#125;;&#125;\"append \"http &#123;\"append \"include /etc/nginx/mime.types;\"append \"default_type application/octet-stream;\"append \"open_file_cache max=65535 inactive=60s;\"append \" sendfile on;\"append \" tcp_nopush on;\"append \" tcp_nodelay on;\"append \" keepalive_timeout $&#123;KEEPALIVE_TIMEOUT&#125;;\"append \" include /etc/nginx/conf.d/*.conf;\"append \"&#125;\"sed -i '0,/listen.*;/s/listen.*;/listen '$&#123;LISTEN&#125;';/' /etc/nginx/conf.d/default.confexec \"$@\" 直接把环境变量echo进nginx配置文件，这样写比sed简单，且能达到同样的效果。 [root@nginx ~ ]# cat dockerfileFROM nginx:latestMAINTAINER zen &lt;2212585023@qq.com&gt;ENV NGINX_VERSION 1.19.1COPY ./index.html /usr/share/nginx/html/COPY ./start.sh /RUN chmod +x /start.shSTOPSIGNAL SIGTERM # 这个是kill -15 温柔的杀死容器里的1号进程EXPOSE 80ENTRYPOINT [\"/start.sh\"]CMD [\"nginx\", \"-g\", \"daemon off;\"] 拉去Nginx镜像，复制HTML文件，复制开机启动脚本，需要注意的是，Nginx官方默认docker-entrypoint.d/目录下的脚本就是开机启动脚本，执行Nginx启动命令。 关于 CMD [“nginx”,”-g”,”daemon off;”] 这个命令，刚开始我以为是在命令行执行nginx -g daemon off，但是在容器内，这条命始终执行不了，以至于我怀疑CMD到底是干什么？命令到底是怎么执行的？越搞越乱！后来发现这条命令执行还需要加一些符号，即Nginx -g “daemon off;” ，这个问题纠结了很久！ 运行方式 docker run -itd \\ -e WORK_PROGRESSES=2 \\ -e WORKER_RLIMIT_NOFILE=65535 \\ -e WORKER_CONNECTIONS=65535 \\ -e KEEPALIVE_TIMEOUT=15 \\ -e LISTEN=80\\ --net=host --name x1 nginx/v1 Version 4 任意参数指定 更高的并发 先看结果，还是原来的两核CPU，实现了57000左右的并发 [root@cmd ~]# for i in &#123;1..3&#125;;do ./hey -c 30000 -z 5s http://127.0.0.1:8080 | grep Requests;done Requests/sec: 58493.2355 Requests/sec: 55574.4684 Requests/sec: 56862.8460 思路还是在启动容器的时候执行EntryPoint脚本修改Nginx参数，不同的地方在于将Nginx参数位置作为前缀，通过前缀指定参数插入的位置，比如 Global -- ngx_glo_worker_progress 相当于全局配置下的worker_progressEvents -- ngx_evt_worker_connections 相当于events中的worker_connectionsHttp -- ngx_http_sendfile 相当于http模块中的sendfileServer -- ngx_ser_listen 相当于server模块中的listenLocation -- ngx_loc_root 相当于location模块中的root 通过case进行筛选，然后插入到nginx.conf配置文件的不同位置,脚本代码如下： CONFIG_PATH=/etc/nginx/nginx.conf cat &gt;/etc/nginx/nginx.conf &lt;&lt; 'EOF'user nginx;pid /run/nginx.pid;include /usr/share/nginx/modules/*.conf;events &#123; use epoll; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server &#123; listen 80 default_server; server_name _; root /usr/share/nginx/html; include /etc/nginx/default.d/*.conf; location / &#123; root /usr/share/nginx/html/; add_header Nginx-Cache \"$upstream_cache_status\"; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; include params; &#125; &#125;&#125;EOFcat &gt; /etc/nginx/params &lt;&lt; 'EOF'proxy_connect_timeout 30;proxy_send_timeout 60;proxy_read_timeout 60;proxy_buffer_size 32k;proxy_buffering on;proxy_buffers 4 128k;proxy_busy_buffers_size 256k;proxy_max_temp_file_size 256k;EOF# 读出来的时候只有：ngx_http_proxy_cache_path=/tmp/cache# 遗留Bug！！！# 已有的替换 出现[include]会替换多个# 没有的插入 [$proxy_add_x_forwarded_for] 没有测试能否插入变量，\\$xxx# 用line循环可以避免中间有空行的变量：ngx_http_proxy_cache_path=/tmp/cache levels=1:2 keys_zone=code_cache:10m max_size=10g inactive=60m use_temp_path=offline=$(env | grep -E \"^ngx\" | wc -l)for i in `seq $line`;do # 这里将第一个'='号替换为0x80是为了防止后面有相同的等号误操作，比如ngx_http_proxy_cache_path=/tmp/cache levels=1:2;这样的变量 one=$(env | grep -E \"^ngx\" | sed -n $&#123;i&#125;'p') value=$(echo \"$&#123;one&#125;\" | sed 's/=/0x80/1' | awk -F '0x80' '&#123;print $2&#125;' ) field=$(echo \"$&#123;one&#125;\" | sed 's/=/0x80/1' | awk -F '0x80' '&#123;print $1&#125;' ) # field=前缀+后缀 prefix=$(echo \"$&#123;field&#125;\" | sed 's/_/ /2' | awk '&#123;print $1&#125;') # 前缀决定字段的位置 ngx_loc suffix=$(echo \"$&#123;field&#125;\" | sed 's/_/ /2' | awk '&#123;print $2&#125;') # 后缀决定什么字段 listen glo_ins()&#123; field=$&#123;1&#125;\" \"$&#123;2&#125;\";\" if [[ -z $(grep \"$1\" $&#123;CONFIG_PATH&#125;) ]];then # 由于出现过ngx_http_tcp_nopush会插入到proxy_set_header Host $http_host;下面，所有在sed侧加入了完全匹配\\&lt;\\&gt; sed -i '/\\&lt;events\\&gt;/i '\"$&#123;field&#125;\" $&#123;CONFIG_PATH&#125; else sed -i '/\\&lt;'\"$&#123;1&#125;\"'\\&gt;/c '\"$&#123;field&#125;\" $&#123;CONFIG_PATH&#125; fi &#125; oth_insrt()&#123; module=\"$&#123;1&#125;\" field=\"$&#123;2&#125; $&#123;3&#125;;\" if [[ -z $(grep \"$2\" $&#123;CONFIG_PATH&#125;) ]];then sed -i '/\\&lt;'\"$&#123;module&#125;\"'\\&gt;/a '\"$&#123;field&#125;\" $&#123;CONFIG_PATH&#125; else sed -i '/\\&lt;'\"$&#123;2&#125;\"'\\&gt;/c '\"$&#123;field&#125;\" $&#123;CONFIG_PATH&#125; fi &#125; # 主要逻辑如下： case $&#123;prefix&#125; in ngx_glo) glo_ins \"$suffix\" \"$value\" ;; ngx_evt) oth_insrt events \"$suffix\" \"$value\" ;; ngx_http) oth_insrt http \"$suffix\" \"$value\" ;; ngx_ser) oth_insrt server \"$suffix\" \"$value\" ;; ngx_loc) oth_insrt location \"$suffix\" \"$value\" ;; esacdoneexec \"$@\" &nbsp;&nbsp;Sed各种匹配替换 “${var}”所包含的是一个完整的变量，如果用${var}且变量为”x=1 y=2 z=3”,那么从环境变量里取出来的时候，往往只能取到x=1 参数指定如下： $ cat run.sh docker rm $(docker ps -a | grep -E '\\&lt;x1\\&gt;' | awk '&#123;print $1&#125;') -fdocker rmi $(docker image ls | grep 'nginx/v1' |awk '&#123;print $3&#125;') --forcedocker build -t nginx/v1 .docker run -itd --cpuset-cpus=\"0,1\" \\-e ngx_glo_worker_processes=4 \\-e ngx_glo_worker_rlimit_nofile=65535 \\-e ngx_evt_worker_connections=65535 \\-e ngx_http_tcp_nopush=on \\-e ngx_http_sendfile=on \\-e ngx_http_proxy_cache_path=\"/tmp/cache levels=1:2 keys_zone=code_cache:10m max_size=10g inactive=60m use_temp_path=off\" \\-e ngx_ser_listen=8080 \\-e ngx_loc_proxy_cache=code_cache \\-e ngx_loc_proxy_cache_valid=\"any 30m\" \\--net=host --name --restart=always x1 nginx/v1","categories":[{"name":"容器","slug":"容器","permalink":"http://ymlog.cn/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ymlog.cn/tags/Docker/"}]},{"title":"VsCode远程开发","slug":"VsCode_Remote_Config","date":"2020-06-18T02:50:36.000Z","updated":"2020-07-04T17:18:01.461Z","comments":true,"path":"2020/06/18/VsCode_Remote_Config/","link":"","permalink":"http://ymlog.cn/2020/06/18/VsCode_Remote_Config/","excerpt":"念两句诗草铺横野六七里，笛弄晚风三四声。归来饱饭黄昏后，不脱蓑衣卧月明。","text":"念两句诗草铺横野六七里，笛弄晚风三四声。归来饱饭黄昏后，不脱蓑衣卧月明。 Powershell下安装OpenSSH，安装失败也不要紧 Get-WindowsCapability -Online | ? Name -like 'OpenSSH*'Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0 1、下载插件：Remote Development 2、Ctrl+Shift+P打开设置Remote SSH Settings，设置Remote.SSH:Show Login Terminal为true 3、左下角会多出来一个远程连接的图标，点击图标会弹出选择框，选择Connect to Host 4、选择一个Host，或者采用如下形式登录 ssh root@x.x.x.x -A 5、输入登录密码 6、添加远程文件夹 7、选择终端解释器，这里我选择了/bin/bash，Ctrl+Shift+` 新建终端 相关链接： https://blog.csdn.net/yh0503/article/details/89851899 https://docs.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_install_firstuse","categories":[{"name":"运维","slug":"运维","permalink":"http://ymlog.cn/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"VsCode","slug":"VsCode","permalink":"http://ymlog.cn/tags/VsCode/"}]},{"title":"Win快捷键","slug":"Win_ShotCut","date":"2020-06-18T00:37:32.000Z","updated":"2020-07-04T17:17:42.906Z","comments":true,"path":"2020/06/18/Win_ShotCut/","link":"","permalink":"http://ymlog.cn/2020/06/18/Win_ShotCut/","excerpt":"念两句诗十年生死两茫茫，不思量，自难忘。千里孤坟，无处话凄凉。纵使相逢应不识，尘满面，鬓如霜。夜来幽梦忽还乡，小轩窗，正梳妆。相顾无言，惟有泪千行。料得年年肠断处，明月夜，短松冈。","text":"念两句诗十年生死两茫茫，不思量，自难忘。千里孤坟，无处话凄凉。纵使相逢应不识，尘满面，鬓如霜。夜来幽梦忽还乡，小轩窗，正梳妆。相顾无言，惟有泪千行。料得年年肠断处，明月夜，短松冈。 Win+P 投影Win+K 蓝牙Win+D 桌面Win+E 此电脑Win+R 调出”运行” Win+Q 搜索Win+W 截图Win+i 设置Win+A 通知Win+F 反馈Win+L 锁屏Win+X 左下功能界面Win+V 历史剪贴板Win+M 最小化当前界面Win+&gt; 表情符号😊🤦‍♂️ Ctrl+Win+⬅ 切换到左边的桌面Ctrl+Win+➡ 切换到右边的桌面 分屏功能键Win+upWin+leftWin+rightWin+down Alt+F4+[Fn] 关机Win+Nbr[1,2,3] 打开任务栏第Nbr位的软件Win+Space 切换输入法F2 重命名F11 全屏","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"ls根目录卡死","slug":"ls_root_broken_down","date":"2020-06-17T14:46:04.000Z","updated":"2020-07-06T03:43:55.355Z","comments":true,"path":"2020/06/17/ls_root_broken_down/","link":"","permalink":"http://ymlog.cn/2020/06/17/ls_root_broken_down/","excerpt":"念两句诗无善无恶心之体，有善有恶意之动知善知恶是良知，为善去恶是格物","text":"念两句诗无善无恶心之体，有善有恶意之动知善知恶是良知，为善去恶是格物 问题只要涉及到根目录，使用ls和df命令就会出现卡死情况。 [root@zen] pwd/root[root@zen] ls /^C[root@zen] df h^C[root@zen] ls /optcontainerd google jumpserver mysql prometheus 踩坑1、起初在网上找了一些方法，大多是目录挂载的问题；里面叫你用strace定位问题，然后在lstate的时候会发现是目录没挂载上去，但是我用strace的时候，是正常退出的，因为流程过长，strace的log放在结尾了。 类似于这样： https://blog.51cto.com/chaichuan/2104093https://blog.csdn.net/u010801696/article/details/78490103 2、后来发现可能是日志文件过大，或者是文件细碎导致ls太慢，通常是/var/spool/postfix/这个目录下的maildrop太大，但是我看了一下我的，并没有太大。maildrop 爆满的问题一般是 crontab 未屏蔽错误造成的,可以将crontab里的条目指定到&amp;&gt;/dev/null [root@zen]# ll /var/spool/postfix/total 56drwx------. 2 postfix root 4096 Oct 31 2018 activedrwx------. 2 postfix root 4096 Oct 31 2018 bouncedrwx------. 2 postfix root 4096 Oct 31 2018 flushdrwx------. 2 postfix root 4096 Oct 31 2018 holddrwx------. 2 postfix root 4096 Oct 31 2018 incomingdrwx-wx---. 2 postfix postdrop 4096 Oct 31 2018 maildrop 3、第三种可能是磁盘挂载的问题，根目录丢失之类的。 cat /etc/fstabcat /etc/mtabgrep -v rootfs /proc/mounts # 修复 /etc/fstab 中的挂载点是开机加载的/etc/mtab 中的挂载点是内核动态实时更新的简单来说就是一次修复挂载的问题，但是我做完这几部操作，依旧没有用 https://zhang.ge/5107.html 解决其实和另一台服务器有关，我们暂时把它称之为O[other]，我们这台服务器为M[me],O上开启了NFS服务，Me服务器挂载了O上的磁盘。过了段时间，O服务器进行了重装，但是M服务器还在挂载O上的磁盘，此时other服务器没有开启NFS服务，但是Me服务器依旧挂载着O的磁盘。 于是执行ls / 命令的时候，me服务器加载目录，加载前几个好好的，在strace中可以看到，但加载到/mount_point的时候，就会向O服务器发送请求，[应该是某个NFSBug，明明O上的NFS Down了，这个M服务器还是在一直等待响应]，于是看上去就像是me服务器卡死了，其实它是在等待NFS的响应。 采取的解决措施：重启，有尝试过umount卸载挂载点，但会卡住。 2020/6/22 看鸟哥Linux私房菜发现也有这方面的情况： 只要有用到文件系统， 那么整个目录树系统就会主动的去查询全部的挂载点。如果你的 NFS 服务器与客户端之间的联机因为网络问题， 或者是服务器端先关机了，却没有通知客户端，那么客户端只要动到文件系统的指令 (例如 df, ls, cp 等等) ，整个系统就会慢到爆！因为你必须要等到文件系统搜寻等待逾时后，系统才会饶了你！(鸟哥等过 df 指令 30 分钟过…) 参数 参数功能 预设参数 fg，bg 当执行挂载时，该挂载的行为会在前景 (fg) 还是在背景 (bg) 执行？ 若在前景执行时，则 mount 会持续尝试挂载，直到成功或 time out 为止，若为背景执行， 则 mount 会在背景持续多次进行 mount ，而不会影响到前景的程序操作。 如果你的网络联机有点不稳定，或是服务器常常需要开关机，那建议使用 bg 比较妥当。 fg soft，hard 如果是 hard 的情况，则当两者之间有任何一部主机脱机，则 RPC 会持续的呼叫，直到对方恢复联机为止。如果是 soft 的话，那 RPC 会在 time out 后『重复』呼叫，而非『持续』呼叫， 因此系统的延迟会比较不这么明显。同上，如果你的服务器可能开开关关，建议用 soft 喔！ hard intr 当你使用上头提到的 hard 方式挂载时，若加上 intr 这个参数， 则当 RPC 持续呼叫中，该次的呼叫是可以被中断的 (interrupted)。 没有 rsize，wsize 读出(rsize)与写入(wsize)的区块大小 (block size)。 这个设定值可以影响客户端与服务器端传输数据的缓冲记忆容量。一般来说， 如果在局域网络内 (LAN) ，并且客户端与服务器端都具有足够的内存，那这个值可以设定大一点， 比如说 32768 (bytes) 等，提升缓冲记忆区块将可提升 NFS 文件系统的传输能力！ 但要注意设定的值也不要太大，最好是达到网络能够传输的最大值为限。 rsize=1024 wsize=1024 for example: $ mount -t nfs -o nosuid,noexec,nodev,rw 192.168.1.1:/data /tmp 最后补充下NFS无法挂载的原因分析： 客户端主机和IP网段不被允许使用, ‘mount to NFS x.x.x.x failed:system error connection refused’ 服务器或客户端服务未启动,’mount to NFS x.x.x.x failed:RPC Error : programe not registered’ 被防火墙拦截 附录[root@zen]# strace ls / execve(\"/usr/bin/ls\", [\"ls\", \"/\"], [/* 23 vars */]) = 0brk(NULL) = 0x169f000mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d51a1000access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory)open(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=52409, ...&#125;) = 0mmap(NULL, 52409, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fd6d5194000close(3) = 0open(\"/lib64/libselinux.so.1\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\220j\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=155744, ...&#125;) = 0mmap(NULL, 2255216, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d4d5a000mprotect(0x7fd6d4d7e000, 2093056, PROT_NONE) = 0mmap(0x7fd6d4f7d000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x23000) = 0x7fd6d4f7d000mmap(0x7fd6d4f7f000, 6512, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fd6d4f7f000close(3) = 0open(\"/lib64/libcap.so.2\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\20\\26\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=20048, ...&#125;) = 0mmap(NULL, 2114112, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d4b55000mprotect(0x7fd6d4b59000, 2093056, PROT_NONE) = 0mmap(0x7fd6d4d58000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x3000) = 0x7fd6d4d58000close(3) = 0open(\"/lib64/libacl.so.1\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0p\\37\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=37064, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d5193000mmap(NULL, 2130560, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d494c000mprotect(0x7fd6d4953000, 2097152, PROT_NONE) = 0mmap(0x7fd6d4b53000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x7000) = 0x7fd6d4b53000close(3) = 0open(\"/lib64/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0`&amp;\\2\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=2156240, ...&#125;) = 0mmap(NULL, 3985920, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d457e000mprotect(0x7fd6d4741000, 2097152, PROT_NONE) = 0mmap(0x7fd6d4941000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1c3000) = 0x7fd6d4941000mmap(0x7fd6d4947000, 16896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fd6d4947000close(3) = 0open(\"/lib64/libpcre.so.1\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\360\\25\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=402384, ...&#125;) = 0mmap(NULL, 2494984, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d431c000mprotect(0x7fd6d437c000, 2097152, PROT_NONE) = 0mmap(0x7fd6d457c000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x60000) = 0x7fd6d457c000close(3) = 0open(\"/lib64/libdl.so.2\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0P\\16\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=19248, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d5192000mmap(NULL, 2109744, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d4118000mprotect(0x7fd6d411a000, 2097152, PROT_NONE) = 0mmap(0x7fd6d431a000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x2000) = 0x7fd6d431a000close(3) = 0open(\"/lib64/libattr.so.1\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\320\\23\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=19896, ...&#125;) = 0mmap(NULL, 2113904, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d3f13000mprotect(0x7fd6d3f17000, 2093056, PROT_NONE) = 0mmap(0x7fd6d4116000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x3000) = 0x7fd6d4116000close(3) = 0open(\"/lib64/libpthread.so.0\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\200m\\0\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=142144, ...&#125;) = 0mmap(NULL, 2208904, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fd6d3cf7000mprotect(0x7fd6d3d0e000, 2093056, PROT_NONE) = 0mmap(0x7fd6d3f0d000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x16000) = 0x7fd6d3f0d000mmap(0x7fd6d3f0f000, 13448, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fd6d3f0f000close(3) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d5191000mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d518f000arch_prctl(ARCH_SET_FS, 0x7fd6d518f840) = 0mprotect(0x7fd6d4941000, 16384, PROT_READ) = 0mprotect(0x7fd6d3f0d000, 4096, PROT_READ) = 0mprotect(0x7fd6d4116000, 4096, PROT_READ) = 0mprotect(0x7fd6d431a000, 4096, PROT_READ) = 0mprotect(0x7fd6d457c000, 4096, PROT_READ) = 0mprotect(0x7fd6d4b53000, 4096, PROT_READ) = 0mprotect(0x7fd6d4d58000, 4096, PROT_READ) = 0mprotect(0x7fd6d4f7d000, 4096, PROT_READ) = 0mprotect(0x61a000, 4096, PROT_READ) = 0mprotect(0x7fd6d51a2000, 4096, PROT_READ) = 0munmap(0x7fd6d5194000, 52409) = 0set_tid_address(0x7fd6d518fb10) = 23051set_robust_list(0x7fd6d518fb20, 24) = 0rt_sigaction(SIGRTMIN, &#123;0x7fd6d3cfd860, [], SA_RESTORER|SA_SIGINFO, 0x7fd6d3d06630&#125;, NULL, 8) = 0rt_sigaction(SIGRT_1, &#123;0x7fd6d3cfd8f0, [], SA_RESTORER|SA_RESTART|SA_SIGINFO, 0x7fd6d3d06630&#125;, NULL, 8) = 0rt_sigprocmask(SIG_UNBLOCK, [RTMIN RT_1], NULL, 8) = 0getrlimit(RLIMIT_STACK, &#123;rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY&#125;) = 0statfs(\"/sys/fs/selinux\", 0x7ffca215e650) = -1 ENOENT (No such file or directory)statfs(\"/selinux\", 0x7ffca215e650) = -1 ENOENT (No such file or directory)brk(NULL) = 0x169f000brk(0x16c0000) = 0x16c0000open(\"/proc/filesystems\", O_RDONLY) = 3fstat(3, &#123;st_mode=S_IFREG|0444, st_size=0, ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d51a0000read(3, \"nodev\\tsysfs\\nnodev\\trootfs\\nnodev\\tr\"..., 1024) = 371stat(\"/etc/sysconfig/64bit_strstr_via_64bit_strstr_sse2_unaligned\", 0x7ffca215dbb0) = -1 ENOENT (No such file or directory)read(3, \"\", 1024) = 0close(3) = 0munmap(0x7fd6d51a0000, 4096) = 0access(\"/etc/selinux/config\", F_OK) = 0open(\"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=106172832, ...&#125;) = 0mmap(NULL, 106172832, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fd6cd7b5000close(3) = 0ioctl(1, TCGETS, &#123;B38400 opost isig icanon echo ...&#125;) = 0ioctl(1, TIOCGWINSZ, &#123;ws_row=39, ws_col=105, ws_xpixel=0, ws_ypixel=0&#125;) = 0stat(\"/\", &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0openat(AT_FDCWD, \"/\", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3getdents(3, /* 29 entries */, 32768) = 800getdents(3, /* 0 entries */, 32768) = 0close(3) = 0fstat(1, &#123;st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd6d51a0000write(1, \"baiduds CloudResetPwdAgentNew\\t \"..., 76baiduds CloudResetPwdAgentNew data home lost+found opt run sys usr) = 76write(1, \"bin\\t CloudResetPwdUpdateAgent d\"..., 70bin CloudResetPwdUpdateAgent dev lib media proc sbin tmp var) = 70write(1, \"boot\\t CloudrResetPwdAgent\\t etc\"..., 62boot CloudrResetPwdAgent etc lib64 mnt root srv tms) = 62close(1) = 0munmap(0x7fd6d51a0000, 4096) = 0close(2) = 0exit_group(0) = ?+++ exited with 0 +++","categories":[{"name":"报错","slug":"报错","permalink":"http://ymlog.cn/categories/%E6%8A%A5%E9%94%99/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"http://ymlog.cn/tags/NFS/"}]},{"title":"Vimium快捷键","slug":"Vimium_ShotCut","date":"2020-06-16T10:02:13.000Z","updated":"2020-07-04T17:18:04.516Z","comments":true,"path":"2020/06/16/Vimium_ShotCut/","link":"","permalink":"http://ymlog.cn/2020/06/16/Vimium_ShotCut/","excerpt":"念两句诗世味年來薄似紗，誰令騎馬客京華。小樓一夜聽春雨，深巷明朝賣杏花。矮紙斜行閒作草，晴窗細乳戲分茶。素衣莫起風塵嘆，猶及清明可到家。","text":"念两句诗世味年來薄似紗，誰令騎馬客京華。小樓一夜聽春雨，深巷明朝賣杏花。矮紙斜行閒作草，晴窗細乳戲分茶。素衣莫起風塵嘆，猶及清明可到家。 转自： https://sspai.com/post/27723 1、常用快捷键 j：向下滚动一点 k：向上滚动一点 gg：到页面最底部 G：到页面最底部 d：向下翻一屏 u：向上翻一屏 gs: 查看网页源代码 yy：拷贝当前页面的URL到剪贴板 gu：跳转到父页面 K：跳转到右边标签页 J：跳转到左边标签页 x：关闭当前标签页 X：恢复刚刚关闭的标签页 H：在历史记录中后退 L：在历史记录中前进 ？：查看帮助页面 2、打开新页面 复制一段链接：经常在网页上看到一段链接文字，但却是不可点的。原来你需要先复制，然后新建标签页，再粘贴，敲回车后才能打开。现在呢？你只需要把要打开的链接复制一下，直接按「p」或「P」就可以打开了，小写的 p 是在当前标签页打开，大写的 P 则新建标签页打开。 从收藏夹、历史记录打开：是不是之前看过什么网页，现在又想看了，还需要再打开历史记录找？或者想打开收藏夹里的某个链接？现在，直接按下「o」，输入对应的关键字后，会一起搜索你的历史记录和收藏夹，如果你输的是一个网址，回车还能直接打开。 3、只用敲三下，打开当前页面上任意一个链接如果说，任意一个页面上，哪所有再多链接，你也不用鼠标，最多只需要敲三个键，你就可以迅速打开任意一个链接，你信不信？Vimium 就可以办到。 你只需要按一下「f」，然后当前页面上所有可点击的元素，都会生成一个对应的快捷键分派给这些链接。比如我现在想点击导航栏上的「专题」，只需要再输入「GJ」，OK！完成了，你只敲了三个键，就打开了「专题」页面。 4、显示当前所有的标签页，并快速切换有时候在查找信息、翻阅资料时，经常会一口气打开几十个网站，东西一多，Chrome 会自动将每个标签页的宽度缩小，几乎就看不到它们的标题了。用了 Vimium，你可以按一下大写的「T」，就可以显示当前打开的所有标签页，并支持快捷搜索和跳转。","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"Jetbrains快捷键","slug":"Jetbrains_ShutCut","date":"2020-06-16T03:23:57.000Z","updated":"2020-07-04T17:19:27.331Z","comments":true,"path":"2020/06/16/Jetbrains_ShutCut/","link":"","permalink":"http://ymlog.cn/2020/06/16/Jetbrains_ShutCut/","excerpt":"念两句诗高城鼓动兰釭灺。睡也还醒，醉也还醒：忽听孤鸿三两声。人生只似风前絮。欢也零星，悲也零星，都作连江点点萍。","text":"念两句诗高城鼓动兰釭灺。睡也还醒，醉也还醒：忽听孤鸿三两声。人生只似风前絮。欢也零星，悲也零星，都作连江点点萍。 转自： https://segmentfault.com/a/1190000007206543 编辑 快捷键组合 说明 Ctrl + Space 代码自动完成提示（选择） Alt + Enter 显示意图动作和快速修复 Ctrl + P 参数信息（在调用方法参数忘记的时候，提示） Ctrl + Q 快速查找文件，可以查找当前类定义的文件等 Ctrl + 鼠标滑过 基本信息 Alt + Insert 生成代码…(细节需要多次操作会发现很有意思) Ctrl + O 重写方法（在PHPStorm中是重写父类方法，会有选择框） Ctrl + I 实现方法（一般是指实现接口类或抽象类方法） Ctrl + Alt + T 环绕代码块 (if..else, try..catch, for, 等) Ctrl + / 单行注释(//) Ctrl + Shift + / 块注释 (/**/) Ctrl + W 选择依次递增的代码块，具体使用目前来看比较少 Ctrl + Shift + W 去掉当前选择返回上一个选择，类似于撤销选择，与上面的相反 Ctrl + Alt + L 格式化代码，一般来说，写的代码格式不整齐统一，这个很有用 Ctrl + Alt + I 自啮合线，这个解释不太好解释，测试结果就是会自动根据代码来进行对齐 Ctrl + D 复制当前行或选定的块 Ctrl + Y 删除插入符号所在行 Ctrl + Shift + J 智能线连接（HTML和JavaScript才有用） Ctrl + Enter 智能分割线 (HTML 和 JavaScript 才有用) Shift + Enter 开始新行，比如光标在当前行，不需要切换到行尾按Enter，直接按这个组合键即可 Ctrl + Shift + U 切换选中的英文文字的大小写，此处其实用到挺多的 Ctrl + Shift + ] 或 [ 选择直到代码块的开始或结束，我之前不知道这个，其实很有用 Ctrl + Delete 删除从当前光标到当前单词结尾 Ctrl + Backspace 从光标位置删除到当前单词的开始 Ctrl + + 或 - 这里是ctrl和加号或者减号产生的组合，可以折叠或展开当前代码块 Ctrl + F4 关闭活动中的tab Ctrl + Shift + V 从历史粘贴 调试 此处我是用得很少 快捷键组合 说明 F8 跳过 F7 步进 Shift + F8 跳出 Alt + F8 表达式求值 F9 恢复程序 Ctrl + F8 切断断点 Ctrl+Shift+F8 查看断点 运行 快捷键组合 说明 Shift + F10 运行 Shift + F9 调试 Ctrl + Shift + F10 从编辑器运行上下文配置（Run context configuration from editor），此处可能翻译不够准确 Ctrl + Shift + X 在命令行运行 搜索/替换 快捷键组合 说明 Ctrl + F/R 查找/替换 F3/Shift + F3 查找下一个/上一个 Ctrl + Shift + F/R 在目录中查找/替换 查找哪些地方使用 快捷键组合 说明 Alt + F7 / Ctrl + F7 当前文件查找被使用/在文件中查找哪些地方使用 Ctrl + Shift + F7 文件中搜索并在使用的地方高亮显示 Ctrl + Alt + F7 显示哪些地方被使用 导航 快捷键组合 说明 Ctrl + N 跳转到指定类 Ctrl + Shift + N 跳转到文件 Ctrl + Alt + Shift + N 跳转到符号 Ctrl + G 跳转到第几行 Alt + Right/Left 切换编辑器活动窗 Esc Go to editor (from tool window) Ctrl + E 弹出最近编辑文件，我也是在写这文档才知道，太方便了 Ctrl + Alt + Left/Right 导航前进/后退 Ctrl + Shift + Backspace 跳转到最近编辑的代码位置 Alt + F1 在任何视图中选择当前文件或符号 Ctrl + B 或 Ctrl + Click 跳到申明（如跳转到当前函数声明的地方，这个很常用，可以实操一下） Ctrl + Alt + B 与上面相反，跳到执行位置 Ctrl + Shift + I 打开快速定义查找 Ctrl + Shift + B 跳转到类型声明 Ctrl + U 跳到超级方法(super-method)/超类 (super-class) Alt + Up/Down 跳转到上一个或者下一个方法，在编辑一个类的时候，方便一个一个的方法进行查看 Ctrl + ] / [ 跳转到代码块的开始或结束 F2 / Shift + F2 跳转到上一个或下一个高亮错误地方，这个检查代码语法错误很有用 F4 / Ctrl + Enter 编辑源代码/查看源代码 常用操作 快捷键组合 说明 快速按两次 Shift 搜索任何一个地方 Ctrl + Shift + A 查找方法(Action) Alt + #[0-9] 打开相应的工具窗口（这个我也没搞明白） Ctrl + Alt + F11 开启或关闭全屏模式 Ctrl + Shift + F12 开启或关闭最大化编辑 Alt + Shift + F 添加到收藏列表（我觉得这个功能很神奇，不知道为啥要这么做） Alt + Shift + I 检查当前文件以及当前配置文件 Ctrl + Alt + S 打开设置对话框（表示会与QQ默认快捷键冲突） Ctrl + Tab 在 tabs 和工具窗口间切换","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"Chrome快捷键","slug":"Chrome_ShutCut","date":"2020-06-16T03:23:27.000Z","updated":"2020-07-04T17:19:41.482Z","comments":true,"path":"2020/06/16/Chrome_ShutCut/","link":"","permalink":"http://ymlog.cn/2020/06/16/Chrome_ShutCut/","excerpt":"念两句诗春未老，风细柳斜斜。试上超然台上望，半壕春水一城花。烟雨暗千家。寒食后，酒醒却咨嗟。休对故人思故国，且将新火试新茶。诗酒趁年华。","text":"念两句诗春未老，风细柳斜斜。试上超然台上望，半壕春水一城花。烟雨暗千家。寒食后，酒醒却咨嗟。休对故人思故国，且将新火试新茶。诗酒趁年华。 转自：https://www.runoob.com/w3cnote/google-chrome-shortcuts.html Windows 和 Linux版本的chrome标签页和窗口快捷键 操作 快捷键 打开新窗口 Ctrl + n 在隐身模式下打开新窗口 Ctrl + Shift + n 打开新的标签页，并跳转到该标签页 Ctrl + t 重新打开最后关闭的标签页，并跳转到该标签页 Ctrl + Shift + t 跳转到下一个打开的标签页 Ctrl + Tab 或 Ctrl + PgDn 跳转到上一个打开的标签页 Ctrl + Shift + Tab 或 Ctrl + PgUp 跳转到特定标签页 Ctrl + 1 到 Ctrl + 8 跳转到最后一个标签页 Ctrl + 9 在当前标签页中打开主页 Alt + Home 关闭当前标签页 Ctrl + w 或 Ctrl + F4 关闭所有打开的标签页和浏览器 Ctrl + Shift + w 最小化当前窗口 Alt + 空格键 + n 最大化当前窗口 Alt + 空格键 + x 退出 Google Chrome Ctrl + Shift + q 或 Alt + F4 chrome 功能快捷键 操作 快捷键 打开”菜单” Alt + f、Alt + e 或 F10 显示或隐藏书签栏 Ctrl + Shift + b 打开书签管理器 Ctrl + Shift + o 在新标签页中打开”历史记录”页 Ctrl + h 在新标签页中打开”下载内容”页 Ctrl + j 打开 Chrome 任务管理器 Shift + Esc 将焦点放置在 Chrome 工具栏中的第一项上 Shift + Alt + t 在地址栏、书签栏（若显示）和页面内容之间向前切换焦点 F6 在地址栏、书签栏（若显示）和页面内容之间向后切换焦点 Shift + F6 打开查找栏搜索当前网页 Ctrl + f 或 F3 跳转到与查找栏中搜索字词相匹配的下一条内容 Ctrl + g 跳转到与查找栏中搜索字词相匹配的上一条内容 Ctrl + Shift + g 打开”开发者工具” Ctrl + Shift + j 或 F12 打开”清除浏览数据”选项 Ctrl + Shift + Delete 在新标签页中打开 Chrome 帮助中心 F1 使用其他帐户登录或进入隐身模式 Ctrl + Shift + m 打开反馈表单 Ctrl + Shift + i 地址栏快捷键 操作 快捷键 使用默认搜索引擎进行搜索 输入搜索字词并按 Enter 键 使用其他搜索引擎进行搜索 输入搜索引擎名称并按 Tab 键 为网站名称添加 www. 和 .com，并在当前标签页中打开该网站 输入网站名称并按 Ctrl + Enter 键 为网站名称添加 www. 和 .com，并在新标签页中打开该网站 输入网站名称并按 Alt + Enter 键 跳转到地址栏 Ctrl + l、Alt + d 或 F6 从页面中的任意位置搜索 Ctrl + k 或 Ctrl + e 网页快捷键 操作 快捷键 打开选项以打印当前网页 Ctrl + p 打开选项以保存当前网页 Ctrl + s 重新加载当前网页 F5 或 Ctrl + r 重新加载当前网页（忽略缓存的内容） Shift + F5 或 Ctrl + Shift + r 停止加载网页 Esc 浏览下一个可点击项 Tab 浏览上一个可点击项 Shift + Tab 使用 Chrome 打开计算机中的文件 按住 Ctrl + o 键并选择文件 显示当前网页的 HTML 源代码（不可修改） Ctrl + u 将当前网页保存为书签 Ctrl + d 将所有打开的标签页以书签的形式保存在新文件夹中 Ctrl + Shift + d 开启或关闭全屏模式 F11 放大网页上的所有内容 Ctrl 和 + 缩小网页上的所有内容 Ctrl 和 - 将网页上的所有内容恢复到默认大小 Ctrl + 0 向下滚动网页，一次一个屏幕 空格键或 PgDn 向上滚动网页，一次一个屏幕 Shift + 空格键或 PgUp 转到网页顶部 首页 转到网页底部 末尾 在网页上水平滚动 按住 Shift 键并滚动鼠标滚轮 将光标移到文本字段中的上一个字词前面 Ctrl + 向左箭头键 将光标移到文本字段中的上一个字词后面 Ctrl + 向右箭头键 删除文本字段中的上一个字词 Ctrl + Backspace 将焦点移到通知上 Alt + n 在通知中允许 Alt + Shift + a 在通知中拒绝 Alt + Shift + d 在当前标签页中打开主页 Alt + Home 网页快捷键 操作 快捷键 在当前标签页中打开链接（仅限鼠标） 将链接拖到标签页中 在新的后台标签页中打开链接 按住 Ctrl 键的同时点击链接 打开链接，并跳转到该链接 按住 Ctrl + Shift 键的同时点击链接 打开链接，并跳转到该链接（仅使用鼠标） 将链接拖到标签栏的空白区域 在新窗口中打开链接 按住 Shift 键的同时点击链接 在新窗口中打开标签页（仅使用鼠标） 将标签页拖出标签栏 将标签页移至当前窗口（仅限鼠标） 将标签页拖到现有窗口中 将标签页移回其原始位置 拖动标签页的同时按 Esc 将当前网页保存为书签 将相应网址拖动到书签栏中 下载链接目标 按住 Alt 键的同时点击链接 显示浏览记录 右键点击”后退”箭头 返回 或”前进”箭头 下一个，或者点击并按住”后退”箭头 返回 或”前进”箭头 下一个 最大化或最小化窗口 双击标签栏的空白区域 放大网页上的所有内容 按住 Ctrl 键的同时向上滚动鼠标滚轮 缩小网页上的所有内容 按住 Ctrl 键的同时向下滚动鼠标滚轮 Mac 系统标签页和窗口快捷键 操作 快捷键 打开新窗口 ⌘ + n 在无痕模式下打开新窗口 ⌘ + Shift + n 打开新的标签页，并跳转到该标签页 ⌘ + t 重新打开最后关闭的标签页，并跳转到该标签页 ⌘ + Shift + t 跳转到下一个打开的标签页 ⌘ + Option + 向右箭头键 跳转到上一个打开的标签页 ⌘ + Option + 向左箭头键 跳转到特定标签页 ⌘ + 1 到 ⌘ + 8 跳转到最后一个标签页 ⌘ + 9 打开当前标签页浏览记录中记录的上一个页面 ⌘ + [ 或 ⌘ + 向左箭头键 打开当前标签页浏览记录中记录的下一个页面 ⌘ + ] 或 ⌘ + 向右箭头键 关闭当前标签页或弹出式窗口 ⌘ + w 关闭当前窗口 ⌘ + Shift + w 最小化窗口 ⌘ + m 隐藏 Google Chrome ⌘ + h 退出 Google Chrome ⌘ + q Google Chrome 功能快捷键 操作 快捷键 显示或隐藏书签栏 ⌘ + Shift + b 打开书签管理器 ⌘ + Option + b 在新标签页中打开”设置”页 ⌘ + , 在新标签页中打开”历史记录”页 ⌘ + y 在新标签页中打开”下载内容”页 ⌘ + Shift + j 打开查找栏搜索当前网页 ⌘ + f 跳转到与查找栏中搜索字词相匹配的下一条内容 ⌘ + g 跳转到与查找栏中搜索字词相匹配的上一条内容 ⌘ + Shift + g 打开查找栏后，搜索选定文本 ⌘ + e 打开”开发者工具” ⌘ + Option + i 打开”清除浏览数据”选项 ⌘ + Shift + Delete 使用其他帐号登录或以访客身份浏览 ⌘ + Shift + m 地址栏快捷键 操作 快捷键 使用默认搜索引擎进行搜索 输入搜索字词并按 Enter 键 使用其他搜索引擎进行搜索 输入搜索引擎名称并按 Tab 键 为网站名称添加 www. 和 .com，并在当前标签页中打开该网站 输入网站名称并按 Control + Enter 键 为网站名称添加 www. 和 .com，并在新标签页中打开该网站 输入网站名称并按 Control + Shift + Enter 键 在新的后台标签页中打开网站 输入网址并按 ⌘ + Enter 键 跳转到地址栏 ⌘ + l 从地址栏中移除联想查询内容 按向下箭头键以突出显示相应内容，然后按 Shift + fn + Delete 网页快捷键 操作 快捷键 打开选项以打印当前网页 ⌘ + p 打开选项以保存当前网页 ⌘ + s 打开”页面设置”对话框 ⌘ + Option + p 通过电子邮件发送当前网页 ⌘ + Shift + i 重新加载当前网页 ⌘ + r 重新加载当前网页（忽略缓存的内容） ⌘ + Shift + r 停止加载网页 Esc 浏览下一个可点击项 Tab 浏览上一个可点击项 Shift + Tab 使用 Google Chrome 打开计算机中的文件 按住 ⌘ + o 键并选择文件 显示当前网页的 HTML 源代码（不可修改） ⌘ + Option + u 打开 JavaScript 控制台 ⌘ + Option + j 将当前网页保存为书签 ⌘ + d 将所有打开的标签页以书签的形式保存在新文件夹中 ⌘ + Shift + d 开启或关闭全屏模式 ⌘ + Ctrl + f 放大网页上的所有内容 ⌘ 和 + 缩小网页上的所有内容 ⌘ 和 - 将网页上的所有内容恢复到默认大小 ⌘ + 0 向下滚动网页，一次一个屏幕 空格键 向上滚动网页，一次一个屏幕 Shift + 空格键 搜索网络 ⌘ + Option + f 将光标移到文本字段中的上一个字词前面 Option + 向左箭头键 将光标移到文本字段中的上一个字词后面 Option + 向右箭头键 删除文本字段中的上一个字词 Option + Delete 在当前标签页中打开主页 ⌘ + Shift + h 鼠标快捷键 操作 快捷键 在当前标签页中打开链接（仅限鼠标） 将链接拖到标签页中 在新的后台标签页中打开链接 按住 ⌘ 键的同时点击链接 打开链接，并跳转到该链接 按住 ⌘ + Shift 键的同时点击链接 打开链接，并跳转到该链接（仅使用鼠标） 将链接拖到标签栏的空白区域 在新窗口中打开链接 按住 Shift 键的同时点击链接 在新窗口中打开标签页（仅使用鼠标） 将标签页拖出标签栏 将标签页移至当前窗口（仅限鼠标） 将标签页拖到现有窗口中 将标签页移回其原始位置 拖动标签页的同时按 Esc 将当前网页保存为书签 将相应网址拖动到书签栏中 下载链接目标 按住 Option 键的同时点击链接 显示浏览记录 右键点击”后退”箭头 或”前进”箭头 ，或者左键点击（并按住鼠标左键不放）”后退”箭头 或”前进”箭头 将窗口高度最大化 双击标签栏的空白区域","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"VSCode快捷键","slug":"VsCode_ShotCut","date":"2020-06-16T02:51:59.000Z","updated":"2020-07-04T17:17:58.456Z","comments":true,"path":"2020/06/16/VsCode_ShotCut/","link":"","permalink":"http://ymlog.cn/2020/06/16/VsCode_ShotCut/","excerpt":"念两句诗醉漾轻舟，信bai流引到花深处。尘缘du相误，无计花间住。烟水茫茫，千里斜阳暮。山无数，乱红如雨，不记来时路。","text":"念两句诗醉漾轻舟，信bai流引到花深处。尘缘du相误，无计花间住。烟水茫茫，千里斜阳暮。山无数，乱红如雨，不记来时路。 常用的几个 shortcut info Ctrl+Shift+K 删除当前行 Ctrl+L 选中当前行 Ctrl+letf, Ctrl+Right 逐个单词跳转 Ctrl+B 打开左侧页面 Ctrl+J 打开终端 Ctrl+F 搜索 Ctrl+D 查找当下字符，可以跳转 Fn+Up , Fn+Down 翻半页 Ctrl+Backspace 删除一个单词 Shift + Alt +Down 复制一行 Ctrl+],Ctrl+[ 缩进tab和退缩进 Ctrl+Shift+W 关闭编辑器 Ctrl+W 关闭当前编辑文本 Ctrl + Enter 在当前行下插入新的一行 Ctrl+Shift+| 匹配括号跳转 Ctrl + up/down 行视图上下偏移 Ctrl + P 跳转文件 Alt + Click 插入光标-支持多个 Ctrl + =/- 放大 / 缩小 Ctrl + Shift + V 复制到当前激活的终端 Ctrl + ` 打开集成终端 Ctrl + Shift + ` 创建一个新的终端 为tab设置颜色 安装Material Theme插件 Ctrl+Shift+P，选择Material Theme：set accent color 选择喜欢颜色 查看运行插件 Ctrl+Shift+P ； 输入show running extensions查看所有运行插件 更多快捷键：https://blog.csdn.net/crper/article/details/54099319","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"KVM实例总结","slug":"KVM_Initial","date":"2020-06-04T09:19:51.000Z","updated":"2020-07-04T17:19:21.421Z","comments":true,"path":"2020/06/04/KVM_Initial/","link":"","permalink":"http://ymlog.cn/2020/06/04/KVM_Initial/","excerpt":"念两句诗大雨落幽燕，白浪滔天，秦皇岛外打鱼船，一片汪洋都不见。知向谁边？往事越千年，魏武挥鞭，东临碣石有遗篇。萧瑟秋风今又是，换了人间。","text":"念两句诗大雨落幽燕，白浪滔天，秦皇岛外打鱼船，一片汪洋都不见。知向谁边？往事越千年，魏武挥鞭，东临碣石有遗篇。萧瑟秋风今又是，换了人间。 大纲kvm创建虚拟机的根本在于这样一条命令，virsh define vm-template.xml，这条命令的核心就是创建一个虚拟机，之后或者之前的内容都是围绕着这条命令和这个虚拟机的。 更新vm-templatem模板是为了进行子机资源配置 在更新模板之前检查时主机是为了防止给子机过量的资源导致母机不稳定 桥接网卡是为了让子机连接局域网 所以，virsh define vm-template.xml 其本质是在安全可靠的前提下，将母机的资源通过kvm虚拟化的形式分配给子机。 所以主要考虑方向有两个 1、保障母机和子机的安全可靠，包括系统安全和网络安全 2、进行资源分配，包括网络资源、存储资源、计算资源等 该脚本考虑了母机分配资源不会超过母机承受范围的资源安全，其他系统层面和网络层面的安全问题还需考虑 命令- 1、sed - 替换注释 sed -i \"s/^IPADDR/#&amp;/\" file- 字段追加 sed -i \"/DEVICE/a\\BRIDGE='br0'\" file- 指定行插入 sed -i \"4iContent\" file- 注意\"\" 和''的区别，在使用变量时可以加\\转义字符- 2、cat - cat &lt;&lt; EOF &gt; file ，这里的变量需要转义字符\\,且EOF不能使用双引号\"EOF\",否则变量会消失- 3、expect- expect执行顺序容易错乱- expect \"~\" &#123; send \"umount /share \\r\" &#125; ：常用expect方法- 如果执行expect需要等待很长时间，可以把timeout设置为-1- expect脚本执行时，不能使用sh script.sh 这样相当于用shell的解释器执行，可以采用./script $args- 4、while- while read a b c d e;do ....; done &lt; file，用于读取类似格式为 192.168.1.1 255.255.255.0 C 之类的文本，读取之后 a b c d e 均为file中对应的变量- 5、echo- 注意echo颜色的使用，红色闪烁和绿色健康：-e \"\\033[31m\\033[01m\\033[05m[ err ]\\033[0m\" \"\\033[32m [ OK ] \\033[0m\"- 6、bc- shell中浮点数和整数、浮点数和浮点数不能直接比较大小，可以使用bc工具- echo \"1.1 &gt; 1\" | bc 正确为1 错误为0 过程完成过程 - 1|主机检查-（磁盘、CPU、内存） 写了自动检查&amp;手动检查[0] - 2|网卡桥接，创建一个br0作为网桥，连接eth1和kvm虚拟机 - 3|安装软件，执行tlinux*.run - 4|重启母机 - 5|主机通信[1] - 6|创建子机磁盘，包括系统盘、数据盘、共享盘 - 6|配置模板，包括调整CPU个数、内存大小、vlanid、网卡、uuid、mac地址、子机名称 - 7|使用6中的模板创建子机[2] - 8|登录子机[3] - 9|执行脚本，只要expect程序不错，这里基本不会错[4][0]刚开始考虑当母机资源超过一定比例则程序退出，比如磁盘使用超过2/3，后来觉得这样不够灵活，改用百分比，默认50%在设置百分比的时候有几点小问题1、浮点数运算保留小数 使用scale可以准确保留小数，echo \"scale=2;62/3\" | bc 结果 20.66 使用printf可以保留小数位，补零填充 printf %.2f 结果20.002、浮点数运算不保留小数 echo \"123.123\"|sed \"s/\\..*//g\" *代表0到多个，所以第一个命令中\\.*只能替换掉小数点变成空 \\..*代表了小数点之后的1到多个3、除法 echo \"2 / 3\" | bc 这个结果会显示为0 echo \"scale=2 ;2 / 3\" | bc 这个结果会显示为.66 printf \"%.2f\" `echo \"scale=2;2/3\" | bc` 这个结果会显示为0.66[1]刚开始的时候选择将subvm_configuration.sh这个脚本cat进内存，然后用expect登录到子机的时候echo到文件，然后执行。后来发现expect输出的时候会把subvm_configuration.sh脚本里的内容先执行一遍，而且还存在其他一些问题，比如说echo到文件的时候残缺不全、不换行、文件为空等。后来采用磁盘共享的方式，在宿主机上创建一块磁盘，然后挂载到/tmp/share/这个目录，再将subvm_configuration.sh脚本和ipinfo配置文件复制到该目录，之后在子机的XML文件中添加一块disk(vdc)，登录进子机后，挂载vdc，此时就可以看到母机上/tmp/share/下的内容了。直接执行脚本即可。磁盘共享也有一个缺点，就是文件内容不能实时刷新，比如在母机上改了ipinfo，只有子机重启后，子机上的ipinfo才可以刷新，鉴于/tmp/share/这个目录每个子机一生只有一次用到，所以这个问题暂时不需要解决。[2]创建子机1、if ( vlanid != 0 &amp;&amp; xenbrx not in `brctl show` ) 会报错网卡未找到导致虚拟机启动失败2、vm-template模板不正确，包括&lt;emulator&gt;/usr/local/bin/qemu-system-x86_64&lt;/emulator&gt;路径不正确，会导致虚拟机无法启动3、disk的slot卡槽相同会导致虚拟机无法启动4、需要注意的是，virsh define vm-template 这条命令的执行路径是/usr/local/etc/libvirt/qemu/vm-template，最后会在/usr/local/etc/libvirt/qemu/下生成vm$ipfmt.xml的配置文件。[3]expect会有很多问题1、命令不按顺序执行2、传入的变量为空，且传入的变量下标是从0开始的；shell传入变量下标从1开始，0代表自身文件3、set timeout $time 设置的时间不一定准确，设置了300秒延时，但未到300s，程序还是退出了，可以考虑直接设置 timeout 为-14、expect有多种写法，有expect &lt;&lt; EOF ; expect eof ; 最正常的是上面用的5、expect文件用的解释器是/usr/bin/expect，这里将login.sh使用cat写在了单独的文件中[4]1、subvm_configuration.sh配置了两张网卡，格式化vdb数据盘，配置ssh2、eth0为连接外网的网卡，使用tunnel，eth1为内网网卡，使用vlanxenbrX为隧道入口，母机收到从xenbr361口收到的报文，就发给另一端隧道，从而实现连接外网tunnel network ---- host(default router: subhost -&gt; netowrk , throught interface &amp; sh vlan.sh ) ---- subhost母机收到vlan的报文，就在指定vlan的广播域内进行路由（不一定是母机进行路由）vlan network ---- host(broadcast router: subhost ---&gt; broadcast/vlanid throught 802.1Q ) ---- subhost [*]expect合理用法 cat &lt;&lt; EOF &gt; $&#123;workdir&#125;/login.sh#!/usr/bin/expectif &#123; \\$argc &lt; 1&#125; &#123;puts \"Usage:cmd &lt;host&gt;\"exit 1&#125;set timeout -1set host [lindex \\$argv 0]spawn virsh console \\$hostexpect \"*Escape*\" &#123; send \"\\r\" &#125;expect \"*login*\" &#123; send \"root\\r\" &#125;expect \"*Password*\" &#123; send \"xxxx\\r\" &#125;interactEOF 高效的while while read equipmentName ip netmask;do echo \"=====================$&#123;equipmentName&#125;==================\" echo \"inner_ip:$&#123;ip&#125;\" echo \"inner_netmask:$&#123;netmask&#125;\"done &lt; file","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://ymlog.cn/tags/KVM/"}]},{"title":"WebSocket","slug":"WebSocket","date":"2020-05-03T11:28:35.000Z","updated":"2020-07-04T17:17:48.944Z","comments":true,"path":"2020/05/03/WebSocket/","link":"","permalink":"http://ymlog.cn/2020/05/03/WebSocket/","excerpt":"念两句诗忆昔午桥桥上饮，坐中多是豪英。长沟流月去无声，杏花疏影里，吹笛到天明。 二十馀年成一梦，此身虽在堪惊。闲登小阁看新晴，古今多少事，渔唱起三更。","text":"念两句诗忆昔午桥桥上饮，坐中多是豪英。长沟流月去无声，杏花疏影里，吹笛到天明。 二十馀年成一梦，此身虽在堪惊。闲登小阁看新晴，古今多少事，渔唱起三更。 WS介绍HTTP 超文本传输协议(HTTP,HypertextTransferProtocol)是互联网上应用最为广泛的一种网络协议。是用于从WWW服务器传输超文本到本地浏览器的传送协议。 Web通讯 WebSocket WebSocket Protocal是HTML5一种新的协议，它实现了浏览器与服务器全双工通信（full-duple），一开始握手需要借助http请求完成。 HTTP请求是无状态的，每一次收发数据都需要建立连接。WebSocket不需要建立连接就可以收发数据。 WebSocket对象提供一组API，用于创建和管理WebSocket连接，以及通过连接发送和接受数据。 创建WebSocket对象var ws = new WebSocket(url,[protocals]);url: 表示要连接的URL，这个URL应该为响应WebSocket的地址protocals:可以是单个的协议名字字符串或者包含多个协议名字字符串的数组 方法 close([code][,reason]) 关闭websocket连接或停止正在进行的连接请求code: 一个数字表示关闭连接的状态号，表示连接关闭的原因reason: 一个可读字符串，表示连接被关闭的原因send(data) 通过websocket连接，向服务器发送数据data: 一个数字值表示关闭连接的状态号，表示连接被关闭的原因 属性 名词 解释 onclose 用于监听连接关闭事件监听器。当WebSocket对象的ReadyState状态变为CLOSED时，会触发该事件。会接受一个close event对象 onerror 当错误发生时，用于监听error事件的事件监听器，会接受一个error event对象 onmessage 一个用于消息事件的事件监听器，这一事件当有消息到达的时候该事件会触发。会接受一个message event对象 onopen 一个用于连接打开事件的事件监听器，当readyState的值变为OPEN的时候会触发该事件，会接受一个open event对象 readyState 连接的当前状态 0 连接还没开启 1 连接已经开启并准备好进行通信 2 连接正在关闭的过程中 3 连接已经关闭，或者连接无法建立 简易的WSnpm安装websocket npm install websocket 后端页面 var WebSocketServer = require('websocket').server;var http = require('http');//创建服务器var server = http.createServer(function(request, response) &#123; console.log((new Date()) + ' Received request for ' + request.url); response.writeHead(404); response.end();&#125;);// 监听8080端口server.listen(3000, function() &#123; console.log((new Date()) + ' Server is listening on port 8080');&#125;); // 创建websocket服务器wsServer = new WebSocketServer(&#123; httpServer: server, autoAcceptConnections: false&#125;); //websocket建立连接wsServer.on('request', function(request) &#123; //当前的连接 var connection = request.accept(null, request.origin); console.log((new Date()) + ' Connection accepted.'); //定时向客户端发送消息 setInterval(function()&#123; connection.sendUTF(\"服务端发送新消息\"+(new Date())) &#125;,1000) // 监听当前连接，发送message的时候 connection.on('message', function(message) &#123; if (message.type === 'utf8') &#123; console.log('Received Message: ' + message.utf8Data); connection.sendUTF(message.utf8Data); &#125; else if (message.type === 'binary') &#123; console.log('Received Binary Message of ' + message.binaryData.length + ' bytes'); connection.sendBytes(message.binaryData); &#125; &#125;); // 监听当前连接，当close的时候出发事件 connection.on('close', function(reasonCode, description) &#123; console.log((new Date()) + ' Peer ' + connection.remoteAddress + ' disconnected.'); &#125;);&#125;); 前端页面 &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Websocket前端页面&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; // 创建websocket对象 var ws = new WebSocket(\"ws://localhost:3000\"); // 监听建立连接 ws.onopen = function(res)&#123; console.log(\"连接成功！\"); console.log(res); &#125; //监听有新消息 ws.onmessage = function(res)&#123; console.log(\"有新消息！\"); console.log(res); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 页面效果 多人通讯后端 var http = require(\"http\")// 引入websocket模块var WebSocketServer = require('websocket').server//存储所有终端连接var clients = [];// 引入http模块，搭建http服务器var server = http.createServer()// server.listen(3000, ()=&gt; &#123;// console.log(\"服务器搭建成功！,监听localhost:3000\")// &#125;)server.listen(3000,\"0.0.0.0\",function()&#123; console.log(\"服务器创建成功\")&#125;)// 创建websocket服务对象var wsServer = new WebSocketServer(&#123;httpServer:server&#125;);// 监听连接请求，建立连接// webSocketRequest 当前连接建立的请求wsServer.on('request',function(webSocketRequest)&#123; console.log(\"建立连接\") // 当前连接 会话 var connection = webSocketRequest.accept(null, 'accepted-origin') //把连接添加到终端 clients.push(connection) // 当客户端发来信息的时候 ,判断信息的两种类型 // For Text Frames: // &#123; // type: \"utf8\", // utf8Data: \"A string containing the received message.\" // &#125; // // For Binary Frames: // &#123; // type: \"binary\", // binaryData: binaryDataBuffer // a Buffer object containing the binary message payload // &#125; connection.on(\"message\",function(msg)&#123; // 如果是文本类型，则给每一个当前的连接都发送一遍 if(msg.type == \"utf8\")&#123; console.log(\"遍历用户，发送数据....\"+msg.utf8Data) // 遍历连接数组，给每一个连接发送数据 clients.forEach(function(item)&#123; //发送数据 item.sendUTF(msg.utf8Data) &#125;) &#125; else &#123; console.log(msg) &#125; &#125;) // 当连接断开的时候 , 触发事件 connection.on(\"close\",function(reasonCode,description)&#123; console.log(\"断开连接\") // 获取当前索引，根据索引删除连接 var index = clients.indexOf(connection) // 删除 clients.splice(index,1) &#125;) &#125;) 前端 &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;多终端通信&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;ul id=\"content\"&gt; &lt;/ul&gt; &lt;input type=\"text\" id=\"msg\"&gt; &lt;button onclick=\"send()\"&gt;SEND&lt;/button&gt; &lt;script&gt; var ws = new WebSocket(\"ws://localhost:3000\"); var inputNode = document.getElementById(\"msg\") var ulCon = document.getElementById(\"content\") function send()&#123; // 将用户输入发送给服务端 ws.send(inputNode.value) &#125; ws.onopen = function(res)&#123; console.log(\"连接成功！\"); &#125; ws.onmessage=function(msg)&#123; // 接受服务端传来的数据 // 这里不是msg.value，因为这里的msg是websocket的msg，不是id=msg的意思 console.log(\"MSG.value:\"+msg.data) content.innerHTML+='&lt;li&gt;'+msg.data+'&lt;/li&gt;' &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"http://ymlog.cn/tags/WebSocket/"}]},{"title":"NodeJS（一） 静态路由","slug":"NodeJS_1","date":"2020-04-29T11:57:22.000Z","updated":"2020-07-04T17:18:54.594Z","comments":true,"path":"2020/04/29/NodeJS_1/","link":"","permalink":"http://ymlog.cn/2020/04/29/NodeJS_1/","excerpt":"念两句诗黄金榜上，偶失龙头望。明代暂遗贤，如何向。未遂风云便，争不恣游狂荡。何须论得丧？才子词人，自是白衣卿相。","text":"念两句诗黄金榜上，偶失龙头望。明代暂遗贤，如何向。未遂风云便，争不恣游狂荡。何须论得丧？才子词人，自是白衣卿相。 Nodejs简介​ V8引擎本身是用于Chrome浏览器的JS解释部分，但是Ryan Dahl将其搬到了服务器上，用于做服务器。 ​ 浏览器和服务器类似，浏览器是发送HTTP请求，接受HTTP响应，服务器也是接受HTTP请求，发送HTTP响应。都已HTML的方式实现。 ​ Nodejs是一个让Javascript运行在服务器端的开发平台，它让Javascript的触角伸到了服务器端，可以和PHP、JSP、Python、Ruby平起平坐。 不同之处： Nodejs不是一种独立的语言，与PHP、JSP、Python的“既是语言，也是平台不同，Nodejs的使用Javascript进行编程，运行在Javascript引擎上（V8） 与PHP、JSP相比，Nodejs跳过了Apache、Nginx、IIS等HTTP服务器，自己不用建设在任何服务器软件之上。 Nodejs特点 单线程 非阻塞IO 事件驱动 1、单线程 在java、php等服务器端语言中，会为每个客户连接创建一个新的线程，每个线程耗费大约2MB的内存，理论上，一个8G内存的服务器可以同时连接的最大用户数为4000个。 Nodejs不为每个客户连接创建一个新的线程，而仅仅使用一个线程。当有用户连接了，就触发一个内部时间，通过非阻塞I/O、事件驱动机制，让Node.js程序宏观上也是并行的。使用Nodejs，一个8G的服务器可以同时处理超过4万用户的连接 另外，单线程带来的好处，还有操作系统完全不再有创建线程，销毁线程带来的时间开销。 但是，一个用户造成的线程崩溃，其他服务也就崩溃了。 2、非阻塞I/O（non-blocking IO） 例如，当在访问数据库取得数据的时候，需要一段时间。在传统的单线程处理机制中，在执行了访问数据库代码之后，整个线程都将暂停下来，等待数据库返回结果，才能执行后面的代码。也就是说，I/O阻塞了代码的执行，极大的降低了程序的执行效率。 由于Nodejs采用了非阻塞I/O机制，因此在执行访问数据库代码之后，将立即转而执行后面的代码，把数据库返回结果的处理代码放在回调函数中，从而提高了程序执行效率。 当某个I/O执行完毕时，将以事件的形式同之I/O操作的线程，线程执行这个事件的回调函数，为了处理异步I/O，线程必须有事件循环，不断的检查有没有未处理的事件。 阻塞模式下，一个线程只能处理一项任务，想要提高吞吐量必须通过多线程，而非阻塞模式下，一个线程永远在执行计算操作，这个线程的CPU核心利用率永远是100%。 3、事件驱动（event-driven） 在Node中，客户端请求建立连接，提交数据等行为，会触发相应的事件，在Node中，一个时刻只能执行一个事件回调函数，但是在执行一个事件回调函数的中途，可以转而处理其他事件（比如又有新用户连接），然后返回据徐执行原事件的回调函数，这种处理机制，称为”时间环“ Nodejs底层时C++，底层代码中，近半数都是用于事件队列、回调函数队列的构建。 Nodejs适合做什么？​ 善于I/O，不善于计算。因为Nodejs最擅长的就是任务调度，如果你的业务有很多CPU计算，实际上也相当于计算阻塞了这个单线程。 ​ 当应用程序需要处理大量并发I/O，而向客户端发出响应之前，应用程序内部不需要进行复杂处理的时候，Nodejs非常合适。Nodejs也非常合适与web socket配合，开发长连接（长连接实际上是通过大量请求模拟长连接）的实时交互应用程序。 比如 用户表单收集 考试系统 聊天室 图文直播 提供JSON的API Nodejs本身就是极客追求性能极致的产物，缺少了服务器的健壮考量。所以Node不可能应用在极高可靠性的业务中。 Hello Node//require表示导包var http = require(\"http\");//创建服务器，参数是一个回调函数，表示如果有什么请求进来，要做什么var server = http.createServer(function (req,res) &#123; // req表示请求，request；res表示响应，response // 设置HTTP头部，状态码200，文件类型html，字符集utf8 res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF-8\"&#125;); res.end(\"Hello NodeJS\"); &#125;)//运行服务器，监听3000端口，任何地址都可以访问 server.listen(3000,\"0.0.0.0\"); NodeJS是服务器语句，写的js语句都将运行在服务器上，返回给客户的，都是已经处理好的纯HTML。如果想修改程序，必须中断当前程序，然后重新启动node，不支持热部署。 Nodejs路由Node.JS没有根目录，因为它没有web容器的概念。 先写一个静态的H5页面： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;style&gt; .app&#123; background-color: red; &#125; &lt;/style&gt; &lt;title&gt;Nodejs读取文件&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=\"app\"&gt;这是一个测试文件&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 效果大概是这样： 使用req.url判断输入的路径 使用fs.readFile()读取网页页面 使用res.end()返回数据 然后写staticRender.js文件 var http = require(\"http\");var fs = require(\"fs\");var server = http.createServer(function (req,res) &#123; if(req.url == \"/red\")&#123; // 输入路由和源文件没有关系 fs.readFile(\"./red.html\",function(err,data)&#123; res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF-8\"&#125;); res.end(data); &#125;); &#125; else if(req.url == \"/blue\")&#123; fs.readFile(\"./blue.html\",function(err,data)&#123; res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF-8\"&#125;); res.end(data); &#125;); &#125; else&#123; res.writeHead(404,&#123;\"Content-type\":\"text/html;charset=UTF-8\"&#125;); res.end(\"没有这个页面\"); &#125; &#125;); server.listen(3000,\"0.0.0.0\"); NodeJS任何静态页面都需要路由，比如在HTML中插入一个image或者css样式，也需要设置一条路由。Nodejs擅长做顶层路由设计。 模块Nodejs中，讲很多的功能划分为了一个个module。 HTTP模块//引用模块var http = require(\"http\");var server = http.createServer(function (req,res) &#123; //req参数表示请求，res表示响应 console.log(\"服务器接收到了请求\"+req.url); //告诉浏览器连接终止 res.end(); //end中必须是字符串或者缓冲区 &#125;); server.listen(3000,\"0.0.0.0\"); 向请求发送响应头，此方法只能在消息上调用一次，并且必须在调用 response.end() 之前调用。 res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF-8\"&#125;); req的属性，最关键的就是req.url属性，表示用户请求的URL地址，所有路由设计，都是通过req.url来实现的，我们比较关心的不是拿到URL，而是识别这个URL。 识别URL用到两个模块，一个是url模块，另一个是querystring模块。 url用于解析url，这样就可以不用正则表达式了 http://nodejs.cn/api/url.html#url_url_strings_and_url_objects var url = require(\"url\");//url.parse()可以将一个完整的URL地址分为很多部分myURL=url.parse('https://user:pass@sub.host.com:8080/p/a/t/h?query=string#hash');console.log(myURL.host); // url.host 获取及设置 URL 的主机部分。 // url.hostname 获取及设置 URL 的主机名部分。 url.host 和 url.hostname 之间的区别是 url.hostname 不包含端口。 // url.password 获取及设置 URL 的密码部分。 // url.pathname 获取及设置 URL 的路径部分。 // url.port 获取及设置 URL 的端口部分。 // url.protocol 获取及设置 URL 的协议部分。 // url.username 获取及设置 URL 的用户名部分。 // url.query 获取及设置URL的查询部分 &amp;name=jack&amp;age=18 // url.parse(req.url,true).query = &gt; // [Object: null prototype] &#123; name: 'jack', age: '18' &#125; // [Object: null prototype] &#123; name: 'jack', age: '18' &#125;url.parse('url',true); //如果第二个参数是true，那么就可以把所有的查询变为对象 ， 就可以直接打点得到这个参数。 表单提交案例： &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;表单提交&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"http://127.0.0.1:3000\" method=\"GET\"&gt; &lt;input type=\"text\" name=\"name\"/&gt; &lt;br&gt; &lt;input type=\"text\" name=\"age\"/&gt; &lt;br&gt; &lt;input type=\"radio\" name=\"sex\" value=\"男\"/&gt;男 &lt;input type=\"radio\" name=\"sex\" value=\"女\"/&gt;女&lt;br&gt; &lt;input type=\"submit\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 提交到浏览器的结果为： http://127.0.0.1:3000/?name=杜振铨&amp;age=21&amp;sex=男 然后在Nodejs服务端用url解析出来 var http = require(\"http\");var url = require(\"url\");http.createServer(function (req,res) &#123; myURL=url.parse(req.url,true); var info = \"服务器收到了 - 姓名：\"+myURL.query.name + \"性别：\"+myURL.query.sex + \"年龄：\"+myURL.query.age; // 这里要用UTF8不然中文乱码 res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); res.end(info); &#125;).listen(3000,\"0.0.0.0\"); 最后在网页上呈现这样的效果： 服务器收到了 - 姓名：杜振铨 性别：男 年龄：21 简单的路由演示： var http = require(\"http\");var server = http.createServer(function(req,res)&#123; // http://127.0.0.1:3000/teacher/122456 //提取出url,为/teacher/123456 var myurl = req.url; console.log(myurl); res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); //比较前9位 [0,9) if(myurl.substr(0,9) == \"/teacher/\")&#123; //取出从第九位开始往后的,这里就是123456 tearcherid = myurl.substr(9); //看取出来的id是否满足6位数字,不满足则返回不存在,学生栏也一样 if(/^\\d&#123;6&#125;$/.test(tearcherid))&#123; res.end(\"您要查询的老师信息为 id:\"+tearcherid); &#125;else&#123; res.end(\"您访问的老师不存在!\"); &#125; &#125; else if(myurl.substr(0,9) == \"/student/\")&#123; var studentid = myurl.substr(9); if(/^\\d&#123;10&#125;$/.test(studentid))&#123; res.end(\"您要查询的学生信息为 id:\"+studentid); &#125;else&#123; res.end(\"您访问的学生不存在!\"); &#125; &#125; else&#123; res.end(\"您访问的人员不存在!\"); &#125;&#125;);server.listen(3000,\"0.0.0.0\"); fs readFile读取文件 mkdir 新建文件夹 rmdir 移除文件夹 fs.Stats 查看文件属性 stats.isBlockDevice() stats.isCharacterDevice() stats.isDirectory() stats.isFIFO() stats.isFile() stats.isSocket() …. 读取文件 // 三个参数,第一个是完整的路径,当前目录写./ // 第二个参数是字符集,也可以不设置 // 第三个参数是回调函数,表示文件读取成功后,做的事 fs.readFile(\"./demo.txt\",&#123;\"charset\":\"utf-8\"&#125;,function (err,data) &#123; // 抛异常 if(err)&#123; throw err; &#125; console.log(userid+\"文件读取完毕!\"); res.end(data); &#125;); 利用读取文件，验证事件环，即NodeJS的单进程异步非阻塞事件驱动模型。 var http = require(\"http\");var fs = require(\"fs\");var server = http.createServer(function(req,res)&#123; var userid = parseInt(Math.random() * 10000); console.log(userid); res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); fs.readFile(\"./demo.txt\",&#123;\"charset\":\"utf-8\"&#125;,function (err,data) &#123; console.log(userid+\"文件读取完毕!\"); res.end(data); &#125;);&#125;);server.listen(3000,\"0.0.0.0\"); 通过访问 http://127.0.0.1:3000 我们可以看到如下 54355435文件读取完毕! 现在我们模拟1000并发 import requestsfrom threading import Threadurl = \"http://127.0.0.1:3000\"def req(): response = requests.get(url) print(response.status_code)l = []for i in range(10000): t = Thread(target=req,) t.start() l.append(t)[ i.join() for i in l]print(\"完成!\") 然后就可以看到 618299976182文件读取完毕!9997文件读取完毕!34503450文件读取完毕! 可以发现，NodeJS在处理当前用户的时候，还会切换到另外的事件调度。 //recursive 多级目录需要递归创建 fs.mkdir(\"./ablum/niki\",&#123; recursive: true &#125;,(err) =&gt;&#123; if(err) throw err; &#125;); fs处理异步问题 由于异步性，下面的语句会在回调函数之前执行 所以console.log()已经把文件夹输出了，但事实上for循环并没有开始遍历 三层回调涉及到的方法 http.createServer()创建一个服务器 fs.readdir() 读取目录下文件和文件夹 fs.stat() 读取文件或者文件夹的状态 var http = require(\"http\");var fs = require(\"fs\");var server = http.createServer(function(req,res)&#123; if(req.url == \"/favicon.ico\")&#123; return; &#125; res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); // 定义一个变量，用来存放目录 var dirs = [] // 读取./ablum下的所有文件,包括文件和文件夹 fs.readdir(\"./ablum\",function (err,files) &#123; console.log(files.length); // 便利这些文件和文件夹,找到其中是文件夹的,将其放入dirs for(var i=0;i&lt;files.length;i++)&#123; var path = \"./ablum/\"+files[i]; fs.stat( path,function(err,stats)&#123; if(stats.isDirectory())&#123; dirs.push(path); &#125; &#125;); &#125; // 由于异步,上面的函数执行完了会立刻执行下面的函数,也就是说,上面还没开始遍历,下面已经执行了.所以这里的dirs是[]空的 console.log(dirs); &#125;); res.end(\"Success\");&#125;);server.listen(3000,\"0.0.0.0\"); 解决办法：迭代器——循环强制同步 var http = require(\"http\");var fs = require(\"fs\");var server = http.createServer(function(req,res)&#123; if(req.url == \"/favicon.ico\")&#123; return; &#125; res.writeHead(200,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); // 定义一个变量，用来存放目录 var dirs = [] // 读取./ablum下的所有文件,包括文件和文件夹 fs.readdir(\"./ablum\",function (err,files) &#123; //定义一个递归函数 function iterator(i)&#123; // 一旦下标到达数组长度,则返回 if(i == files.length)&#123; console.log(dirs); return ; &#125; var path = \"./ablum/\"+files[i]; // 判断是否为文件夹,如果是,则加入dirs fs.stat(path,function (err,stats) &#123; if(stats.isDirectory())&#123; dirs.push(path); &#125; iterator(i+1); &#125;); &#125; // 强制当前下标迭代完再迭代下一个下标 iterator(0); &#125;); res.end(\"Success\");&#125;);server.listen(3000,\"0.0.0.0\"); 静态目录 通过路径访问文件 浏览器的Content-type能读取文件正确的格式以便渲染 事先在同级目录下准备static文件，用于存放html、css、jpg等静态资源 var http = require(\"http\");var url = require(\"url\");var fs = require(\"fs\");var path = require(\"path\");http.createServer(function(req,res)&#123; //得到用户的路径 var pathname = url.parse(req.url).pathname; //默认首页 if(pathname == \"/\")&#123; pathname = \"index.html\"; &#125; //拓展名 var extname = path.extname(pathname); //真的读取这个文件 fs.readFile(\"./static/\" + pathname,function(err,data)&#123; if(err)&#123; //如果此文件不存在，就应该用404返回 fs.readFile(\"./static/404.html\",function(err,data)&#123; res.writeHead(404,&#123;\"Content-type\":\"text/html;charset=UTF8\"&#125;); res.end(data); &#125;); return; &#125;; //MIME类型，就是 //网页文件： text/html //jpg文件 : image/jpg var mime = getMime(extname); res.writeHead(200,&#123;\"Content-type\":mime&#125;); res.end(data); &#125;);&#125;).listen(3000,\"127.0.0.1\");function getMime(extname)&#123; switch(extname)&#123; case \".html\" : return \"text/html\"; break; case \".jpg\" : return \"image/jpg\"; break; case \".css\": return \"text/css\"; break; &#125;&#125;","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://ymlog.cn/tags/NodeJS/"}]},{"title":"VueJS 浅知","slug":"VueJS","date":"2020-04-26T05:43:51.000Z","updated":"2020-07-04T17:17:54.221Z","comments":true,"path":"2020/04/26/VueJS/","link":"","permalink":"http://ymlog.cn/2020/04/26/VueJS/","excerpt":"念两句诗东城渐觉风光好，縠(hú)皱波纹迎客棹。绿杨烟外晓寒轻，红杏枝头春意闹。浮生长恨欢娱少， 肯爱千金轻一笑。 为君持酒劝斜阳，且向花间留晚照。","text":"念两句诗东城渐觉风光好，縠(hú)皱波纹迎客棹。绿杨烟外晓寒轻，红杏枝头春意闹。浮生长恨欢娱少， 肯爱千金轻一笑。 为君持酒劝斜阳，且向花间留晚照。 正文Vue 是Javascript的框架，用于简化DOM（domain obeject m）操作，响应式数据驱动。 Vue两种导入方式： &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt; &lt;!-- 生产环境版本，优化了尺寸和速度 --&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&quot;&gt;&lt;&#x2F;script&gt; 初试Vue1、 Hello World &lt;!DOCTYPE html&gt;&lt;head&gt;&lt;title&gt;Vue基础&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt; &lt;div id&#x3D;&quot;app&quot;&gt; &#123;&#123; message &#125;&#125; &lt;&#x2F;div&gt;&lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot; Hello Vue !&quot; &#125; &#125;)&lt;&#x2F;script&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 2、介绍 el是用来设置Vue实例挂载的元素 Vue会管理el选项命中的元素机器内部的后代 可以使用其他选择器，但是建议使用ID选择器 可以使用其他的双标签，不能使用HTML和Body标签 3、data：数据对象 &lt;div id&#x3D;&quot;app&quot;&gt; &#123;&#123; message &#125;&#125;&lt;&#x2F;div&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot; Hello Vue !&quot; &#125;&#125;) 4、字符、字典、数组的表示 &lt;div id&#x3D;&quot;app&quot;&gt; 字符：&#123;&#123; message &#125;&#125; &lt;br&gt; 字典：&#123;&#123; contact.phone &#125;&#125; &lt;br&gt; 数组：&#123;&#123; hobby[0] &#125;&#125; &lt;br&gt;&lt;&#x2F;div&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot; Hello Vue !&quot;, contact:&#123; phone:&quot;18151908744&quot;, email:&quot;2212585023@qq.com&quot;, &#125;, hobby:[&quot;Reading&quot;,&quot;Sleeping&quot;,&quot;JS&quot;,&quot;Watching&quot;], &#125;,&#125;) Vue指令vue指令指的是以v-开头的一组特殊语法 内容绑定，事件绑定 v-text v-html v-on 显示切换，属性绑定 v-show v-if v-bind 列表循环，表单元素绑定 v-for v-on补充 v-model 内容绑定v-text设置标签的文本值 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;h2 v-text&#x3D;&quot;message&quot;&gt;&lt;&#x2F;h2&gt;&lt;&#x2F;div&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot;Hello Vue!&quot; &#125;&#125;) v-html设置html标签 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;!-- 如果是普通文本，这里的显示结果和v-text没有任何不同 如果是HTML文本，则会渲染 --&gt; &lt;div v-html&#x3D;&quot;message&quot;&gt;&lt;&#x2F;div&gt;&lt;&#x2F;div&gt;var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; message:&quot;&lt;a href&#x3D;&#39;http:&#x2F;&#x2F;www.baidu.com&#39;&gt;Hello Vue!&lt;&#x2F;a&gt;&quot;, &#125;&#125;) v-html指令的作用是：设置元素的innerHTML 内容中有HTML结构会被解析为标签 v-text指令无论内容是什么，只会解析成文本 v-on 为元素绑定事件 事件名不需要写on 指令可以简写为@ 绑定的方法定义在methods属性中 基本结构 &lt;div&gt; &lt;input type&#x3D;&quot;button&quot; value&#x3D;&quot;事件绑定&quot; v-on:事件名&#x3D;&quot;方法&quot;&gt; &lt;&#x2F;div&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, methods:&#123; 方法名:function()&#123; &#x2F;&#x2F;逻辑 &#125; &#125; &#125;)&lt;&#x2F;script&gt; v-on 可以直接替换为 @ 事件名有以下几种类型 点击事件 click 鼠标移入 monseenter (这两个好像不太行) 双击dbclick 示例： &lt;div id&#x3D;&quot;app&quot;&gt; &lt;input type&#x3D;&quot;button&quot; value&#x3D;&quot;事件绑定&quot; v-on:click&#x3D;&quot;doit&quot;&gt;&lt;&#x2F;div&gt;var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, methods: &#123; doit:function()&#123; alert(&quot;GGGGo!&quot;); &#125; &#125;,&#125;) Vue中不考虑更改DOM元素，只需要更改数据，数据更改之后，DOM元素会同步更新。 this关键字，拿到定义的数据 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;h2 type&#x3D;&quot;text&quot; v-text&#x3D;&quot;food&quot; @click&#x3D;changeFood&gt; &lt;&#x2F;h2&gt; &lt;&#x2F;div&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; food:&quot;抹茶味冰淇淋&quot; &#125;, methods: &#123; changeFood:function()&#123; &#x2F;&#x2F; console.log(this.food); this.food +&#x3D;&quot;卖完了！&quot;; &#125; &#125;, &#125;) 1、计数器 创建Vue示例时：el（挂载点）；data（数据），methods（方法） v-on指令的作用就是绑定事件，简写为@ 方法中通过this关键字获取data中的数据 v-text指令的作用是：设置元素的文本值，简写为 &#123;&#123; &#125;&#125; &lt;body&gt; &lt;div id&#x3D;&quot;app&quot;&gt; &lt;input type&#x3D;&quot;button&quot; value&#x3D;&quot;-&quot; @click&#x3D;sub&gt; &lt;span&gt;&#123;&#123; Nbr &#125;&#125;&lt;&#x2F;span&gt; &lt;input type&#x3D;&quot;button&quot; value&#x3D;&quot;+&quot; @click&#x3D;add&gt; &lt;&#x2F;div&gt; &lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; Nbr:1, &#125;, methods: &#123; add:function()&#123; this.Nbr+&#x3D;1; &#125;, sub:function()&#123; this.Nbr-&#x3D;1; &#125; &#125;, &#125;)&lt;&#x2F;script&gt;&lt;&#x2F;body&gt; 显示切换v-show 根据表达式真假，切换元素的显示或隐藏。 原理是修改元素的display属性，实现显示隐藏 指令后面的内容，最后都会解析成布尔值 如果为true显示元素，如果为false则隐藏 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;img src&#x3D;&quot;.&#x2F;img&#x2F;orange.jpg&quot; alt&#x3D;&quot;ORANGEIMG&quot; v-show&#x3D;&quot;isShow&quot; height&#x3D;&quot;400px&quot;&gt; &lt;!-- 当年龄大于18岁的时候，图片才会显示 --&gt; &lt;img src&#x3D;&quot;.&#x2F;img&#x2F;orange.jpg&quot; alt&#x3D;&quot;ORANGEIMG&quot; v-show&#x3D;&quot;age&gt;18&quot; height&#x3D;&quot;400px&quot;&gt;&lt;&#x2F;div&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; isShow:true, age:15, &#125;, &#125;) v-if v-if指令的作用是：根据表达式的真假切换元素的显示状态 本质是通过操纵DOM元素来实现显示状态 表达式的值为true，元素存在于dom树中，为false，从dom树中移除。 频繁的切换v-show，反之使用v-if，前者切换消耗小 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;img src&#x3D;&quot;.&#x2F;img&#x2F;orange.jpg&quot; alt&#x3D;&quot;ORANGEIMG&quot; v-if&#x3D;&quot;age&lt;11&quot; height&#x3D;&quot;400px&quot;&gt; &lt;&#x2F;div&gt;&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el:&quot;#app&quot;, data:&#123; isShow:true, age:12, &#125;, &#125;) v-bind v-bind指令的作用是：为元素绑定属性 完整写法是：v-bind:属性名 简写的话可以直接省略v-bind，只保留：属性名 &lt;!-- 1、记得想要操纵的属性前面一定要加冒号，比如:src , :class 2、functional中想要取变量需要加this 3、显示隐藏class的语法是:class&#x3D;&#123;className,isActive&#125; --&gt;&lt;div id&#x3D;&quot;app&quot;&gt; &lt;img v-bind:src&#x3D;&quot;imgSrc&quot; v-bind:alt&#x3D;&quot;imgAlt&quot; v-bind:title&#x3D;&quot;imgTitle&quot; height&#x3D;&quot;400px&quot; @click&#x3D;&quot;ToRed&quot; :class&#x3D;&quot;&#123;active:isActive&#125;&quot; &gt;&lt;&#x2F;div&gt; &lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el: &#39;#app&#39;, data: &#123; isActive: false, imgSrc: &quot;&#x2F;img&#x2F;orange.jpg&quot;, imgAlt: &#39;vue-logo&#39;, imgTitle: &#39;这是你指定的title&#39; &#125;, methods: &#123; ToRed:function()&#123; this.isActive&#x3D;!this.isActive; &#125; &#125;, &#125;);&lt;&#x2F;script&gt; 2、图片切换 图片列表使用数组保存 v-bind指令可以设置元素的属性 v-show和v-if都可以设置元素的显示状态，频繁切换使用v-show &lt;div id&#x3D;&quot;app&quot;&gt; &lt;a href&#x3D;&quot;javascript:void(0)&quot; @click&#x3D;&quot;prev&quot; v-show&#x3D;&quot;index!&#x3D;0&quot;&gt;上一张&lt;&#x2F;a&gt; &lt;img :src&#x3D;&quot;arrayImg[index]&quot; alt&#x3D;&quot;凉了&quot; height&#x3D;&quot;360px&quot; style&#x3D;&quot;align-items: center;&quot;&gt; &lt;a href&#x3D;&quot;javascript:void(0)&quot; @click&#x3D;&quot;next&quot; v-show&#x3D;&quot;index&lt;arrayImg.length-1&quot;&gt;下一张&lt;&#x2F;a&gt;&lt;&#x2F;div&gt; &lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;&lt;script&gt; var app &#x3D; new Vue(&#123; el: &#39;#app&#39;, data: &#123; arrayImg:[ &quot;.&#x2F;img&#x2F;1.jpg&quot;, &quot;.&#x2F;img&#x2F;2.jpg&quot;, &quot;.&#x2F;img&#x2F;4.jpg&quot;, &quot;.&#x2F;img&#x2F;5.jpg&quot;, ], index:0, &#125;, methods: &#123; prev:function()&#123; this.index--; &#125;, next:function()&#123; this.index++; &#125;, &#125;,&#125;);&lt;&#x2F;script&gt; 列表循环v-for 根据数据生成列表结构 数组经常和v-for结合使用 语法是（item，index） in 数据 item 和 index 可以结合其他指令一起使用 数组长度的更新会同步到页面上，是响应式的 &lt;ul&gt; &lt;li v-for&#x3D;&quot;(item,index) in arr&quot; :title&#x3D;&quot;item&quot;&gt; &#123;&#123; index &#125;&#125; . &#123;&#123; item &#125;&#125; &lt;&#x2F;li&gt;&lt;&#x2F;ul&gt; var app = new Vue(&#123; el: '#app', data:&#123; arr:['a','b','c','d','e'], dict:&#123; name:\"ZEN\", school:\"UJS\" &#125;, &#125;&#125;); v-on补充 事件绑定的方法写成函数调用的形式，可以传入自定义参数 定义方法时需要定义形参来接受传入的实参 事件的后面跟上.修饰符可有对事件进行限制 .enter可以限制出发的按键为回车 &lt;!-- 点击Button在控制台打印参数在输入栏敲回车alert字符 --&gt;&lt;div id&#x3D;&quot;app&quot;&gt; &lt;input type&#x3D;&quot;button&quot; value&#x3D;&quot;Button&quot; @click&#x3D;&quot;doit(18151908742,&#39;ZEN&#39;)&quot;&gt; &lt;input type&#x3D;&quot;text&quot; @keyup.enter&#x3D;&quot;sayHi&quot;&gt;&lt;&#x2F;div&gt; var app = new Vue(&#123;el: '#app',data:&#123; arr:['a','b','c','d','e'],&#125;,methods: &#123; doit:function(p1,p2)&#123; console.log(p1,p2); &#125;, sayHi:function()&#123; alert(\"Hi Vue!\"); &#125;, &#125;,&#125;); v-model获取设置表单元素的值，双向绑定，修改任意一方，另外一个也会被修改 &lt;!-- h2标签的值会随着输入框输入的而改变，由此可以得出，v-model的改变是双向的 --&gt;&lt;div id&#x3D;&quot;app&quot;&gt; &lt;input type&#x3D;&quot;text&quot; v-model&#x3D;&quot;message&quot;&gt; &lt;h2&gt;&#123;&#123; message &#125;&#125; &lt;&#x2F;h2&gt;&lt;&#x2F;div&gt; var app = new Vue(&#123;el: '#app',data:&#123; message:\"Vue\",&#125;,&#125;); 3、记事本 列表结构可以通过v-for生成 v-on结合事件修饰符可以对事件进行限制，比如.enter v-on在绑定事件的时候可以传入自定义参数 通过v-model可以快速设置和获取表单元素的值 VUE是基于数据的开发方式，JS是基于DOM的开发方式 新增、删除、统计、清空、隐藏 增加list条目 v-mode把需要增加的信息双向绑定 添加键盘敲击事件响应，回车调用add方法 v-for遍历todo列表 push把元素添加到数组 &lt;div id&#x3D;&quot;app&quot;&gt; &lt;input type&#x3D;&quot;text&quot; v-model&#x3D;&quot;message&quot; @keyup.enter&#x3D;&quot;add&quot;&gt; &lt;ul&gt; &lt;li v-for&#x3D;&quot;(item,index) in todoList&quot;&gt; &#123;&#123; index+1 &#125;&#125;.&#123;&#123; item &#125;&#125; &lt;&#x2F;li&gt; &lt;&#x2F;ul&gt;&lt;&#x2F;div&gt; var app = new Vue(&#123; el:\"#app\", data:&#123; todoList:['起床','吃饭','睡觉'], message:'写代码', &#125;, methods: &#123; add:function()&#123; this.todoList.push(this.message); &#125; &#125;,&#125;); 删除 删除时传入下标 splice参数 v-for的即时响应 &lt;div id=\"app\"&gt; &lt;input type=\"text\" v-model=\"message\" @keyup.enter=\"add\"&gt; &lt;ul&gt; &lt;li v-for=\"(item,index) in todoList\"&gt; &#123;&#123; index+1 &#125;&#125;.&#123;&#123; item &#125;&#125; &lt;button @click=\"del(index)\"&gt;x&lt;/button&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; del:function(INDEX)&#123; //第一个参数是从哪删 ///第二个参数是删除几个元素 this.todoList.splice(INDEX,1);&#125; 统计 &lt;h3 v-text=\"'当前待执行的事件有 '+todoList.length+' 个'\"&gt;&lt;/h3&gt;&lt;h3&gt;当前待执行的事件有 &#123;&#123; todoList.length &#125;&#125; 个&lt;/h3&gt; 清空 &lt;div&gt; &lt;h3&gt;当前待执行的事件有 &#123;&#123; todoList.length &#125;&#125; 个&lt;/h3&gt; &lt;button @click=\"clear\"&gt;Clear&lt;/button&gt;&lt;/div&gt; clear:function()&#123; this.todoList=[];&#125; 隐藏 &lt;!-- 数组为空的时候隐藏计数和Clear按钮 --&gt;&lt;div&gt; &lt;h3 v-show=\"todoList.length!=0\"&gt;当前待执行的事件有 &#123;&#123; todoList.length &#125;&#125; 个&lt;/h3&gt; &lt;button @click=\"clear\" v-show=\"todoList.length!=0\"&gt;Clear&lt;/button&gt;&lt;/div&gt; 我就不写CSS 网络应用Vue结合网络数据开发应用 axios必须先导入才可以使用 使用get或post方法可以发送对应的请求 then方法中的回调函数可以在请求成功或失败时触发 通过回调函数的形参可以获取响应内容，或错误信息 axios网络请求库 &lt;script src=\"https://unpkg.com/axios/dist/axios.min.js\"&gt;&lt;/script&gt;axios.get(地址?key=value,key=value).then(function(response)&#123;&#125;,function(err)&#123;&#125;)axios.post(地址,(key=value,key=value)).then(function(response)&#123;&#125;,function(err)&#123;&#125;) axios的两种请求 &lt;!-- 官网提供的axios在线地址 --&gt; &lt;script src=\"https://unpkg.com/axios/dist/axios.min.js\"&gt;&lt;/script&gt; &lt;script&gt; /* 接口1：随机笑话 请求地址：https://autumnfish.cn/api/joke/list 请求方法：Get 请求参数：num（笑话条数，数字） 相应内容：随机笑话 */ document.querySelector(\".get\").onclick = function()&#123; axios.get(\"https://autumnfish.cn/api/joke/list?num=3\").then(function (response)&#123; console.log(response); &#125;,function(err)&#123; console.log(err); &#125;) &#125; /* 接口2：用户注册 请求地址：https://autumnfish.cn/api/user/reg 请求方法：post 请求参数：username(用户名，字符串) 响应内容：注册成功或失败 */ document.querySelector(\".post\").onclick = function()&#123; axios.post(\"https://autumnfish.cn/api/user/reg\",&#123;username:\"ZEN\"&#125;).then(function(response)&#123; console.log(response); &#125;,function(err)&#123; console.log(err); &#125;) &#125; &lt;/script&gt; vue+axios 使用axios获取API返回的数据 this传递数据，交给界面显示 axios回调函数中的this已经改变，无法访问data中的数据，可以先定义一个变量把this保存起来 &lt;div id=\"app\"&gt; &lt;input type=\"button\" value=\"Get请求\" class=\"get\" @click=\"getJoke\"&gt; &lt;br&gt; &lt;ul&gt; &lt;li v-for=\"(item,index) in joke\"&gt; &#123;&#123;item&#125;&#125; &lt;br&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; var app = new Vue(&#123; el:\"#app\", data:&#123; joke:\"一个笑话\", &#125;, methods: &#123; getJoke:function()&#123; var that = this axios.get(\"https://autumnfish.cn/api/joke/list?num=3\").then( function(response)&#123; console.log(response.data); that.joke = response.datajokes; &#125;, function(err)&#123; console.log(err); &#125; ) &#125; &#125;,&#125;)","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://ymlog.cn/tags/Vue/"}]},{"title":"Redis","slug":"Redis","date":"2020-04-01T07:03:22.000Z","updated":"2020-07-04T17:18:21.526Z","comments":true,"path":"2020/04/01/Redis/","link":"","permalink":"http://ymlog.cn/2020/04/01/Redis/","excerpt":"念两句诗芦叶满汀洲，寒沙带浅流。二十年重过南楼。柳下系船犹未稳，能几日，又中秋。黄鹤断矶头，故人曾到否？旧江山浑是新愁。欲买桂花同载酒，终不似，少年游。","text":"念两句诗芦叶满汀洲，寒沙带浅流。二十年重过南楼。柳下系船犹未稳，能几日，又中秋。黄鹤断矶头，故人曾到否？旧江山浑是新愁。欲买桂花同载酒，终不似，少年游。 Redis简介Redis特点 K-V 数据库 支持丰富的数据类型：String、Hash、List、Set、Zset（5大基础类型） 和Memcache对比：数据都是存储在内存中的，但是Redis可以做持久化存储（数据可以存储在磁盘上） 工作模型：单线程 | IO多路复用 | 内存 集群方案 速度快 Redis为什么快？ 数据库存储在内存中 一般采用单线程IO多路复用 单线程可以避免CPU竞争带来的开销（Redis属于CPU密集型，单独部署，避免和其他业务产生CPU竞争问题） 单线程数据结构等开销较小 常用场景1、缓存 2、计数，许多应用都会使用Redis作为计数的基础工具，它可以实现快速计数、查询缓存的功能，同时数据可以异步落地到其他数据源。例如笔者所在团队 的视频播放数系统就是使用Redis作为视频播放数计数的基础组件，用户每 播放一次视频，相应的视频播放数就会自增1： long incrVideoCounter(long id) &#123; key = \"video:playCount:\" + id; return redis.incr(key);&#125; 3、共享Session 4、限速 很多应用出于安全的考虑，会在每次进行登录时，让用户输入手机验证码，从而确定是否是用户本人。但是为了短信接口不被频繁访问，会限制用 户每分钟获取验证码的频率 phoneNum = \"138xxxxxxxx\"; key = \"shortMsg:limit:\" + phoneNum;// SET key value EX 60 NX isExists = redis.set(key,1,\"EX 60\",\"NX\"); if(isExists != null || redis.incr(key) &lt;=5)&#123; // 通过&#125;else&#123; // 限速&#125; 初入Redis[root@localhost ~]# yum -y install redis [root@server yum.repos.d]# rpm -ql redis/etc/logrotate.d/redis # 日志配置/etc/redis-sentinel.conf # 哨兵配置/etc/redis.conf # 主配置文件/usr/bin/redis-cli # 客户端工具/usr/bin/redis-sentinel # 哨兵配置工具/usr/bin/redis-server # redis服务工具/usr/bin/redis-check-aof # aof文件修复工具/usr/bin/redis-check-rdb # rdb文件修复工具 # Redis服务的启动redis-server# 连接Redis服务redis-cli 配置文件[root@server ~]# cat /etc/redis.conf | grep -Ev '^$|^#'bind 127.0.0.1 # 监听服务地址protected-mode yes port 6379 # 端口tcp-backlog 511 # tcp全连接数量timeout 0 # 超时时间tcp-keepalive 300 # tcp长连接数量daemonize no # 是否在后台运行supervised no # supervised管理是否打开pidfile /var/run/redis_6379.pid # redis服务的pid文件位置loglevel notice # 日志等级记录logfile /var/log/redis/redis.log # 日志存放位置databases 16 # redis数据库实例的设置数量save 900 1 # 出发rdb持久化存储的策略900s -&gt; 1条写入 ； save 300 10 # 同上save 60 10000stop-writes-on-bgsave-error yes # bgsave手动触发rdb持久化存储，命令失败停止写入rdbcompression yes # rdb文件压缩rdbchecksum yes # rdb文件校验dbfilename dump.rdb # rdb文件名称dir /var/lib/redis # redis服务目录slave-serve-stale-data yes slave-read-only yes # 当此结点作为slaver的时候，开启只读模式# master-slaver之间的复制策略repl-diskless-sync no repl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100 # slave优先级appendonly no # 持久化aof存储appendfilename \"appendonly.aof\" # aof文件名称appendfsync everysec no-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000 # 慢日志设定时间，单位微秒slowlog-max-len 128 # 慢日志长度，当慢查询日志处于其最大长度时，将最早插入的命令移出latency-monitor-threshold 0notify-keyspace-events \"\"# 数据类型底层编码的策略：相同的数据类型，底层的数据结构编码方式可能不同hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yes# 客户端输出缓冲区显示策略client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10 # 内存回收策略，定期删除过期任务每s运行次数aof-rewrite-incremental-fsync yes 慢查询 slowlog get # 获取慢查询日志slowlog len # 获取慢查询日志长度slowlog reset # 重置慢查询日志 Redis小工具 redis-cli -r 100 -i 1 info | grep used_memory_human# -r repeat# -i interval# -a auth# -c Cluster# -x 从标准输入(stdin)读取数据# --slave 把客户端模拟成当前Redis节点的从节点# --latency 测试客户端到目标Redis的延迟# --stat 实时获取Redis统计信息 redis-server# --test-memory 1024 检测操作系统能否稳定分配1G内存给Reids redis-benchmark 基准性能测试# -c clients 客户端并发数，默认50# -n&lt;requests&gt; 客户端请求总量，默认100000# -p pipeline 每个请求的pipeline数量，默认为1# -k&lt;boolean&gt; 是否启用keepalive，1为使用# -t&lt;get,set&gt; 使用指定命令进行基准测试# --csv 结果以csv格式输出[root@hw ~]# redis-benchmark -c 100 -n 2000.........24.50% &lt;= 1 milliseconds60.05% &lt;= 2 milliseconds66.15% &lt;= 3 milliseconds76.60% &lt;= 4 milliseconds87.05% &lt;= 5 milliseconds93.60% &lt;= 6 milliseconds95.90% &lt;= 7 milliseconds97.70% &lt;= 8 milliseconds98.65% &lt;= 13 milliseconds99.65% &lt;= 14 milliseconds100.00% &lt;= 14 milliseconds29850.75 requests per second # 监视Redis正在执行的命令，可能会占用大量的内存127.0.0.1:6379&gt; monitorOK1586155547.048775 [0 121.36.70.55:34886] \"auth\" \"abc\"1586155555.897676 [0 121.36.70.55:34886] \"keys\" \"*\"# 客户端统计片段121.36.70.55:6379&gt; info clientsconnected_clients:2client_longest_output_list:0 # 客户端缓冲区可能会造成内存陡增，尤其是对于主节点；内存陡增还可能是存在大量写入；或者是客户端在执行monitor命令解决办法：1、kill这个连接 2、禁止monitor命令 3、限制输出缓冲区的大小client_biggest_input_buf:0blocked_clients:0 数据类型http://redisdoc.com/index.html String1、设置获取键值 SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds ： 将键的过期时间设置为 seconds 秒。 PX milliseconds ： 将键的过期时间设置为 milliseconds 毫秒。 NX ： 只在键不存在时， 才对键进行设置操作。 XX ： 只在键已经存在时， 才对键进行设置操作。 [root@server ~]# redis-cli127.0.0.1:6379&gt; set k1 v1OK127.0.0.1:6379&gt; get k1\"v1\"127.0.0.1:6379&gt; ttl 获取键值的生存时间incr 为键值进行加操作incrbydecr 为键值进行减操作decrby 不想写了，都在这： http://redisdoc.com/index.html listlpush rpush lpop rpop lrange lset lindex HashSetsadd scard sdiff sinter sunion smembers spop scre zsetzadd zcard zcount zrange 键 操作 含义 rename key newkey 重命名key renamenx key newkey 确保只有newKey不存在时候才被覆盖 randomkey 随机返回一个键 expire key seconds 键在seconds秒后过期 ttl key 观察它的过期剩余时间（单位：秒） pexpire key milliseconds 键在milliseconds毫秒后过期 persist key 将键的过期时间清除 keys pattern 获取所有的键(key *) scan cursor [match pattern] [count number] 扫描字典键，对其他数据类型，则是hscan、sscan、zscan。渐进式地遍历 键迁移 dump key restore key ttl value 数据库管理 命令 含义 select dbIndex 切换数据库 databases 16 flushdb 只清除当前数据库 flushall 清除所有数据库 auth “youpassword” 输入redis密码，即配置文件中requirepass 127.0.0.1:6379&gt; set hello world OK127.0.0.1:6379&gt; get hello \"world\" 127.0.0.1:6379&gt; select 15OK 127.0.0.1:6379[15]&gt; get hello(nil) 持久化存储 RDB持久化存储 AOF持久化存储 RDBRDB持久化存储：将内存中的数据存储快照写到磁盘中（快照方式） 优点： 应用场景：做全量备份；快照代表的一个时间的数据集状态 RDB文件：a. 二进制文件 b. 压缩机制；所以对于AOF文件来说，体积更小 生成RDB文件：redis主进程去fork()一个子进程去负责RDB文件生成工作，fork()这个操作肯定会有阻塞 缺点： 没办法做到实时持久化 RDB二进制格式随着Redis版本的得带，可能存在兼容性问题 周期性执行一次性备份操作，如果Redis在此期间down掉，会存在数据丢失 RDB压缩会消耗CPU资源 触发方式： 自动触发：主配置文件中的save字段 手动触发：bgsave config get dir可以查看RDB文件的备份路径， 服务启动时，热更新配置: config set dir /path config set dbfilename value redis服务启动时，会去dir下读取dbfilename文件 停止RDB持久化：注释配置文件中的save关键字 RDB工作流程： bgsave命令发送给主进程 redis父进程接收到bgsave命令之后，fork()创建一个子进程 当子进程完成之后，继续去响应客户端请求 子进程负责将内存中的数据打上快照并生成RDB文件存储在本地指定位置上 子进程完成工作后发信号通知父进程 获取最近一个fork操作的耗 时，单位为微秒info stats...latest_fork_usec:133执行lastsave命令可以获取最后一次生成RDB的时间 Redis默认采用LZF算法对生成的RDB文件做压缩处理，压缩后的文件远远小于内存大小，默认开启 AOFRedis的持久化方式之一，RDB是通过保存数据库中的键值对来记录数据库的状态，而另一种持久化方式AOF则是通过保存Redis服务所执行的命令来记录数据库的状态 优点： AOF持久化的方法提供了多种同步频率，即使使用默认同步频率每秒同步一次，redis最多也就丢失一秒的数据 AOF文件使用Redis命令追加的形式来构造，因此，即使Redis只能向AOF文件写入命令的片段，使用redis-check-aof工具也很容易修正AOF文件 AOF文件可读性较强，这也为使用者提供了更灵活的处理方式。如果我们不小心错用了FLUSHALL命令，在重写还没进行时，我们可以手工将最后FLUSHALL命令去掉，然后再使用AOF文件来恢复数据 缺点： 对于具有相同数据的Redis，AOF文件通常会比RDB文件体积更大 虽然AOF提供了多种同步频率，默认情况下，每秒同步一次的频率也具有较高的性能。但是在Redis的负载较高时，RDB比AOF具有更好的性能保证 RDB使用快照的形式来持久化整个Redis数据，而AOF只是将每次执行的命令追加到AOF文件中，因此从理论上来说RDB比AOF方式更健壮，官方文档也指出，AOF的确存在一些BUG。 开启AOF 将redis.conf的appendonly改为yes 客户端内：config set appendonly yes，查看是否开启 config get appendonly 手动备份：bgrewriteaof AOF工作流程 用户操作命令追加写入到AOF Buf AOF缓冲区会将操作命令根据指定的同步策略写入到AOF文件中 进行重写操作（新的AOF文件替换就的AOF文件） 服务启动时，可以去加载AOF文件达到的数据恢复的状态 AOF同步策略：调用两个系统接口：write &amp; fsync always：保证文件存储到磁盘中才返回（write -&gt; buf -&gt; fsync -&gt; disk) 可靠性高阻塞长 no ：只能保证文件存储到缓冲区（write -&gt; buf ；直接返回）缓冲区中的数据同步到磁盘上是由系统调度机制去完成的）阻塞相对较短，但是可靠性不高 everysec：调用write操作将内存中的数据写入到缓冲区中，然后后天会有一个专门的fsync线程每s执行一次将缓冲区的内容写入到磁盘中。相对于always和no来说，可靠性和效率都有所保证。 write操作：会触发延迟写机制，因为Linux在内核提供页缓冲区来提供磁盘IO性能，write操作在写入系统缓冲区后直接返回，同步到硬盘依赖于系统的调度机制。 fsync操作：针对单个文件操作，做强制硬盘同步，fsync将阻塞直到写入硬盘完成后返回，保证了数据的持久化。 AOF重写工作流程： 执行bgrewriteaof操作交由redis父进程 父进程fork()创建一个子进程（完成AOF生成替换工作） 父进程继续响应用户请求操作 写入到AOF_BUF中，追加到old aof文件中 写入到AOF_rewrite_buf 子进程根据内存数据集完成AOF文件的工作 还需要将AOF_rewrite_buf中的数据追加生成到AOF文件中（从而保证子进程创建AOF文件时，父进程继续相应用户请求数据 新的AOF文件替换旧的AOF文件 为什么要重写? 比如操作： set k1 v1 del k1 这个操作最后没有任何数据产生，是没有意义的，所以AOF不需要写入。 AOF和RDB文件同时存在的时候，优先加载AOF文件。 主从复制缺点： 如果master服务器出现问题，则不能提供服务，需要人工修改配置，将slave提升为master 主从复制，master服务器成为写操作瓶颈 单机节点存储能力有限 复制原理从节点复制主结点数据，从节点只能响应读操作。 全量复制：将主结点的所有数据复制到本地 部分复制：主结点持续响应用户请求操作，然后同步到本地执行 从节点执行 slaveof 命令 从节点只是保存了 slaveof 命令中主节点的信息，并没有立即发起复制 从节点内部的定时任务发现有主节点的信息，开始使用 socket 连接主节点 连接建立成功后，发送 ping 命令，希望得到 pong 命令响应，否则会进行重连 如果主节点设置了权限，那么就需要进行权限验证；如果验证失败，复制终止。 权限验证通过后，进行数据同步，这是耗时最长的操作，主节点将把所有的数据全部发送给从节点。 当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。 全量复制 部分复制 优点：备份；读写分离 缺点： 如果主结点down了，我们需要人工切换slave节点的新主节信息（slaveof） 单机存储容量受限（数据只会存储在master节点上），master节点读操作负载容易变高 实验#!/bin/bashmkdir /tmp/redis/&#123;data,conf,log&#125; -pv# 主服务器cat &lt;&lt; EOF &gt;/tmp/redis/conf/redis_6380.confbind 127.0.0.1port 6380daemonize yespidfile /tmp/redis/redis_6380.pidloglevel noticelogfile /tmp/redis/log/redis_6380.logdir /tmp/redis/data/EOFcat &lt;&lt; EOF &gt;/tmp/redis/conf/redis_6381.confbind 127.0.0.1port 6381daemonize yespidfile /tmp/redis/redis_6381.pidloglevel noticelogfile /tmp/redis/log/redis_6381.logdir /tmp/redis/data/slaveof 127.0.0.1 6380EOFcat &lt;&lt; EOF &gt;/tmp/redis/conf/redis_6382.confbind 127.0.0.1port 6382daemonize yespidfile /tmp/redis/redis_6382.pidloglevel noticelogfile /tmp/redis/log/redis_6382.logdir /tmp/redis/data/slaveof 127.0.0.1 6380EOFredis-server /tmp/redis/conf/redis_6380.confredis-server /tmp/redis/conf/redis_6381.confredis-server /tmp/redis/conf/redis_6382.conf 测试 [root@localhost ~]# redis-cli -p 6380127.0.0.1:6380&gt; info Replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6381,state=online,offset=99,lag=0slave1:ip=127.0.0.1,port=6382,state=online,offset=99,lag=0master_repl_offset:99repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:98# 写入一定的值127.0.0.1:6380&gt; set k1 v1 OK127.0.0.1:6380&gt; get k1\"v1\"127.0.0.1:6380&gt; [root@node01 ~]# redis-cli -p 6381127.0.0.1:6381&gt; keys *1) \"k1\" master日志分析 10974:M 05 Apr 15:08:11.474 * Starting BGSAVE for SYNC with target: disk# bgsave执行过程10974:M 05 Apr 15:08:11.474 * Background saving started by pid 10982# master接收到来自slave2的全量复制请求10974:M 05 Apr 15:08:11.483 * Slave 127.0.0.1:6382 asks for synchronization10974:M 05 Apr 15:08:11.483 * Full resync requested by slave 127.0.0.1:638210974:M 05 Apr 15:08:11.483 * Waiting for end of BGSAVE for SYNC10982:C 05 Apr 15:08:11.485 * DB saved on disk10982:C 05 Apr 15:08:11.485 * RDB: 0 MB of memory used by copy-on-write10974:M 05 Apr 15:08:11.567 * Background saving terminated with success# 数据同步给slave1和2，增量复制10974:M 05 Apr 15:08:11.568 * Synchronization with slave 127.0.0.1:6381 succeeded10974:M 05 Apr 15:08:11.568 * Synchronization with slave 127.0.0.1:6382 succeeded slaver日志分析 # 与master节点建立连接通信10978:S 05 Apr 15:08:11.473 * Connecting to MASTER 127.0.0.1:6380# 全量复制同步开始前的准备阶段10978:S 05 Apr 15:08:11.473 * MASTER &lt;-&gt; SLAVE sync started10978:S 05 Apr 15:08:11.473 * Non blocking connect for SYNC fired the event.10978:S 05 Apr 15:08:11.473 * Master replied to PING, replication can continue...10978:S 05 Apr 15:08:11.474 * Partial resynchronization not possible (no cached master)# 开始全量复制10978:S 05 Apr 15:08:11.474 * Full resync from master: 0ae1eafaf5a6804f35d3a3a5a5934a0f62d4f390:110978:S 05 Apr 15:08:11.568 * MASTER &lt;-&gt; SLAVE sync: receiving 77 bytes from master10978:S 05 Apr 15:08:11.568 * MASTER &lt;-&gt; SLAVE sync: Flushing old data10978:S 05 Apr 15:08:11.568 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory10978:S 05 Apr 15:08:11.568 * MASTER &lt;-&gt; SLAVE sync: Finished with success 哨兵架构Sentinel Mode 优点：备份 ； 读写分离 ； 可以自动切换主节点 缺点： 单机存储容量受限 主结点写负载会很高 扩展性较差 哨兵原理： 每个哨兵会向其他哨兵、主服务器、从服务器定时发送消息，以确认对方是否活着。 当主节点挂掉的时候，某个哨兵1通过检测机制发现了这样一个情况，主观的认为这个主节点挂掉了（暂时还不能确认），会将这个信息发送给其他的哨兵，其他哨兵如果都赞同哨兵1的确认信息，则主观认为这个节点挂掉了（主结点真正的被分为挂掉了）。 发现master挂掉之后，从剩下的slave中重新选择新的master节点；每个哨兵都会监控slaver节点的状态信息，通过slave节点的状态信息进行投票选择，票数高的成为新的主结点，并且哨兵回去向其他节点告知新主节点的信息（IP_PORT) ，其他节点得到哨兵的通知消息后，自动执行slaveof去同步新的主节点信息。 哨兵实验#!/bin/bash#配置哨兵1，监听26378端口cat &lt;&lt; EOF &gt; /tmp/redis/conf/redis-sentinel-26378.confport 26378daemonize yesdir '/tmp'sentinel monitor mymaster 127.0.0.1 6380 1sentinel down-after-milliseconds mymaster 6000sentinel failover-timeout mymaster 18000logfile \"/tmp/redis/log/sentine1.log\"EOF#配置哨兵2，监听26379端口cat &lt;&lt; EOF &gt; /tmp/redis/conf/redis-sentinel-26379.confport 26379daemonize yesdir '/tmp'sentinel monitor mymaster 127.0.0.1 6380 1sentinel down-after-milliseconds mymaster 6000sentinel failover-timeout mymaster 18000logfile \"/tmp/redis/log/sentine2.log\"EOF#配置哨兵3，监听26380端口cat &lt;&lt; EOF &gt; /tmp/redis/conf/redis-sentinel-26380.confport 26380daemonize yesdir '/tmp'sentinel monitor mymaster 127.0.0.1 6380 1sentinel down-after-milliseconds mymaster 6000sentinel failover-timeout mymaster 18000logfile \"/tmp/redis/log/sentine3.log\"EOF# 启动哨兵redis-sentinel /tmp/redis/conf/redis-sentinel-26379.confredis-sentinel /tmp/redis/conf/redis-sentinel-26378.confredis-sentinel /tmp/redis/conf/redis-sentinel-26380.conf 测试： [root@node01 ~]# redis-cli -p 26379127.0.0.1:26379&gt; sentinel master mymaster 1) \"name\" 2) \"mymaster\" 3) \"ip\" 4) \"127.0.0.1\" 5) \"port\" 6) \"6380\".... sentinel master &lt;master-name&gt; ： 显示所有被监控主节点状态及统计信息sentinel slaves &lt;master-name&gt; ： 显示指定&lt;master-name&gt;的从节点状态及统计信息sentinel sentinels &lt;master-name&gt; ： 显示指定&lt;master-name&gt;的sentinel节点集合sentinel failover &lt;master-name&gt; ： 强制故障转移sentinel ckquorum &lt;master-name&gt; ： 检查当前可达Sentinel节点总数是否到&lt;quoro&gt;个数sentinel flushconfig ：将节点的配置强制刷到磁盘上sentinel remove &lt;master-name&gt; ： 取消当前Sentinel对指定&lt;master&gt;节点的监控sentinel set &lt;master-name&gt;：动态修改Sentinel节点配置sentinel is-master-down-by-addr ：Sentinel节点之间用来交换对主节点是否下线的判断 模拟master挂掉 [root@node01 ~]# ps -ef | grep redisroot 10974 1 0 15:08 ? 00:00:08 redis-server 127.0.0.1:6380root 10978 1 0 15:08 ? 00:00:07 redis-server 127.0.0.1:6381root 10983 1 0 15:08 ? 00:00:08 redis-server 127.0.0.1:6382root 11060 1 0 17:10 ? 00:00:01 redis-sentinel *:26379 [sentinel]root 11064 1 0 17:10 ? 00:00:01 redis-sentinel *:26378 [sentinel]root 11068 1 0 17:10 ? 00:00:01 redis-sentinel *:26380 [sentinel]root 11123 10907 0 17:19 pts/0 00:00:00 grep --color=auto redis[root@node01 ~]# kill -9 10974# 分析哨兵日志[root@node01 ~]# tailf /tmp/redis/log/sentine1.log 11068:X 05 Apr 17:10:26.924 # Sentinel ID is 58bdbb66f27e1e87dea74caed765090bdcef84f211068:X 05 Apr 17:10:26.924 # +monitor master mymaster 127.0.0.1 6380 quorum 111068:X 05 Apr 17:10:26.925 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 638011068:X 05 Apr 17:10:26.927 * +slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 638011068:X 05 Apr 17:10:28.906 * +sentinel sentinel 3756a9cd418f17b20e29b51a71a100c221a37379 127.0.0.1 26379 @ mymaster 127.0.0.1 638011068:X 05 Apr 17:10:28.932 * +sentinel sentinel 125c85846d42c32b15f364db43afab85c4858888 127.0.0.1 26378 @ mymaster 127.0.0.1 638011068:X 05 Apr 17:20:17.292 # +new-epoch 111068:X 05 Apr 17:20:17.294 # +vote-for-leader 125c85846d42c32b15f364db43afab85c4858888 1# 主观下线11068:X 05 Apr 17:20:17.371 # +sdown master mymaster 127.0.0.1 6380# 客观下线11068:X 05 Apr 17:20:17.371 # +odown master mymaster 127.0.0.1 6380 #quorum 1/111068:X 05 Apr 17:20:17.371 # Next failover delay: I will not start a failover before Sun Apr 5 17:20:54 202011068:X 05 Apr 17:20:18.415 # +config-update-from sentinel 125c85846d42c32b15f364db43afab85c4858888 127.0.0.1 26378 @ mymaster 127.0.0.1 6380# master切换11068:X 05 Apr 17:20:18.415 # +switch-master mymaster 127.0.0.1 6380 127.0.0.1 638111068:X 05 Apr 17:20:18.416 * +slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 638111068:X 05 Apr 17:20:18.416 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 638111068:X 05 Apr 17:20:24.461 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6381 重新启动6380后，6380将变成6381的slave节点 [root@node01 ~]# redis-server /tmp/redis/conf/redis_6380.conf127.0.0.1:6380&gt; info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6381 集群架构是一种分布式解决方案 优点 ： 每个节点都可以存储数据，每个节点都可以响应读写操作 更容易扩容 缺点： 部署复杂 redis部分cli命令受限，比如批量操作等 每个节点如何存储数据？（虚拟槽） 对象保存到Redis之前先经过CRC16哈希到一个Node上 每个Node被平均分配到一个Slot段，对应着0-16384，Slot不能重复也不能缺失，否则会导致对象重复存储或无法存储 Node之间相互监听，一旦有Node退出或者加入，会按照Slot为单位做数据迁移。例如Node1掉线了，0-5640这些Slot将会平均分摊到Node2和Node3上，由于Node2和Node3本身维护的Slot还会再自己身上不会被重新分配，所以执行过程中不会影响到5641-16384Slot段的使用。 计算CRC的过程，就是用一个特殊的“除法”，来得到余数，这个余数就是CRC。 它不是真正的算术上的除法！过程和算术除法过程一样，只是加减运算变成了XOR（异或）运算！ 集群实验Redis5.0之后部署会简单一点 wget http://download.redis.io/releases/redis-5.0.8.tar.gzyum install -y wget gcc make tcltar -xzf redis-5.0.8.tar.gzcd redis-5.0.8/make # 这里需要注意一下， 如果之前没有装gcc直接make，然后装了gcc再次make，会提示有个文件没有# PATH=$PATH:/usr/local/redis/bin,如果安装的时候prefix指定了路径，可以修改环境变量mv redis-5.0.8/ redismkdir -p /tmp/redis-cluster #!/bin/bash#=====================================================================#搭建一个Redis集群#=====================================================================mkdir /tmp/redis-cluster/redis&#123;7000..7005&#125; -pvtouch /tmp/redis-cluster/redis&#123;7000..7005&#125;/redis.conffor i in &#123;7000..7005&#125;;docat &lt;&lt; EOF &gt; /tmp/redis-cluster/redis$i/redis.confdaemonize yesport $icluster-enabled yescluster-config-file /tmp/redis-cluster/redis$i/nodes-$i.confcluster-node-timeout 5000appendonly yesEOF/root/redis/src/redis-server /tmp/redis-cluster/redis$i/redis.confdone 集群中有6个节点，设置3个master3个slaver [root@node01 ~]# /root/redis/src/redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...# 分配Slot槽Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 127.0.0.1:7004 to 127.0.0.1:7000Adding replica 127.0.0.1:7005 to 127.0.0.1:7001Adding replica 127.0.0.1:7003 to 127.0.0.1:7002&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: 2518beb0563857adb5c1497fffb4c5eb3d682103 127.0.0.1:7000 slots:[0-5460] (5461 slots) masterM: 1d39c766c5275ec08ae47f90b69d5e9c6c88eb8b 127.0.0.1:7001 slots:[5461-10922] (5462 slots) masterM: 141382f53c59164a232329efcc9530daffc43a25 127.0.0.1:7002 slots:[10923-16383] (5461 slots) masterS: 9269115a3ef21c7f378dcc68855a72059e943605 127.0.0.1:7003 replicates 2518beb0563857adb5c1497fffb4c5eb3d682103S: 6c33423da686f301f756dd624174bfd9f0487a67 127.0.0.1:7004 replicates 1d39c766c5275ec08ae47f90b69d5e9c6c88eb8bS: f8c74822b558a2e11ae36cf144b8a9388783bf95 127.0.0.1:7005 replicates 141382f53c59164a232329efcc9530daffc43a25Can I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join...&gt;&gt;&gt; Performing Cluster Check (using node 127.0.0.1:7000)M: 2518beb0563857adb5c1497fffb4c5eb3d682103 127.0.0.1:7000 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: 9269115a3ef21c7f378dcc68855a72059e943605 127.0.0.1:7003 slots: (0 slots) slave replicates 2518beb0563857adb5c1497fffb4c5eb3d682103M: 1d39c766c5275ec08ae47f90b69d5e9c6c88eb8b 127.0.0.1:7001 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f8c74822b558a2e11ae36cf144b8a9388783bf95 127.0.0.1:7005 slots: (0 slots) slave replicates 141382f53c59164a232329efcc9530daffc43a25S: 6c33423da686f301f756dd624174bfd9f0487a67 127.0.0.1:7004 slots: (0 slots) slave replicates 1d39c766c5275ec08ae47f90b69d5e9c6c88eb8bM: 141382f53c59164a232329efcc9530daffc43a25 127.0.0.1:7002 slots:[10923-16383] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 验证1： [root@node01 ~]# ps -ef | grep redisroot 12733 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7000 [cluster]root 12736 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7001 [cluster]root 12742 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7002 [cluster]root 12751 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7003 [cluster]root 12757 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7004 [cluster]root 12764 1 0 21:02 ? 00:00:00 /root/redis/src/redis-server *:7005 [cluster] 验证2：登录集群查看信息 [root@node01 ~]# redis/src/redis-cli -c -p 7000127.0.0.1:7000&gt; info cluster# Clustercluster_enabled:1127.0.0.1:7000&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:259cluster_stats_messages_pong_sent:267cluster_stats_messages_sent:526cluster_stats_messages_ping_received:262cluster_stats_messages_pong_received:259cluster_stats_messages_meet_received:5cluster_stats_messages_received:526# slave节点后缀ID和Master的ID号对应2518beb0563857adb5c1497fffb4c5eb3d682103 127.0.0.1:7000@17000 myself,master - 0 1586092155000 1 connected 0-54609269115a3ef21c7f378dcc68855a72059e943605 127.0.0.1:7003@17003 slave 2518beb0563857adb5c1497fffb4c5eb3d682103 0 1586092157502 4 connected1d39c766c5275ec08ae47f90b69d5e9c6c88eb8b 127.0.0.1:7001@17001 master - 0 1586092156896 2 connected 5461-10922f8c74822b558a2e11ae36cf144b8a9388783bf95 127.0.0.1:7005@17005 slave 141382f53c59164a232329efcc9530daffc43a25 0 1586092157502 6 connected6c33423da686f301f756dd624174bfd9f0487a67 127.0.0.1:7004@17004 slave 1d39c766c5275ec08ae47f90b69d5e9c6c88eb8b 0 1586092156391 5 connected141382f53c59164a232329efcc9530daffc43a25 127.0.0.1:7002@17002 master - 0 1586092157401 3 connected 10923-16383# 写入值，重定向k1 v1 CRC16计算，--&gt; slot_12706，给7002号master127.0.0.1:7000&gt; set k1 v1-&gt; Redirected to slot [12706] located at 127.0.0.1:7002OK","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ymlog.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://ymlog.cn/tags/Redis/"}]},{"title":"Django——Models","slug":"Django_Models","date":"2020-03-28T06:42:14.000Z","updated":"2020-07-04T17:19:38.591Z","comments":true,"path":"2020/03/28/Django_Models/","link":"","permalink":"http://ymlog.cn/2020/03/28/Django_Models/","excerpt":"念两句诗笙管本无律，清风顾盼闲。哀哀稚子意，眷眷亲人怜。岁月悲华发，流光爱少年。山中有历日，年尽不言寒。幼小便失亲，山深自本真。几行逝水泪，一片朝霞洇。或有野村梦，岂无花蕾心？春夏秋冬后，情仇过眼云。","text":"念两句诗笙管本无律，清风顾盼闲。哀哀稚子意，眷眷亲人怜。岁月悲华发，流光爱少年。山中有历日，年尽不言寒。幼小便失亲，山深自本真。几行逝水泪，一片朝霞洇。或有野村梦，岂无花蕾心？春夏秋冬后，情仇过眼云。 前期准备0、首先创建一个Django项目： django-admin startproject DoModelcd DoModeldjango-admin startapp App项目框架：-------------------------------G:\\Django\\django1.11\\DoModel&gt;tree /FFolder PATH listing for volume tmpVolume serial number is 1030-3F09G:.│ manage.py│├───App # 我们主要写代码的地方│ │ admin.py│ │ apps.py│ │ models.py # 和数据库交互的地方│ │ tests.py│ │ views.py # 写业务逻辑的地方│ │ __init__.py│ ││ └───migrations│ __init__.py│└───DoModel settings.py urls.py wsgi.py __init__.py 1、在DoModel/DoModel/settings.py中加入应用 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'App',] 2、更改DoModel/DoModel/settings.py中的数据库为MySQL，下面会详细讲解如何更换数据库 3、在DoModel/urls.py中注册App的路由 urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^app/',include(\"App.urls\"))] 更换数据库详解在DoModel/setting.py*中修改DATABASES设置 DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'model3', 'USER': 'niki', 'PASSWORD': '123456', 'HOST': '121.36.70.55', 'PORT': '3306', &#125;&#125; 1、在MySQL上创建数据库model3, create database model3; 2、添加数据库 3、下载驱动 4、 安装数据库驱动 python -m pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple pip install pymysql -i https://pypi.tuna.tsinghua.edu.cn/simple 5、伪装驱动 因为Django是不认pymysql的，所以需要伪装成MySQL_db # HelloDjango/__init__.pyimport pymysqlpymysql.install_as_MySQLdb() 6、执行迁移 python manage.py makemigrationspython manage.py migrate 可以看到Student表迁移成功： 简介 开发环境 Windows10 Python==3.5.2 django=1.11.7 MTV/MVCMVC：（Model 、View、Controller） Model：用于封装与应用程序的业务逻辑相关的数据及对数据的处理方法，是web应用程序中用于处理应用程序的数据逻辑部分，Model通常只提供功能性的接口，通过这些接口可以获取Model的所有功能 View：负责数据的呈现，View对用户直接输出 Controller：负责从用户端收集用户输入，主要处理用户的交互 MTV是从MVC演化而来，本质上和MVC一样，只是名字改了： MTV：（Model、Template、View） Model：负责业务对象和数据库对象 View：负责业务逻辑，并在适当的时候调用Module 和 Template Template：负责把页面展示给用户 在Django中，还有url，主要用来将一个个URL页面请求分发给不同的view进行处理，View再调用相应的Model和Template。 ORMORM（Object Relation Mapping） 对象关系映射，就是把数据库也看作是一个对象，将数据库的属性映射到对象的属性和方法，目的是为了将业务逻辑和SQL语句进行解耦合： 数据库的表（table） –&gt; 类（class） 记录（record，行数据）–&gt; 对象（object） 字段（field）–&gt; 对象的属性（attribute） ORM 使用对象，封装了数据库操作，因此可以不碰 SQL 语言。开发者只使用面向对象编程，与数据对象直接交互，不用关心底层数据库。 下面一段代码就是创建了两张表，Grade表的字段是g_grade、Student表的字段是s_name、s_password和s_grade。 可以看到，数据库的表对应了面向对象的类，且必须继承自models.Model这个类；字段则是对应了面向对象的属性。 /DoModel/App/models.py from django.db import modelsclass Grade(models.Model): g_grade = models.CharField(max_length=16)class Student(models.Model): s_name = models.CharField(max_length=32) s_password = models.CharField(max_length=32) s_grade = models.ForeignKey(Grade) 连接数据库 映射到库中： python manage.py makemigrations # 生成迁移文件python manage.py migrate # 执行迁移 刷新数据库就可以看到App_Student和App_Grade两张表了。查看表的定义： -- auto-generated definitioncreate table App_student( id int auto_increment primary key, s_name varchar(32) not null, s_password varchar(32) not null, s_grade_id int not null, constraint App_student_s_grade_id_797e4cc7_fk_App_grade_id foreign key (s_grade_id) references App_grade (id)); -- auto-generated definitioncreate table App_grade( id int auto_increment primary key, g_grade varchar(16) not null); 定义字段字段名不允许使用下划线，因为查询条件需要用到下划线 字段类型 字段类型 含义 AutoField 一个根据实际ID自动增长的IntegerField，通常不指定如果不指定，一个主键字段将自动添加到模型中 CharField 字符串，默认的表单样式是 TextInput TextField 大文本字段，一般超过4000使用，默认的表单控件是Textarea IntegerField 整数 DecimalField 使用python的Decimal实例表示的十进制浮点数 FloatField 用Python的float实例来表示的浮点数 BooleanField true/false 字段，此字段的默认表单控制是CheckboxInput，MySQL不支持Bool值，所以ORM会把布尔值转换为tinyint(1)类型 NullBooleanField 支持null、true、false三种值 DateField(auto_now=False, auto_now_add=False) 使用Python的datetime.date实例表示的日期 TimeField 使用Python的datetime.time实例表示的时间，参数同DateField DateTimeField 使用Python的datetime.datetime实例表示的日期和时间，参数同DateField，示例：.o_time = modes.DataTimeField(auto_now_add=True) FileField 一个上传文件的字段 ImageField 继承了FileField的所有属性和方法，但对上传的对象进行校验，确保它是个有效的image DateField参数说明 DateField.auto_now每次保存对象时，自动设置该字段为当前时间，用于&quot;最后一次修改&quot;的时间戳，它总是使用当前日期，默认为false DateField.auto_now_add 1、当对象第一次被创建时自动设置当前时间，用于创建的时间戳，它总是使用当前日期，默认为false 2、说明 该字段默认对应的表单控件是一个TextInput. 在管理员站点添加了一个JavaScript写的日历控件，和一个“Today&quot;的快捷按钮，包含了一个额外的invalid_date错误消息键 3、注意 auto_now_add, auto_now, and default 这些设置是相互排斥的，他们之间的任何组合将会发生错误的结果字段约束 字段约束 含义 null 如果为True，Django 将空值以NULL 存储到数据库中，默认值是 False blank 如果为True，则该字段允许为空白，默认值是 False，null是数据库范畴的概念，blank是表单验证证范畴的 db_column 字段的名称，如果未指定，则使用属性的名称 db_index 若值为 True, 则在表中会为此字段创建索引 default 默认值 primary_key 若为 True, 则该字段会成为模型的主键字段 unique 如果为 True, 这个字段在表中必须有唯一值 示例： from django.db import models# Create your models here.class Person(models.Model): # max_length: 最大长度 # unqiue: 唯一性 # db_column: 自定义字段名，如果不定义，就直接使用s_name s_name = models.CharField(max_length=16,unique=True,db_column='name') s_age = models.IntegerField(default=18,db_column='age') # False表示男，True表示女 s_sex = models.BooleanField(default=False,db_column='sex') # 自定义表名 class Meta: db_table = 'People' 属性显性属性（开发者手动声明的属性），隐性属性（没有声明，父类中也不存在，动态产生出来的；如果开发者主动声明这些属性，隐性属性自己就不再产生了） 增删改查增事前准备： 1、在总的urls中注册App的urls urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^app/',include(\"App.urls\"))] 2、创建并且编写App的urls.py from django.conf.urls import urlfrom App import viewsurlpatterns = [ url(r'^addStudent/', views.addStudent),] 3、创建views中的函数，用于添加学生数据 # Create your views here.def addStudent(request): return HttpResponse(&quot;学生数据添加成功&quot;) 4、手动创建几个Grade字段 创建数据的几种方式 1、直接实例化对象设置属性 2、创建对象传入属性 3、使用Model.objects.create() 4、自己封装类方法创建 5、使用Manager()中封装方法创建 6、直接调用类方法添加数据 1、直接实例化对象设置属性def addStudent(request): student = Student() student.s_name = \"Jack\" grade = Grade.objects.get(pk=1) print(\"What is The Grade Type:\",type(grade)) # &lt;class 'App.models.Grade'&gt; student.s_grade = grade # 因为Student和Grade进行了外键关联，这里需要传入的是一个Grade的示例，不然会报错 student.s_password = \"123456789\" student.save() return HttpResponse(\"学生数据添加成功1\") 之后在Student表中就会多出一行数据了 MariaDB [model3]&gt; select * from App_student;+----+--------+------------+------------+| id | s_name | s_password | s_grade_id |+----+--------+------------+------------+| 1 | Jack | 123456789 | 1 |+----+--------+------------+------------+ 2、创建对象传入属性def addStudent(request): grade = Grade.objects.get(pk=3) student = Student(s_name='Rose',s_password='abcdefg',s_grade=grade) student.save() return HttpResponse(\"学生数据添加成功2\") 3、使用Model.objects.create()def addStudent(request): grade = Grade.objects.get(pk=2) student = Student.objects.create(s_name='Niki',s_password='987654321',s_grade=grade) student.save() return HttpResponse(\"学生数据添加成功3\") 4、自己封装类方法创建封装自己的类方法，可以添加默认值 class Student(models.Model): s_name = models.CharField(max_length=32) s_password = models.CharField(max_length=32) s_grade = models.ForeignKey(Grade) @classmethod def create(cls,s_name,s_grade,s_password='PASWD'): return cls(s_name=s_name,s_password=s_password,s_grade=s_grade) 调用自己封装的类方法 def addStudent(request): grade = Grade.objects.get(pk=2) student = Student.objects.create(s_name='Bool',s_password='poiuytq',s_grade=grade) student.save() return HttpResponse(\"学生数据添加成功4\") 5、使用Manager()中封装方法创建在Models中定义Manager() class Student(models.Model): s_name = models.CharField(max_length=32) s_password = models.CharField(max_length=32) s_grade = models.ForeignKey(Grade) # 多出来这1行，之后调用的时候可以写Student.s_m ，而不是Student.object s_m = models.Manager() 在views中调用Manager() def addStudent(request): grade = Grade.objects.get(pk=2) student = Student.s_m.create(s_name='ZJ',s_password='ILKEY',s_grade=grade) student.save() return HttpResponse(\"学生数据添加成功5\") 6、直接调用类方法添加数据person = Person.create('Neo',18)person.save() 删删除是基于查询的，把查询到的结果进行删除，这里删除的是主键为2的，因为刚刚jack插入了两次，重复了，所以删了。 def delStudent(request): student = Student.objects.get(pk=2) student.delete() return HttpResponse(\"删除成功！\") 改修改是基于查询的，修改后保存。 此时的数据库表： MariaDB [model3]&gt; select * from App_student;+----+--------+------------+------------+| id | s_name | s_password | s_grade_id |+----+--------+------------+------------+| 1 | Jack | 123456789 | 1 || 3 | Niki | 987654321 | 1 || 4 | Rose | abcdefg | 3 || 5 | Bool | poiuytq | 2 || 6 | ZJ | ILKEY | 2 |+----+--------+------------+------------+5 rows in set (0.00 sec) 我们把Bool用户的ZJ用户的Password修改为：oiuytre def modStudent(request): student = Student.objects.get(s_name='ZJ') student.s_password = \"oiuytre\" student.save() return HttpResponse(\"修改成功！\") 查查询句柄objects，objects是Manager()的实例，操作都封装在了objects里面，如Person.objects.all()，如果不想使用object对象，可以重写Manager()方法，详情见增的第5点。 object ——&gt; Manager ——&gt; BaseManager ——&gt; get_queryset class Manager(BaseManager.from_queryset(QuerySet)): pass BaseManager是个类，类下面有get_queryset方法： def get_queryset(self): \"\"\" Returns a new QuerySet object. Subclasses can override this method to easily customize the behavior of the Manager. \"\"\" return self._queryset_class(model=self.model, using=self._db, hints=self._hints) Student.objects.all()方法是调用的get_queryset方法： def all(self): # We can't proxy this method through the `QuerySet` like we do for the # rest of the `QuerySet` methods. This is because `QuerySet.all()` # works by creating a \"copy\" of the current queryset and in making said # copy, all the cached `prefetch_related` lookups are lost. See the # implementation of `RelatedManager.get_queryset()` for a better # understanding of how this comes into play. return self.get_queryset() 查询方法最后都会归结到get_queryset方法，所以只要对这个方法做封装，就可以实现定制化查询，比如逻辑删除后的查询。 获取查询结果集all、filter、exclude、order_by、values、切片 链式调用：person.objects.filter().filter()…..exclude()… all返回所有数据 def queStudent(request): students = Student.objects.all() ''' print(\"数据:\",students,\"类型:\",type(students)) 数据: &lt;QuerySet [&lt;Student: Student object&gt;, 。。。。&gt; 类型: &lt;class 'django.db.models.query.QuerySet'&gt; ''' for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name,student.s_password)) ''' 姓名：Jack 密码：123456789 姓名：Niki 密码：987654321 姓名：Rose 密码：abcdefg 姓名：Bool 密码：poiuytq 姓名：ZJ 密码：oiuytre ''' return HttpResponse(\"查询成功\") filter过滤操作，将符合条件的对象过滤出来，exclude和filter相反，exclude是过滤出不符合条件的数据 def queStudent(request): students = Student.objects.filter(pk__gt=3) # 主键 &gt;3 for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name,student.s_password)) ''' 姓名：Rose 密码：abcdefg 姓名：Bool 密码：poiuytq 姓名：ZJ 密码：oiuytre ''' return HttpResponse(\"查询成功\") order_by依照指定的字段名进行排序输出 def queStudent(request): students = Student.objects.order_by('-s_name') # 负号表示反序 for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name,student.s_password)) ''' 姓名：ZJ 密码：oiuytre 姓名：Rose 密码：abcdefg 姓名：Niki 密码：987654321 姓名：Jack 密码：123456789 姓名：Bool 密码：poiuytq ''' return HttpResponse(\"查询成功\") valuesdef queStudent(request): students_all = Student.objects.values() # 以字典的形式返回 for students in students_all: # 把每个用户字典集中取出来 print(\"-------------------------------------\") for student in students.items(): # 把用户的每个元素从字典中取出来 print(student) return HttpResponse(\"查询成功\") slice 和Python中的切片不太一样 QuerySet[5:15] 获取第5到15条数据，相当于SQL中的Limit和Offset def queStudent(request): students = Student.objects.all()[0:2] for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name,student.s_password)) ''' 姓名：Jack 密码：123456789 姓名：Niki 密码：987654321 ''' return HttpResponse(\"查询成功\") 获取查询条件的单个对象first、last、get、exist first返回查询集中的第一个对象 def queStudent(request): student = Student.objects.last() # 返回查询的最后个对象 print(student.s_name) return HttpResponse(\"查询成功\") last返回查询集中的最后一个对象 def queStudent(request): student = Student.objects.last() # 返回查询的第一个对象 print(student.s_name) return HttpResponse(\"查询成功\") get返回一个满足条件的对象，如果没有找到符合条件的对象， 会引发DoesNotExist异常，如果找到多个，会引发模型MultiObjectsReturned异常，可以使用try ... except 模型类.异常...的方式捕获异常。 def queStudent(request): try: student = Student.objects.get(pk=11) print(student.s_name) except Student.DoesNotExist: print(\"用户不存在\") except Student.MultipleObjectsReturned: print(\"存在多个用户\") return HttpResponse(\"查询成功\") exist判断查询结果是否存在 def queStudent(request): result = Student.objects.filter(s_name='ZJ').exists() print(result) return HttpResponse(\"查询成功\") 查询条件表达式：属性__操作符=临界值 - gt 大于- lt 小于- gte 大于等于- lte 小于等于- in 在某一集合中- contains 类似于模糊查询like- startswith 以xx开始，本质也是like- endswith 以xx结束，也是like- exact 精确等于,相当于 == - 前面同时添加i , ignore 忽略 - iexact 忽略大小写的匹配 - icontains - istartswith - iendswith- isnull 、isnotnull- django中查询条件有时区问题 - 关闭django中自定义的时区 - 在数据库中创建对应的时区表 示例： def queStudent(request): students = Student.objects.filter(pk__gt = 2) for student in students: print(student.s_name) return HttpResponse(\"查询成功\") FQ对象F对象和Q对象 F对象 可以获取我们属性的值 可以实现一个模型不同属性的运算操作 还可以支持算术运算 # 可以使用模型的A属性与B属性进行比较grades = Grade.objects.filter(ggirlnum__gt=F('gboynum') )# F对象支持算数运算grades = Grade.objects.filter(ggirlnum__gt=F('gboynum') +10 ) Q对象 过滤器的方法中的关键参数，常用于组合条件 对查询条件进行封装， 封装之后支持逻辑运算 与 &amp; and 或 | or 非 ~ not def queStudent(request): # 查询主键值在[2,4]之间的用户 students = Student.objects.filter(Q(pk__gte = 2) &amp; Q(pk__lte =4)) for student in students: print(student.s_name) return HttpResponse(\"查询成功\") 聚合函数使用aggregate()函数返回聚合函数的值 Avg：平均值 Count：数量 Max：最大 Min：最小 Sum：求和 def queStudent(request): result = Student.objects.aggregate(Count('s_name')) print(result) ''' &#123;'s_name__count': 5&#125; ''' return HttpResponse(\"查询成功\") 逻辑删除对于重要数据都做逻辑删除，不做物理删除，实现方法是定义isDelete属性，类型为BooleanField，默认值为False。 修改数据库表单 class Student(models.Model): s_name = models.CharField(max_length=32) s_password = models.CharField(max_length=32) s_grade = models.ForeignKey(Grade) is_delete = models.BooleanField(default=False) 进行文件迁移 python manage.py makemigrationspython manage.py migrate 先查询所有项 # 查询函数def queStudent(request): students = Student.objects.filter(is_delete=False) for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name, student.s_password)) return HttpResponse(\"查询成功\") 结果 姓名：Jack 密码：123456789姓名：Niki 密码：987654321姓名：Rose 密码：abcdefg姓名：Bool 密码：poiuytq姓名：ZJ 密码：oiuytre 删除其中某项 # 实际上是把is_delete字段修改为True，并不是真的删除def modStudent(request): student = Student.objects.get(s_name='ZJ') student.is_delete = True student.save() return HttpResponse(\"修改成功！\") 再次查询结果： 姓名：Jack 密码：123456789姓名：Niki 密码：987654321姓名：Rose 密码：abcdefg姓名：Bool 密码：poiuytq 这样做可以实现对重要数据不是真的删除，但是有一个缺点，我们每次查询的时候，都需要加上is_delete=False这样一个选项，能不能有什么改进的措施呢？ 可以通过自定义Manager实现统一封装，重写get_queryset方法，这样就不需要在查询的时候写filter(is_delete=False) 1、修改models.py from django.db import modelsclass Grade(models.Model): g_grade = models.CharField(max_length=16)class StudentManager(models.Manager): def get_queryset(self): return super(StudentManager,self).get_queryset().filter(is_delete=False)class Student(models.Model): s_name = models.CharField(max_length=32) s_password = models.CharField(max_length=32) s_grade = models.ForeignKey(Grade) is_delete = models.BooleanField(default=False) objects = StudentManager() # 对Manager的实例Objects的get_qeuryset方法在进行一层封装 2、这样查询语句中的is_delete字段就可以去掉了 def queStudent(request): students = Student.objects.filter() for student in students: print(\"姓名：&#123;0&#125; 密码：&#123;1&#125; \".format(student.s_name, student.s_password)) return HttpResponse(\"查询成功\") 多表查询·分类 ·ForeignKey：一对多，将字段定义在多的端中 ·ManyToManyField：多对多，将字段定义在两端中 ·OneToOneField：一对一，将字段定义在任意一端中·用一访问多 ·格式 ·对象.模型类小写_set ·示例 grade.students_set·用一访问一 ·格式 ·对象.模型类小写 ·示例 ·grade.students·访问id ·格式 ·对象.属性_id ·示例 ·student.s_grade_id 1、通过学生的姓名查询学生所在的班级，使用外键作为连接： def queStudent(request): student = Student.objects.get(s_name='Rose') print(student.s_grade.g_grade) # Science return HttpResponse(\"查询成功\") 2、直接查询 def queStudent(request): grade = Grade.objects.get(student__s_name='Rose') print(grade.g_grade) # Science return HttpResponse(\"查询成功\") 缓存集 filter、exclude、all 都不会真正的去查询数据库 只有我们在迭代结果集，或者获取单个对象属性的时候，它才会去查询数据库 懒查询：为了优化我们结构和查询","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://ymlog.cn/tags/Django/"}]},{"title":"Mysql常用语句","slug":"SQL","date":"2020-03-02T04:55:14.000Z","updated":"2020-07-04T17:18:15.326Z","comments":true,"path":"2020/03/02/SQL/","link":"","permalink":"http://ymlog.cn/2020/03/02/SQL/","excerpt":"念两句诗世味年来薄似纱，谁令骑马客京华。小楼一夜听春雨，深巷明朝卖杏花。矮纸斜行闲作草，晴窗细乳戏分茶。素衣莫起风尘叹，犹及清明可到家。","text":"念两句诗世味年来薄似纱，谁令骑马客京华。小楼一夜听春雨，深巷明朝卖杏花。矮纸斜行闲作草，晴窗细乳戏分茶。素衣莫起风尘叹，犹及清明可到家。 Init初始安装和创建授权用户 # 查看是否已经安装rpm -qa mariadb# 安装mysql和服务端yum -y install mariadb-server mariadb# 开启mysql进程systemctl start mariadb# 初始化mysql，主要是创建root用户的密码，如果没有这步，root密码为空mysql_secure_installation# 创建用户create user 'username'@'localhost' IDENTIFIED BY 'userpasswd';# 授权用户grant all privileges on *.* to 'username'@'localhost';# 创建用户并授权,并授权指定数据库下所有表,而非所有数据库grant all on dbname.* to 'username'@'localhost' identified by 'userpasswd';# 删除用户drop user 'username'@'localhost';# 刷新mysql系统权限相关表flush privileges;# 显示当前用户select user();# 显示所有用户select User, Host, Password FROM mysql.user; DB_SQL数据库的库语句，包括数据库的创建，删除，字符集等。 # 查看当前MySQL中有哪些数据库show databases;# 查看选中数据库详情show create database &lt;db_name&gt;\\G# 创建数据库create databases &lt;db_name&gt;;# 使用数据库use &lt;db_name&gt;;# 删除数据库drop database &lt;db_name&gt;;# 设置字符集create database &lt;db_name&gt; default charset 'utf8'; TB_SQL表语句包括创建表、删除表、查看表以及定义表中字段的属性。其中定义表中字段属性往往比创建表更值得研究。 表语句 # 首先还是解决一下创建表时常见的字符集问题create table tableName(...)DEFAULT CHARSET=utf8mb4;# 创建表 create table tb_name(...);# 查看表show tables;show table status like '&lt;tb_name&gt;'\\G# 删除表drop tables &lt;tb_name&gt;;# 修改表alter table &lt;old_name&gt; rename &lt;new_name&gt; 实例： MariaDB [demo]&gt; DESC myt7;+-------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || sex | char(10) | YES | | man | |+-------+----------+------+-----+---------+----------------+/* NULL：是否可以存储NULL值 Key：是否已经编制索引，PRI表示该列是主键的一部分；UNI表示该列是UNIQUE索引的一部分，NULL表示在列中某个给定值允许出现多次 Default：表示该列是否有默认值 Extra：获取该列的附加信息*/ 实例 //查询后删除表MariaDB [demo]&gt; select group_concat(table_name) from information_schema.tables where table_schema='demo';+----------------------------+| group_concat(table_name) |+----------------------------+| fruits,sping,suppliers,x,y |+----------------------------+drop tables fruits,sping,suppliers,x,y; 字段 1、SQL主键的六种约束 名称 含义 PRIMARY KEY 主键约束，记录唯一标识，主键自动拥有not null及 unique约束 NOT NULL 非空约束，强制字段有值 UNIQUE 唯一约束，该字段值必须唯一 FOREIGN KEY 外键，预防破坏表之间的连接行为，防止非法数据插入外键列 CHECK 限制列的取值范围 DEFAULT 设置默认值 AUTO_INCREMENT 自动增加字段，且字段类型必须为整型主键一部分 实例： 1create table my1( id INT PRIMARY KEY NOT NULL AUTO_INCREMENT, name VARCHAR(20) NOT NULL UNIQUE , sex char(2) NOT NULL DEFAULT 'm' );2//主键约束create table myt3( name VARCHAR(50), salary FLOAT, PRIMARY KEY(name,salary));3//外键约束/* 外键表：即当前这张表 主键表：mainTable 绑定的主键：main_key_name 绑定的外键：foreign_key_name 绑定名称：foreign_name constraint ： 约束*/constraint (foreign_name) foreign key(foreign_key_name) references mainTable(main_key_name) 修改字段语句 # 修改字段类型和字段名alter table &lt;tb_name&gt; change &lt;old_field&gt; &lt;new_field&gt; INT(15);# 修改字段的类型和字段名alter table &lt;tb_name&gt; add &lt;new_field&gt; INT(15) AFTER|FIRST &lt;field&gt;;# 删除字段alter table &lt;tb_name&gt; drop &lt;field&gt;;# 修改字段的排列位置alter table &lt;tb_name&gt; modify &lt;f1&gt; type FIRST|AFTER &lt;f2&gt;;# 修改字段的数据类型alter table &lt;tb_name&gt; modify &lt;field&gt; INT(20);# 更改存储引擎alter table &lt;tb_name&gt; engine=&lt;en_name&gt;;# 删除外键约束alter table &lt;tb_name&gt; drop FOREIGN KEY 外键约束名;# 删除没有关联的表drop table IF EXISTS &lt;tb1&gt;,&lt;tb2&gt;; 总结： change用来修改KEY本身 modify则修改KEY的属性 后面直接和定义语法一样，千万别忘了后面的类型，如…INT(11)，不然会报错 FIRST：将字段设置为表的第一个字段 AFTER：将新添加的字段添加到指定字段的后面 实例 删除两个有关联的表create table pt( id int(11) PRIMARY KEY,name varchar(30));create table subt( id int(11) PRIMARY KEY, depId int(11), CONSTRAINT fk_name FOREIGN KEY (depId) REFERENCES pt(id));/* 不能直接 drop pt，但可以直接删除subt 先解除关联，再删除主表*/ alter table subt drop FOREIGN KEY fk_name; drop table pt; SQLinsert # 两种数值插入的方式insert into &lt;tb_name&gt; (coloumn_list) VALUES (value_list);insert into &lt;tb_name&gt; VALUES (value_list);# 将查询到的结果插入insert into table1 (coloumn_list) select (coloumn_list) from table2 WHERE (condition);for exampleMariaDB [demo]&gt; insert into my1 -&gt; select id,name,age from my2 WHERE id&gt;2; update update &lt;tb_name&gt; SET column_name1=value1,column_name2=value2,.... WHERE condition; delete DELETE from &lt;tb_name&gt; [WHERE condition];/如果没有WHERE，则删除表中所有记录。 NB.selectselect 字段1，字段2，字段3...-&gt; from [表1],[表2]... //数据来源-&gt; WHERE 表达式 //查询的条件-&gt; GROUP BY (group by definition) //如何显示查询数据，按照指定字段分组-&gt; HAVING (expression) [(operator) (expression)] -&gt; ORDER BY (order by definition) //用什么样的顺序显示查询的数据，ASC(升序)、DESC(降序)-&gt; LIMIT [(offset),] (row count) //限制显示条数select &#123;字段1，字段2，字段3，...&#125;from &#123;表或视图&#125;WHERE &#123;查询条件&#125;; 过滤,排序,分组。排序要在过滤之后，不然报错 数据源 # 创建库create database db_test default charset 'utf8';# 创建表create table person ( id INT NOT NULL AUTO_INCREMENT, name CHAR(20) NOT NULL, book VARCHAR(50) NOT NULL, dynasty VARCHAR(10) DEFAULT 'China', PRIMARY KEY(id) )DEFAULT CHARSET=utf8mb4;# 插入值 insert into person (name,book,dynasty) VALUES ('王阳明','传习录','ming');insert into person (name,book) VALUES ('林清玄','白雪少年');insert into person (name,book,dynasty) VALUES ('孔子','论语','chunqiu');insert into person (name,book,dynasty) VALUES ('老子','道德经','chunqiu');insert into person (name,book,dynasty) VALUES ('李白','蜀道难','tang');insert into person (name,book,dynasty) VALUES ('陈子昂','登幽州台歌','tang');# 查看插入的值select * from person; 简单查询 MariaDB [nikitest]&gt; select id,name,book,dynasty from person where id in (01,02,06) AND dynasty='tang';+----+-----------+-----------------+---------+| id | name | book | dynasty |+----+-----------+-----------------+---------+| 6 | 陈子昂 | 登幽州台歌 | tang |+----+-----------+-----------------+---------+ 别名查询 MariaDB [nikitest]&gt; select id as ID,name as NAME,book as BOOK,dynasty as DYNASTY from person as f where f.id &lt; 5;+----+-----------+--------------+---------+| ID | NAME | BOOK | DYNASTY |+----+-----------+--------------+---------+| 1 | 王阳明 | 传习录 | ming || 2 | 林清玄 | 白雪少年 | China || 3 | 孔子 | 论语 | chunqiu || 4 | 老子 | 道德经 | chunqiu |+----+-----------+--------------+---------+//即将字段以别名显示，同时将表也以表明显示（这里用的是f-&gt;person，所以条件查询f下的字段就可以写成f.id) 排序 //单列排序，DESC反序select DISTINCT id,name,book, dynasty from person order by id DESC;//多列排序，先按照朝代排序，相同朝代的再按照名称排序select DISTINCT id,name,book, dynasty from person order by dynasty DESC,name; 分组 //同类分为一组，通过GROUP_CONCAT(field)显示详细信息&gt; select group_concat(name),dynasty from person group by dynasty;+--------------------+---------+| GROUP_CONCAT(name) | dynasty |+--------------------+---------+| 林清玄 | China || 孔子,老子 | chunqiu || 王阳明 | ming || 李白,陈子昂 | tang |+--------------------+---------+ 过滤 //查看同一时代的人，过滤出人数&gt;1的&gt; select group_concat(name), dynasty from person group by dynasty having count(dynasty)&gt;1;+--------------------+---------+| group_concat(name) | dynasty |+--------------------+---------+| 孔子,老子 | chunqiu || 李白,陈子昂 | tang |+--------------------+---------+ 限制 //限制显示结果为 offset &amp; count&gt; select * from person limit 2;+----+-----------+--------------+---------+| id | name | book | dynasty |+----+-----------+--------------+---------+| 1 | 王阳明 | 传习录 | ming || 2 | 林清玄 | 白雪少年 | China |+----+-----------+--------------+---------+2 rows in set (0.00 sec)//限制显示2个结果，并从第4个开始显示，这里设置了偏移位=4&gt; select * from person limit 3,2;+----+--------+-----------+---------+| id | name | book | dynasty |+----+--------+-----------+---------+| 4 | 老子 | 道德经 | chunqiu || 5 | 李白 | 蜀道难 | tang |+----+--------+-----------+---------+ AF函数aggregate function，mysql内置聚合函数 函数 作用 AVG() 列数值均值 COUNT() 个数，忽略空行,COUNT(*)计算表中总行数，不忽略空行 MAX() 列数值最大 MIN() 列数值最小 SUM() 列数值和 实例 select id,name,book,MAX(dynasty) from person;| 0111 0100 | 0164 | 116 | 0x74 | t || 0110 0011 | 0143 | 99 | 0x63 | c || 0110 1101 | 0155 | 109 | 0x6D | m |//这里t最大，所以选出来tang 这里只介绍了基础的SQL语句，后面还有连接查询、子查询、合并查询等……..","categories":[{"name":"数据库","slug":"数据库","permalink":"http://ymlog.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ymlog.cn/tags/MySQL/"}]},{"title":"Switch交换机","slug":"Switch","date":"2020-02-27T12:34:14.000Z","updated":"2020-07-04T17:18:12.173Z","comments":true,"path":"2020/02/27/Switch/","link":"","permalink":"http://ymlog.cn/2020/02/27/Switch/","excerpt":"念两句诗浮云一别后，流水十年间。","text":"念两句诗浮云一别后，流水十年间。 交换技术主要用于构建局域网，主要实现的局域网内的通信和隔离。交换机即插即用，因为所有的接口默认分配在vlan 1 中，且vlan 1为native vlan，不需要进行封装。为了实现局域网的隔离，可以将不同的接口或者MAC地址划分到不同的vlan，同一个vlan下的地址可以相互通信。 交换机主要存在的问题和解决方法： 广播风暴，链路防环：使用Spanning-Tree或者快速生成树(MSTP、RSTP等)以及一系列生成树补丁来解决 Vlan同步：交换机不能转发自己没有的vlan信息，比如一个只有vlan 10,20,30的交换机不能转发和接受vlan40的报文，有两种解决方式：（1）手动配置使之相同 （2）VTP vlan同步协议 带宽受限：因为spanning-tree的缘故，两个交换机之间只能存在一条链路，因此带宽受限。可以使用二层或三层链路捆绑，提高网络带宽 网关单点故障：因为只有一个默认网关，所以当down了之后，终端就无法与外界通信。可以使用网关冗余协议，如(FHRP,VRRP,GLBP)做高可用。 讲到交换机不得不讲MAC地址，MAC地址和交换机同属于OSI七层的第二层——数据链路层。MAC地址一共有48位，前24位厂家分配，类似于手机的前几位网络识别号。MAC地址有如下字段： 其中： 类型：用于标识上一层使用的协议 IP数据报长度：46 = 64 - 6 - 6 - 2 - 4 FCS：帧检验序列，使用CRC循环冗余校验 配置VLANps：vlan的隔离包括广播，即使是发ARP，也只会发在自己的vlan。 # SW7 创建vlanvlan 10,20# SW7 将接口加入到vlan，e0/1,2 e1/0,1 都是这样配int e0/1switchport mode access # 将接口模式改为accessswitchport access vlan 10 # 将接口加入到vlan 10 中# SW7 串口配置，即和SW8连接的e0/3接口int e0/3switchport trunk encapsulation dot1q # 一律使用802.1Q封装switchport mode trunk # 改变接口的模式为trunk 交换机接口的三种模式：Vlan的链路类型可以分为接入链路和干道链路。 Access：只能属于1个VLAN，且该端口不打tag，一般用于连接计算机端口； Trunk：可以允许多个VLAN通过，且该端口都是打tag的，一般用于交换机之间的连接； Hybrid：可以允许多个VLAN通过，至于该端口在vlan中是否打tag由用户根据具体情况而定，可以用于交换机之间的连接也可以用于交换机和用户计算机之间的连接。 Trunk和Hybrid的区别主要是，hybrid端口可以允许多个vlan的报文不打标签，而 trunk端口只允许缺省vlan的报文不打标签，同一个交换机上不能hybrid和trunk并存。 Trunk也可以由交换机自行协商，但一般都是网络管理员手动配置。 VTPVTP用于Vlan同步，分为三种模式：服务端(server)、客户端(client)、透传端(transparent)，客户端只可以查看不可以修改，服务端和透传端既可以查看又可以修改。 VTP只会同步vlan和vlan的名字，vlan的接口信息不会被同步走。 配置VTP # 配置服务端vlan 10-20 # 创建vlanvtp domain cisco # 更改域名， 可以改可以不改，用于让一个局域网有许多vtpvtp mode server # 将本机vtp的模式改为server# 配置透传端vtp domain ciscovtp mode transparent# 配置客户端vtp domain ciscovtp mode client 其他命令 Switch#sh vlan brief # 查看本机vlan摘要Switch#sh vtp ? # 查看vtp相关 VTP修剪：一种优化vlan的方法 A ----> B -----> C -----D(I'm a PC) vtp pruning # 开启vtp修剪 比如：A、B、C是交换机，D是PC。 A的vlan：10，20，30，40 B的vlan：10，20 C的vlan：10，20 一旦开启vtp修剪，则C会告诉B：”我这没有vlan30，40，以后不要给我发vlan30，40的广播或者其他消息了”，B收到后会告诉A：”我这没有vlan30 ，40，以后不要发这个vlan的消息了”。A就会把这接口上的这两个vlan剪掉。 生成树生成树（Spanning-tree）是一种工作在OSI网络模型中的第二层（数据链路层）的通信协议，基本应用是防止交换机冗余链路产生的环路.用于确保以太网中无环路的逻辑拓扑结构.从而避免了广播风暴,大量占用交换机的资源。 生成树使用封锁接口的方式避免环路，被封锁的接口有如下判定方式： 每个广播域选择一个根桥（注意是广播域，不是局域网）Root Bridge 每个非根桥选择一个根端口 Root Port 每个段选择一个指定端口 Designated Port 选择一个非指定端口，以上所有选择策略，都是以越小越优为准则 根桥的制定：谁的MAC地址最小，谁就是根桥 根端口的指定：谁离根桥进，谁就是根端口 指定端口的指定： 离根桥近 COST值小 发送者的端口ID小，端口ID即交换机的接口 非指定端口将被封锁。 全网一开始是如何知道谁是根桥？ 全网交换机开机，一开始，每台交换机都认为自己是根桥ID向外发送BPDU报文，如果在收到的BPDU报文中，发现了比自己还小的MAC地址，就把根桥ID改为那一台交换机的ID。经过一段时间，就可以确定全网的唯一的根桥ID。（可以抢占） BPDU报文格式： 字节 字段 描述 2 协议 代表上层协议(BPDU)，该值总为0 1 版本 （802.1D的总为0） 1 TYPE “配置BPDU” 为0，“TCN BPDU”为80，TCN，topology change notification，拓扑改变时发送的报文，自下而上。 1 标志 LSB最低有效位表示TC标志，MSB最高的有效位表示TCA标志 8 根桥ID 根网桥的桥ID 4 路径开销 到达根桥的STP cost，如果是根桥则写0，带宽越大，开销越低 8 网桥ID BPDU发送桥的ID 2 端口ID BPDU发送网桥的端口ID（优先级+端口号），优先级默认128 2 消息寿命Message age 从根网桥发出BPDU之后的秒数，每经过一个网桥都减1，本质上是到达根桥的跳数 2 最大寿命Max age 当一段时间未收到任何BPDU，生存期达到MAX age，网桥认为该端口连接链路发生故障，默认20S 2 HELLO时间 根网桥连续发送BPDU之间的时间间隔，默认2S 2 转发延迟 在监听和学习状态停留的时间间隔，默认15S 关于生成树，要配置的内容很少，都是现象，因为一切默认都已经配置好了，除非是改变生成树的种类。 show spanning-tree #查看生成树的状态spanning-tree vlan 1 priority 4096 #修改VLAN中spanning-tree的优先级。必须是4096的倍数VLAN0001 #VLAN 1 Spanning tree enabled protocol ieee Root ID Priority 32769 #32769=32768+VLAN.Nbr Address aabb.cc00.0100 #MAC地址 Cost 100 #这个VLAN的COST值 Port 2 (Ethernet0/1) #RootID所用的端口 Hello Time 2 sec Max Age 20 sec Forward Delay 15 sec #Hello报文2s，最大寿命20s，转发延迟15s Bridge ID Priority 32769 (priority 32768 sys-id-ext 1) #系统扩展ID就是VLAN 的序号 Address aabb.cc00.0300 Hello Time 2 sec Max Age 20 sec Forward Delay 15 sec Aging Time 300 sec #网络拓扑变化时，会变成15s，快速刷新mac表Interface Role Sts Cost Prio.Nbr Type------------------- ---- --- --------- -------- --------------------------------Et0/0 Desg FWD 100 128.1 ShrEt0/1 Root FWD 100 128.2 ShrEt0/2 Altn BLK 2 128.3 ShrEt0/3 Desg FWD 100 128.4 Shr接口 角色 端口状态 Cost值 优先级.序号 类型 生成树中的端口状态 状态 说明 Disabled 不收发任何报文 Blocking 不接受也不转发帧，接受但不发送BPDU，不学习MAC地址 Listening 不接受也不转发帧，接受并且发送BPDU，不学习MAC地址 Learning 不接受也不转发帧，接受并且发送BPDU，学习MAC地址 Forwarding 接收并转发帧，接受并且发送BPDU，学习MAC地址 状态转换： 实验现象 R6 ping R7原本sw4的e0/3没有连接sw1的e0/3，现在将他们连接起来。此时，链路会有30s的不通，这是spanning-tree协议工作：原本的路由是R6 -- SW4 -- SW3 -- SW2 --SW1 --R7现在SW4和SW1连通，造成了SW3的e0/2接口发生了阻断BLK。路由路线变为：R6 -- SW4 -- SW1 -- R7SW4的e0/3接口从LIS -- LRN -- FWD需要30s的时间，所以30sping不通。然后将sw4的e0/3 shutdown ,SW3发现没有BPDU出现了，进入Lost BPDU Max age=20s，20sBPDU不出现，然后进入Listening（15s）和Learning（15s），一共恢复需要30s。 生成树拓扑变化也叫STP 拓扑变化。 Topology Change Notification Bridge Protocol Data Unit = TCN BPDU 网络拓扑变更报文 网桥协议单元，即当下层交换机拓扑发生变化时，次级交换机向Root Bridge传递TCN BPDU报文，即BPDU字段中的Type改为80。沿着根端口就可以最终把报文传送给Root，Root接收到后，发送TC标志设置，内容为空，目的是为了泛洪。 35s = age老化时间（20s） + Learning（15s）[生成树的计算时间] Portfast：快速端口一个接口从开启到能正常运行会经历三个阶段，需要一定的时间。这是为了防止环路。如果不需要防环，可以使用Portfast来快速启动，这样已启动就变成FWD。 配置命令 spanning-tree portfast PVST+：Peer Vlan Spanning-Tree Plus每个VLAN都有一个生成树，Cisco私有。 Cisco Catalyst交换机的MAC地址池最多可以容纳1024个地址，交换机的型号决定了可用MAC的数目，并不是所有catalyst交换机都能支持到这么多个MAC 这些MAC地址作为VLAN生成树中的网桥ID的MAC地址部分，不同交换机型号支持不同的可用MAC地址数目，交换机依照次序分配MAC地址 show run int | include bia可以看到所有的MAC，其中第一个MAC将被生成树使用，也就是CPU的MAC，接下去就是每个以太网接口的MAC 我们知道交换机能够支持的VLAN数据是很庞大的，如果开启PVST+，每个VLAN一棵生成树，而每棵生成树都要有一个独立的标识，都需要耗费MAC的话，那么MAC地址池肯定是无法承受的 因此需要用到MAC地址缩减方案，这也是为什么优先级必须是4096倍数的原因。 show spanning-treePriority 4097 (priority 4096 sys-id-ext 1)#因为系统扩展ID是1，所以优先级要+1#系统扩展ID=1是因为VLAN是1 实验： VLAN 10,20 SW1为Root VLAN 30,40 SW2为Root show spanning-tree #查看生成树的状态spanning-tree vlan 1 priority 4096 #修改PVST+的优先级spanning-tree vlan 10,20 root primary #将vlan10,20的优先级比当前环境下最小的优先级低两个档次spanning-tree vlan 10,20 root primary #将vlan10,20的优先级比当前环境下最小的优先级低一个档次 快速生成树由于生成树的速度过慢，一般会采用快速生成树。数据中心不会使用生成树，而是大二层的结构，但园区网还是会用到生成树。下面介绍两种快速生成树，一种是Cisco私有的RSTP，一种是公开的MSTP。 RSTP：Rapid Spanning Tree Protocol特点： 802.1W 端口角色：根端口、指定端口、替代端口、备份端口 端口状态：转发、丢弃、学习 在Cisco Catalyst交换机上，PVST+是基于RSTP实现的perVLAN版本 配置： spanning-tree mode rapid-pvst #BPDU的速度又多了快这个生成树就有多快 MSTP：Multiple Spanning Tree Protocol集成了RSTP的优点，每实例一个生成树，PVSTP是每个vlan一颗生成树。 spanning-tree mst configurationinstance 1 vlan 10,20 # 创建实例，并把vlan10，20归入实例1instance 2 vlan 30,40show pending#配置优先级，系统扩展id变为实力号Instance.NbrSW1spanning-tree mst 1 root primary spanning-tree mst 2 root secondarySW2spanning-tree mst 1 root secondaryspanning-tree mst 2 root primary 生成树补丁Spanning-tree Patch，主要有六种生成树补丁，针对解决生成树反应慢、出差错、及故障检测。 1、BPDUGuard该接口在手都BPDU报文后，会立即切换到err-disable状态,把接口down了，常搭配portfast特性在接口上一起使用，用于连接主机，可在接口模式上激活，也可在全局模式上配置，两者有所不同。 spanning-tree bpduguard enable # 接口spanning-tree portfast bpduguard default # 全局show err recov # 查看状态 2、BPDUFilter一旦收到BPDU，就把接口上的Portfast删除。相当于可以智能判断是PC还是Switch。 spanning-tree portfast bpdufilter default # 全局spanning-tree bpdufilter enable # 接口 3、UplinkFast当唯一的根端口Down，立刻切换到转发状态 ，跳过了LIS和LER的30s延时,但还有20s的max age 。所有配置了Uplink的交换机，都会把自己的优先级升高、COST值增加3000，防止自己成为ROOT。 spanning-tree uplinkfast 4、BackboneFast 在部署了Backbone Fast后，SW3一旦收到SW2发送来的次优BPDU，会立即进行一系列的步骤以重新计算根端口，SW3会从跟端向根桥发送RLQ请求 Root SW1收到RLQ请求，立刻以RLQ响应进行恢复，以告知自己仍然存活 SW3立刻老化掉存储在Fae0/3上的BPDU，端口Fa0/3进入Listening状态开始发送BPDU SW2从SW3收到BPDU，经过计算得出自己的Fa0/2为根端口 相当于去掉了20s BLK状态 spanning-tree backbonefast 5、RootGuard 只要Service-Provider Network端收到其他地方发来的更优质的BPDU，就将那个区域置为inconsistent。注意inconsistent跟err-disable的区别是，err-disable会disable整个接口，而inconsistentport是针对特定的vlan的。 只会屏蔽当前VLAN(发给我更优的BPDU)spanning-tree guard root # 接口上配置root防护，这个端口就不可以成为根段偶show span inconsistentport # 查看接口 6、LoopGuard spanning-tree guard loop #接口上配置loop防护，这个端口就可以检测单向通行故障 单臂路由单臂路由，路由器只有一条线连接，是三层交换机的替代品。其主要缺点就是三层交换机的优点： 故障多，路由器的故障， 交换机的故障，路由器到交换机只有一条链路，单点故障 带宽有限，如果是三层交换机，则三层交换机中的路由器和交换机传输速率几乎无限 ` R1int e0/0no shint e0/0.10encapsulation dot1Q 10ip add 192.168.10.254 255.255.255.0int e0/0.20encapsulation dot1Q 20ip add 192.168.20.254 255.255.255.0endsh int e0/0.10#swint e0/1sw tr en do sw mo trend#交换机还要反应一会，从LIS-LRN-FWD此时，R2 Ping R3 三层交换三层交换就相当于二层交换加了一台路由器在上面，可以实现更加灵活的网络流量路由管控。 现在R2处于vlan10，R3处于vlan20，想要R2 ping通R3 ，在SW上进行配置： 1、 配置接口 vlan 10，添加属于R2网段额IP地址 2、配置接口 vlan 20， 添加属于R3网段的IP地址 3、在R2和R3上配置默认路由 4、 然后就会发现，R2可以直接ping通R3了 #SWint vlan 10 #启用SVI接口，Lay3SW的交换机接口是虚拟的ip add 192.168.10.254 255.255.255.0no shendsh ip int briint vlan 20ip add 192.168.20.254 255.255.255.0no shendsh ip int bri#R，一定要记得配默认路由ip route 0.0.0.0 255.255.255.255 Ethernet0/0 SVI(switch virtual interface) 交换虚拟接口的Line-State在以下条件满足的情况下，才会是UP SVI对应的VLAN必须在vlan database中存在并且是激活的——vlan存在且激活 vlan interface存在并且不能是down状态——路由器接口up 必须至少有一个二层接口是UP的，而且必须是Spanning-tree的FWD状态——二层交换机接口up DHCP Dynamic Host Configuration Protocal 基于UDP协议端口67及68 bootPC：67（客户端端口号）；bootPS：68（服务端端口号） 这四条消息全部都是广播。 配置DHCP (config-if)# ip dhcp pool cisico(dhcp-config)# network 192.168.1.0/24(dhcp-config)# default-router 192.168.1.1 # 默认路由器(dhcp-config)# dns-server 114.114.114.114 114.114.115.115 # DNS(dhcp-config)# lease 1 -租约时间1天(config)# ip dhcp excluded-address 192.168.1.1 # 排除掉我们用的地址还有一种写法：1~99不分配ip dhcp excluded-address 192.168.1.1 192.168.1.99#局域网的其他设备(config)# ip add dhcp sh ip dhcp bingding #查看DHCP的IP地址的绑定#绑定IP地址ip dhcp pool R1host 192.168.1.10client-identifier [client-id]#如果client_id已被使用，则清楚clear ip dhcp bind * #跨越路由器的广播DHCP请求R4是DHCP服务器，R1想要请求DHCP的广播不能跨越R3，这是可以在R3上进行配置，如果收到请求DHCP的报文，则用单播的形式将消息发送给R4R3int e0/1ip helper-address 192.168.34.4 链路捆绑如果直接连接两个交换机，则会因为有spanning-tree，造成无论链接多少线，都只会有一根通，从而带宽得不到提高。链路捆绑最大支持8根线绑在一起，这里只介绍二层捆绑，三层捆绑要在接口上no switchport，然后再配置IP地址 EC：需要对端交换机都配 int range e0/1 -2channel-group 1 mode on此时再看生成树，就会发现e0/1和e0/2都消失了，只留下了Po1，查看带宽，也变大了。配置Trunkint port-channel 1 sw tr en do sw mo tr查看channelsh etherchannel [summary] 修改负载均衡的方式 port-channel load-balance [] # src-dst-mac#二层不能用IP地址show etherchannel loadbalance 首跳冗余协议FHRP：first hop redundancy protocal，用于配置多个网关，配在多个朝内的接口上。常用的FHRP协议有： HSRP VRRP GLBP HSRP其中以VRRP最常见，HSRP是Cisco私有的，GLBP有Bug。 @不让R2和R3建立邻居R2# passive-interface e0/1R3# passive-interface e0/1 @配置网关,R4网关指向的地址不存在R4# ip route 0.0.0.0 0.0.0.0 192.168.1.254@在R2,R3上配置standby ip 监听一个虚拟的IPint e0/1standby 1 ip 192.168.1.254sh standby brief #查看standby的缩略信息- standby 会向组播地址发送信息- R2、R3会发现彼此，通过IP地址选出一个人来做网关#上图是交换机，实际上交换机不行，需要换成集线器 这个IP地址是规定死的，最后一位表示standby 1 HSRP状态机 State 说明 Initial 初始化接口状态，当接口UP时，或者某些配置变更时会有的状态 Learn 接口未设定虚拟IP（但激活了HSRP，用standby ip），等待从Active路由器学习到该组的虚拟IP Listen 路由器已经获知虚拟IP，开始侦听其他同组HSRP路由器的HELLO消息 Speak 发送周期性的Hello消息同时参与Active/Standby选举 Standby 成为Standby路由器，同时周期性的发送Hello，持续侦听Active路由器的Hello消息，以便在其失效后接替位置 Active 成为Active路由器，响应PC对于虚拟IP的ARP请求，同时周期性发送Hello消息，宣告自己的存货状态。 (config-if)# standby 1 preempt #打开抢占(config-if)# standby 1 priority 110 #调高优先级@有一种情形@R2的上游支路shutdown了，但是因为R2的优先级比R3大，R4发包还是选择R2，但是却不能ping通R4---@如果R2上面的接口shutdown，则把R2的优先级降低20，这样Standby就被R3抢走(config)# track 1 interface e0/0 line-protocol #在接口的协议上设置一个追踪 (config)# int e0/1 (config-if)# standby 1 track 1 decrement 20 #如果接口shutdown，则将优先级-20，会在show standby上显示详细条目 VRRPVRRP和HSRP不一样的地方 在Cisco上抢占模式不一样，VRRP默认开启 MAC地址不一样，就是开头的固定格式不一样 Hello包发送的周期不一样，HSRP是3s-10s，而VRRP 1s一个Hello包，3s收不到就挂了 激活的状态不一样，一个是backup，一个是active，其他地方一样 GLBP AVG生成一堆虚拟的mac地址分发给局域网里面的路由器（假设有路由器A、B、C），此时有PC1来请求mac地址上网(这个mac地址是默认网关的mac，不是pc自己的mac)，AVG会挑选一台路由器B给它，又有PC2来请求上网，AVG挑选路由器C给它，又有PC3，路由器把A给它。如果路由器B坏了，则重新分配给其他路由器，如果AVG坏了，则路由器重新选举新的AVG。IP地址大则为AVG 所以GLBP抢占的是AVG，而其他的则是抢占干活的机会。 GLBP、VRRP、HSRP配置命令都差不多。","categories":[{"name":"路由技术","slug":"路由技术","permalink":"http://ymlog.cn/categories/%E8%B7%AF%E7%94%B1%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Switch","slug":"Switch","permalink":"http://ymlog.cn/tags/Switch/"}]},{"title":"Ansible","slug":"Ansible","date":"2020-02-24T06:00:36.000Z","updated":"2020-07-04T17:16:08.090Z","comments":true,"path":"2020/02/24/Ansible/","link":"","permalink":"http://ymlog.cn/2020/02/24/Ansible/","excerpt":"念两句诗三过平山堂下，半生弹指声中。十年不见老仙翁。壁上龙蛇飞动。欲吊文章太守，仍歌杨柳春风。休言万事转头空。未转头时皆梦。","text":"念两句诗三过平山堂下，半生弹指声中。十年不见老仙翁。壁上龙蛇飞动。欲吊文章太守，仍歌杨柳春风。休言万事转头空。未转头时皆梦。 简介运维自动化发展历程： 内容 运维自动化发展历程及技术 Ansible命令使用 Ansible常用模块详解 YAML语法简介 Ansible playbook基础 Playbook变量、tags、handlers使用 Playbook模板templates Playbook条件判断when Playbook字段with_items Ansible Roles 自动化运维应用场景： 文件传输 命令执行： 应用部署 配置管理 任务流编排 ansible特性： 模块化，有Paramiko、PyYAML、Jinja2(模板语言)三个关键模块 支持自定义模块 基于Python语言实现 部署简单，基于python和SSH，agentless 安全，基于OpenSSH 支持playbook编排任务 幂等性：一个任务执行1遍和执行n遍的效果是一样的 无需代理，不依赖PKI(无需SSL) 支持其他语言写模块 YMAL格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 常用的自动化运维工具： Ansible：python，Agentless，中小型应用环境 Saltstack：python，一般需要部署agent，执行效率更高 Puppent：ruby，功能强大，配置复杂，重型适合大型环境 Fabric：python，agentless Chef：ruby，国内少 ansible架构 Ansible Playbooks：任务剧本，编排定义Ansible任务集的配置文件，由ANSI不了顺序依次执行，通常是JSON格式的YML文件 Inventory：ANSI不了u案例主机清单/etc/anaible/hosts Modules：Ansible执行命令的功能模块，多数为内置核心模块，可以自定义 Plugins：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API：供第三方程序调用的应用程序编程接口 Ansible：组合Inventory、API、Modules Plugins的绿框，可以理解为是ansible命令工具 安装 yum安装 yum -y install epel-releaseyum -y install ansible git安装 git clone https://github.com/ansible/ansible.gitcd ./ansiblesource ./hacking/env-setup pip安装 yum -y install python-pip python-develyum -y install gcc glibc-devel zibl-devel rpm-bulid openssl-develpip install --upgrade pippip install ansible --upgrade 确认安装 ansible --version 配置文件相关文件 配置文件 /etc/ansible/ansible.cfg：主配置文件，配置ansible工作特性 /etc/ansible/hosts：主机清单 /etc/ansible/roles：存放角色目录 程序 /usr/bin/ansible： 主程序，临时命令执行工具 /usr/bin/ansible-doc：查看配置文档，模块功能查看工具 /usr/bin/ansible-galaxy：下载/上传优秀代码或Role模块的官网平台 /usr/bin/ansible-playbook：定制自动化任务，编排剧本工具/usr/bin/ansible-pull：远程执行命令工具 /usr/bin/ansible-value：文件加密工具 /usr/bin/ansible-console：基于Console界面于用户交互的执行工具 ansible命令 ansible ansible-docansible-playbookansible-valutansible-consoleansible-galaxyansile-pull 配置文件 [root@node01 ~]# vim /etc/ansible/ansible.cfg[defaults]#inventory = /etc/ansible/hosts #主机列表配置文件#library = /usr/share/my_modules/ #库文件存放目录#remote_tmp = ~/.ansible/tmp #临时py命令文件存放在远程主机目录#local_tmp = ~/.ansible/tmp #本机的临时命令执行目录#forks = 5 #默认并发数#poll_interval = 15 #sudo_user = root #默认sudo用户#ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码#ask_pass = True #remote_port = 22#log_path = /var/log/ansible.log #日志文件，默认不记录。如果想打开日志记录，可以取消注释#host_key_checking = False #检查对应服务器的host_key，建议取消注释，取消完ssh可以不敲yes 其中remote_tmp和local_tmp用于执行ansible脚本，当用户在ansible主机上发送命令时，ansible会把命令记录在本地的~/.ansible/tmp/目录，然后发送到受控主机的~/.ansible/tmp目录进行执行，并把执行结果返回给ansible主机。 ansible配置文件改动不需要用systemctl重启，因为ansible不是以服务的形式长驻内存的，它是用的时候临时调出。 Ad-Hocansible命令执行过程 加载自己的配置文件，默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-Nbr/XXX.py文件 给文件+x执行 执行并返回结果 删除py文件，sleep 0 退出 可以使用ansible all -m ping -vvv来展示详细过程 颜色说明 红色：执行失败 绿色：成功，对目标系统没有做任何修改 黄色：成功，对目标系统做出变更 在/etc/ansible/ansible.cfg中的[colors]有说明 ansible用法 [root@node01 ~]# ansible --helpusage: ansible &lt;host-pattern&gt; [-m module_name] [-a args]optional arguments: --ask-vault-pass ask for vault password --list-hosts 列出主机列表，如：ansible webserver --list-all -a MODULE_ARGS, --args 追加模块参数 -f FORKS 连接并发数，默认是5 -t TREE, --tree TREE log output to this directory -v, --verbose 显示详细过程，-vv，-vvv更详细 -K, --ask-become-pass 提示输入sudo密码 -b, --become 代替sudo切换 -T TIMEOUT, --timeout 执行命令的超时时间，默认10s -k, --ask-pass 提示输入ssh连接密码，默认key验证 -u REMOTE_USER, --user 指定连接用户 测试能否ping通另一台主机，这里的Ping不是用ICMP协议，而是用SSH协议 # 首先在主机列表里加入我们的主机echo \"192.168.70.20\" &gt;&gt; /etc/ansible/hostsecho \"192.168.70.30\" &gt;&gt; /etc/ansible/hostsecho \"192.168.70.40\" &gt;&gt; /etc/ansible/hosts# 然后再使用ping命令，如果能通，对方主机会回复一个pong # 这里因为我在`192.168.70.30`上配置了key，所以立刻就能通。下面通过加参数k，来输入密码：ansible 121.36.70.55 -m ping -k#多台主机，用逗号隔开ansible 192.168.70.20,192.168.70.30 -m ping#执行所有主机ansible all -m ping# 通过清单分类ping，清单分类见下文ansible dbserver -m ping 主机清单分组 [dbserver]192.168.70.30192.168.70.20[webserver]192.168.70.10192.168.70.40[appserver]192.168.70.[1:3]#等价于192.168.70.1, 192.168.70.2, 192.168.70.3 docansible-doc用法 # ansible-doc：显示模块帮助ansible-doc [option] [module...] -a 显示所有模块的文档 -l,--list 列出可用模块 -s,--$nippet 显示指定模块的playbook片段# 示例： ansible-doc -l #列出所有模块ansible-doc ping #查看ping模块的帮助文档ansible-doc -s ping #查看ping模块的简略信息 用ansible执行命 ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible端能基于密钥认证的方式联系各被管理的节点 # 查看dbserver组里的用户家目录[root@node01 ~]# ansible dbserver -u root -m command -a 'ls /root'192.168.70.30 | CHANGED | rc=0 &gt;&gt;anaconda-ks.cfg192.168.70.20 | CHANGED | rc=0 &gt;&gt;anaconda-ks.cfg 普通用户在ansible执行自己主机root权限 #首先在node02上添加普通用户dzq，密码000000，然后追加扩展组到wheel便于执行sudo权限[root@node02 ~]# useradd dzq[root@node02 ~]# passwd dzq更改用户 dzq 的密码 新的 密码：000000无效的密码： 密码是一个回文重新输入新的 密码：000000passwd：所有的身份验证令牌已经成功更新。[root@node02 ~]# visudo[root@node02 ~]# usermod -aG wheel dzq#然后到node01上执行[root@node01 ~]# ansible 192.168.70.20 -u dzq -m command -a 'ls /root' -k -K -bSSH password: 000000BECOME password[defaults to SSH password]: 000000192.168.70.20 | CHANGED | rc=0 &gt;&gt;anaconda-ks.cfg# visudo带颜色[root@node02 ~]# echo export EDITOR=vim &gt;&gt; /etc/profile.d/env.sh[root@node02 ~]# source /etc/profile.d/env.sh hosts主机清单 # 匹配主机的列表1、All：表示有Inventory中的所有主机2、通配符 *3、或关系 :4、与关系5、逻辑非6、综合逻辑7、正则表达式演示：1、ansible all -m ping2、ansible 192.168.70.* -m ping3、ansible \"webserver:appserver\" -m ping4、ansible 'webserver:&amp;appserver' -m ping5、ansible 'webserver:!appserver' -m ping6、ansible 'webserver:appserver:&amp;dbserver:!ftpserver' -m ping7、ansible '~(web|db).*\\.server' -m ping ansible常用模块 Command：在远程主机上执行命令，默认模块，可忽略-m选项 ansible node24 -m command -a ‘systemctl restart sshd’ ansible node24 -m command -a ‘echo 000 | passwd –stdin dzq’ 【不成功】 此模块不支持 $VARNAME &lt; &gt; | ; $ $ 等，应该用shell模块实现 Shell：和command相似，用shell执行命令 ansible node24 -m shell -a ‘echo 000 | passwd –stdin dzq’ 调用bash执行命令，类似`cat /etc/passwd | awk -F ‘:’ ‘{print $1,$2}’ &amp;&gt; /tmp/example.txt这些复杂的命令，即使使用shell也可能会失败，解决办法：写到脚本里，copy到远程执行，再把所需要的结果拉回执行命令的机器 Script：运行脚本呢 -a “/PATH/TO/SCRIPT_FILE” ansible node24 -m script -a f1.sh Copy：把服务器上的文件复制到受控端 如果目标存在，默认覆盖，此处指定先备份 ansible all -m copy -a ‘src=/etc/selinux/config dest=/etc/selinux/config backup=yes owner=dzq mode=000’ 利用内容直接生成目标文件 ansible all -m copy -a ‘content=’hello world’ dest/tmp/1.txt’ Fetch：从客户端取文件至服务器端 ansible node23 -m file -a ‘src=/root/a.sh dest=/tmp/‘ File：设置文件属性 ansible node23 -m file -a ‘path=/root/a.sh owner=dzq mode=755’ ansible node23 -m file -a ‘src=/app/testfile dest=/app/testfile-link state=link’ 创建文件 ansible node23 -m file -a ‘path=’/root/f1.txt’ state=touch’ 删除文件 ansible node23 -m file -a ‘path=’/root/f1.txt’ state=absent’ 创建软连接 ansible node23 -m file -a ‘src=/etc/ssh/sshd_config dest=/root/ssh_link state=link’ Hostname：管理主机名 更改主机名 ansible 192.168.70.20 -m hostname -a ‘name=node02’ Cron：计划任务 支持时间：minute、hour、day、month、weekday 创建任务： ansible node24 -m cron -a ‘minute=* weekday=1,3,5 job=”/usr/bin/wall FBI warning” name=warnning’ 禁用任务： ansible node24 -m cron -a ‘disabled=trued job=”/usr/bin/wall FBI warning” name=warnning’ 删除任务： ansible node24 -m cron -a ‘job=”/usr/bin/wall FBI warning” name=warnning state=absent’ Yum：管理包 安装 ansible node24 -m yum -a ‘name=httpd state=latest’ 删除 ansible node24 -m yum -a ‘name=httpd state=absent’ Service：管理服务 安装FTP服务启动，并设置开启自启 ansible node24 -m service -a ‘name=vsftpd state=started enabled=yes’ ansible srv -m service -a ‘name=httpd state=stoped’ ansible srv -m service -a ‘name=httpd state=started’ ansible srv -m service -a ‘name=httpd state=reloaded’ ansible srv -m service -a ‘name=httpd state=restart’ User：管理用户 ansible srv -m user -a ‘name=user1 commment=”test user” uid=2048 home=/app/user1” group=root’ ansible srv -m user -a ‘name=sysuser1 system=yes home=/app/sysuser1’ ansible srv -m user -a ‘name=user1 state=absent remove=yes’ #删除用户家目录 Group：管理组 ansible srv -m group -a ‘name=testgroup system=yes’ ansible srv -m group -a ‘name=testgroup state=absent’ ansible-galaxy 连接https://galaxy.ansible.com下载相应的roles 列出已安装的galaxy：ansible-galaxy list 安装galaxy：ansible-galaxy install username.rolename 删除galaxy：ansible-galaxy remove username.rolename ansible-vault加密解密playbook #解密ansible-vault encrypt hello.yml#加密ansible-vault decrypt hello.yml#加密后查看文件ansible-vault view hello.yml#加密后编辑文件ansible-vault eidtor hello.yml#重新设置口令ansible-vault rekey hello.yml ansible-consoleansible交互式控制台 ansible-consoleroot@node24 (2)[f:5]$ forks 3root@node24 (2)[f:3]$ cd node23root@node23 (2)[f:3]$ ? #查看有哪些命令root@node23 (2)[f:3]$ command hostname #执行命令：模块名/命令192.168.70.20 | CHANGED | rc=0 &gt;&gt;node02192.168.70.30 | CHANGED | rc=0 &gt;&gt;node03root@node23 (2)[f:3]$ service name=httpd state=start ansible-playbook playbook是由多个play组成的列表 play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让他们联通起来按实现编排的机制同唱一台大戏 playbook采用yaml语言编写 Playbook核心元素 Hosts：执行的远程主机列表 Tasks：任务集 Varniables：内置变量或自定义变量在playbook中调用 Templates：模板，可替换模板文件的变量并实现一些简单逻辑文件 Handlers和Notity结合使用，由特定条件出发的操作，满足条件方才执行，否则不执行 tags：标签，指定某条任务执行，用于选择运行playbook中的部分代码，ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有变化的时间依然会非常长，此时如果确信没有其他变化，可以就通过tags跳过此代码片段 playbook常见选项 ansible-playbook file.yml --list-hosts #列出playbook中的主机ansible-playbook file.yml --list-tasks #列出playbook中的任务ansible-playbook file.yml --limit node23#限制任务执行的主机ansible-playbook -C file.yml #检查yaml语法 hostsplaybook中每个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务，hosts用于指定要执行任务的主机，须事先定义在主机清单中。 可以是如下形式 one.example.com one.example.com:two.example.com 192.168.1.2 192.168.1.* webserver:dbserver:&amp;appserver 示例： host: webserver 检查playbook语法：ansbile-playbook -C file.yml - hosts: websrvs remote_user: root tasks: - name: create new file file: name=/data/newfile state=touch - name: create new user user: name=test3 state=present system=yes - name: install package yum: name=httpd state=installed - name: copy html copy: src=/var/www/html/index.html dest=/var/www/html/ - name: start service service: name=httpd state=started enabled=yes taskstask列表和action play的主体部分是task list。task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后再开始第二个。在运行自上而下某playbook，如果中途发生错误，所有已执行任务都将回滚，因此，在更正playbook后重新执行一次即可 task的目的是使用指定参数执行模块，而在模块参数中可以使用变量，模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致 每个task都应该有其name，用于playbook的执行结果输出，建议其内容尽可能清晰地描述任务执行步骤，如果未提供name，则action的结果将用于输出 action格式： (1) action: module arguments(2) module: arguments 脚本错误继续执行 (1)task: -name: run this command and ignore the result shell: /usr/bin/comnands || /bin/true (2)tasks -name: run this command and ignore the result shell: /usr/bin/commands ignore_errors: True handlers &amp; notify Handlers：是task列表，这些task与前述的task没有本质上的不同，用于当关注资源发生变化时，才会采取一定的操作 Notify此Action可用于在每个play的最后被触发，这样可以避免多次有改变发生时，每次都执行指定操作，仅在所有的变化发生完后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调用handler中定义的操作。 一旦配置文件发生变化，服务重启 ---#httpd服务- host: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd - name: copy config file copy: src=/etc/httpd/conf/httpd.conf dest=/etc/httpd/conf/ backup=yes notify: restart httpd service - name: start service service: name=httpd state=started enabled=yes handlers: - name: restart httpd service service: name=httpd state=restarted# 如果copy config file改动，则触发handlers中的restart httpd service notify &amp; handler 多个的写法,用列表的形式呈现 - name: config copy: src=file/nginx.conf dest=/etc/nginx/nginx.conf notify: - restart nginx - check nginx process handlers: - name: restart nginx service: name=nginx state=restarted enable=yes - name: check nginx process shell: killall -0 nginx &gt; /tmp/nginx.log tags只执行标签内容，或者不执行标签内容 #以下是不同的动作不同的标签，也可以多个动作公用一个标签- host: webserver remote_user: root tasks: - name: install httpd package yum: name=httpd tags: install_httpd - name: copy config file copy: src=/etc/httpd/conf/httpd.conf dest=/etc/httpd/conf/ backup=yes notify: restart httpd service - name: start service service: name=httpd state=started enabled=yes tags: restart_httpd handlers: - name: restart httpd service service: name=httpd state=restarted# ansible-playbook调用# ansible-playbook -t install_httpd,restart_httpd httpd.yml Varniables变量名：仅能由字母、下划线、数字组成，且只能以字母开头 变量来源： ansible setup facts 远程主机的所有变量都可以直接调用 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共变量：针对主机中所有主机定义的统一变量 通过命令行指定变量，优先级最高 ansible-playbook -e ‘varname=value’ file.yml 在playbook中定义 vars: - var1: value1 - var2: value2 在role中定义 优先级：命令行&gt;Playbook&gt;主机清单 命令行的变量赋值 - host: webserver remote_user: root tasks: - name: install httpd package yum: name=&#123;&#123; pkgname &#125;&#125; - name: start service service: name=&#123;&#123; pkgname &#125;&#125; state=started enabled=yes# 执行# ansible-playbook -e 'pkgname=vsftpd' app.yml 定义playbook中的变量 ---- host: webserver remote_user: root vars: - pkgname1: httpd - pkgname2: vsftpd tasks: - name: install httpd package yum: name=&#123;&#123; pkgname1 &#125;&#125; - name: start service service: name=&#123;&#123; pkgname2 &#125;&#125; state=started enabled=yes 在主机清单中定义变量 # 定义主机清单中的变量$ vim /etc/ansible/hosts[node23]192.168.70.30 Nbr=300192.168.70.20 Nbr=200# 在playbook中调用- hosts: node23 remote_user: root tasks: - name: set hostanem hostname: name=www.&#123;&#123; Nbr &#125;&#125;ymlog.cn 清单统一变量 $ vim /etc/ansible/hosts[node23]192.168.70.30 Nbr=300192.168.70.20 Nbr=200[node23:vars]nodename=wwwdomainname=ymlog.cn- hosts: node23 remote_user: root tasks: - name: set hostanem hostname: name=&#123;&#123; nodename &#125;&#125;&#123;&#123; Nbr &#125;&#125;&#123;&#123; domainname &#125;&#125; templates模板 文本文件，嵌套有脚本 Jinja2语言，使用字面量，有下面形式： 字符串：使用单引号或双引号 数字：整数、浮点数 列表：[item1,item2,…] 元组：{item1,item2,…} 字典：{key1:value1,key2:value2,….} 布尔型：true/false 算术运算：+ ,- , * ,/ ,// , % ,** 比较操作：==, != ,&lt; , &lt;= ,&gt; ,&gt;= 逻辑运算：and、or、not 流表达式：For If When ---- hosts: webserver remote_user: root vars_files: - vars.yml tasks: - name: install package yum: name=nginx - name: copy template template: src=/root/.ansible/templates/nginx.conf.j2 dest=/etc/nginx/nginx.conf - name: start service service: name=nginx state=started enabled=yes 1、将Nginx的工作进程改为CPU核心数的二次方倍：修改templates的文件，原来templates/nginx.conf.j2的文件就是nginx.conf的配置文件。 先查看setup中的cpu变量用什么标识： [root@node01 ~]# ansible node24 -m setup | grep cpu \"ansible_processor_vcpus\": 1, \"ansible_processor_vcpus\": 1, user nginx;worker_processes &#123;&#123; ansible_processor_vcpus**2 &#125;&#125;; 2、将node2的端口改为200，node3的端口改为300 192.168.70.30 Nbr=300192.168.70.20 Nbr=200 server &#123; listen &#123;&#123; Nbr &#125;&#125; default_server; listen [::]:&#123;&#123; Nbr &#125;&#125; default_server; 3、 when 条件测试：如果需要根据变量、facts或此前任务执行结果来作为某task执行与否的前提时要用到条件测试，通过when语句实现，在task中使用，jinja2的语法格式 when语句 在task后添加when子句即可使用条件测试；when语句支持jinja2表达语法 示例： tasks:- name: &quot;shutdown RedHat Flavored Systems&quot; command: &#x2F;sbin&#x2F;shutdown -h now when: ansible_os_family &#x3D;&#x3D; &quot;Redhat&quot; 当为7版的时候才复制文件 ---- hosts: webserver remote_user: root tasks: - name: install package yum: name=nginx - name: copy template template: src=/root/.ansible/templates/nginx.conf.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == \"7\" - name: start service service: name=nginx state=started enabled=yes with_item迭代 1、新建多个文件 ---- hosts: webserver remote_user: root tasks: - name: create some files file: name=/data/&#123;&#123; item &#125;&#125; state=touch with_items: - file1 - file2 - file3 2、迭代嵌套子变量 ---- hosts: webserver remote_user: root tasks: - name: add some groups group: name=&#123;&#123; item &#125;&#125; state=present with_items: - group1 - group2 - group3 - name: add some users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present with_items: - &#123; name:'user1',group: 'group1'&#125; - &#123; name:'user2',group: 'group2'&#125; - &#123; name:'user',group: 'group3'&#125; for循环 $ vim templates.yml- hosts: all remote_user: root vars: ports: - 81 - 82 - 83 tasks: - name: copy conf template: src=for1.conf.j2 dest/data/for1.conf $ vim for1.conf.j2&#123;% for port in ports %&#125;server&#123; listen &#123;&#123; port &#125;&#125;&#125;&#123;% endfor %&#125;$ 执行ansible-playbook all templates.yml 把列表换成字典 $ vim templates.yml- hosts: all remote_user: root vars: ports: - web1: port: 81 name: www.web1.com rootdir: /root/website1 - web2: port: 82 name: www.web2.com rootdir: /root/website2 - web3: port: 83 name: www.web3.com rootdir: /root/website3 tasks: - name: copy conf template: src=for1.conf.j2 dest/data/for1.conf $ vim for1.conf.j2&#123;% for p in ports %&#125;server&#123; listen &#123;&#123; p.port &#125;&#125; servername &#123;&#123; p.name &#125;&#125; documentroot &#123;&#123; p.rootdir&#125;&#125;&#125;&#123;% endfor %&#125;$ 执行ansible-playbook all templates.yml if条件判断 # 如果p.name被定义了&#123;% if p.name is defined %&#125;do...&#123;% endif %&#125;do... YAML介绍 YAML是一个可读性高的用来表达资料序列的格式，YAML参考了其他多种语言，包括XML、C、Python、Perl以及电子邮件格式RFC2822等，Clark Evans在2001年首次发表了这种语言。 YAML特性 可读性好 和脚本语言的交互性好 使用实现语言的数据类型 有一个一致的信息模型 易于实现 可以基于流来处理 表达能力强，扩展性好 http://www.yaml.org YAML语法简介 在单一文件中，可以连续用三个连字号-区分多个档案，另外，还有选择性的连续三个点号(…)用来表示档案结尾 次行开始正常写playbook的内容，一般建议写明该Playbook的功能 使用#注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别就是通过缩进 结合换行来实现的 YAML文件内容和Linux系统大小写判断方式保持一致，区分大小写，key/value值均需大小写敏感 key/value值可同行写也可以换行写，同行使用:分隔 value可以是字符串，也可以是另一个列表 一个完整的代码块功能需要最少元素包括name:task 一个name只能包含一个task YAML文件扩展名通常为yml或yaml LIST：列表 # A List- blue- grenn- black- white- yellow DICTIONARY：字典 # A Dictionayname: Ajobs: Bskil: C&#123;name: A,Job: B,Skil: C&#125; 基础写法：在node24上创建文件 ---- hosts: node24 #指定受控端 remote_user: root #以什么身份登录受控端 tasks: - name: hello #任务名，没什么意思 command: touch /root/pl.test #使用command模块执行命令 # 把变量定义到一个文件中$ cat vars.ymlvar1: vsftpdvar2: httpd# 调用变量---- hosts: webserver remote_user: root vars_files: - vars.yml tasks: - name: install package yum: name=&#123;&#123; var1 &#125;&#125; roles roles ansible自1.2版本引入的新特性，用于层次性、结构化组织playbook。roles能够根据层次型结构自动装载变量、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可，简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并且可以便捷的inlcude它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以用于构建 守护进程等场景中。 复杂场景建议使用roles，代码复用性高 某些功能需要多个playbook，通过includes即可实现 roles目录结构----------------------------------------------# 每个角色，以特定的层级目录结构进行组织playbook.ymlroles/ project/ tasks/ files/ vars/ default/ templates/ handlers/ meta/ 各目录的作用： files/ ：存放由copy或script模块等调用的文件 templates/：template模块查找所需模板文件目录 tasks/：定义task，role的基本元素，至少应该包含一个名为main.yml的文件，其他的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个main.yml的文件；其他文件需要再次文件中通过include进行包含 vars/：定义变量，至少应该包含一个main.yml的文件；其他文件需要再次文件中通过include进行包含 meta/：定义当前角色的特殊设定及其依赖关系，至少应该包含一个名为main.yml的文件，其他文件需再此文件中通过include进行包含 default/：设定默认变量时，使用此目录中的mian.yml文件 Ansible搭建httpd安装httpd 1、目录结构 ├── httpd_role.yml├──*roles│ └──*httpd│ ├──*tasks│ │ ├── group.yml│ │ ├── install.yml│ │ ├── main.yml│ │ ├── restart.yml│ │ ├── start.yml│ │ ├── templ.yml│ │ └── user.yml│ └──*templates│ └── httpd.conf.j2dir:roles,httpd,task,templates 2、文件内容 [root@node01 .ansible]# cat httpd_role.yml - hosts: all remote_user: root roles: - role: httpd [root@node01 tasks]# cat group.yml - name: add group group: name=httpd gid=110 system=yes [root@node01 tasks]# cat user.yml - name: add user user: name=httpd uid=110 system=yes [root@node01 tasks]# cat install.yml - name: install httpd yum: name=httpd [root@node01 tasks]# cat templ.yml - name: copy config template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf [root@node01 tasks]# cat start.yml - name: start service service: name=httpd state=started templates下的文件就是复制的/etc/httpd/conf/httpd.conf，并改名为httpd.conf.j2 调用别的角色的任务 main.yml- include: install package- include: roles/httpd/tasks/copyfile.yml 调用多个角色、启用标签、判断语句 [root@node01 .ansible]# cat some.yml - hosts: all remote_user: root roles: - &#123; role: httpd,tags:['web','httpd'],when: ansible_distribution_major_version == \"7\" &#125; #加判断 - role: nginx #这里可以调用多个角色 - &#123; role: vsftpd,tags: ['web','vsftpd' ]&#125; #加标签 标签执行 ansible-play -t vsftpd some.yml Ansible搭建Haproxy 主机 IP 功能 node01 192.168.70.10 ansible node02 192.168.70.20 haproxy node03 192.168.70.30 httpd node04 192.168.70.40 httpd #!/bin/bashyum -y install ansibleIP2=\"192.168.70.20\"IP3=\"192.168.70.30\"IP4=\"192.168.70.40\"rm -rf /etc/ansible/hosts echo \"[webs]\" &gt;&gt; /etc/ansible/hosts echo \"$IP3 SITE=web1\" &gt;&gt; /etc/ansible/hosts echo \"$IP4 SITE=web2\" &gt;&gt; /etc/ansible/hosts echo \"[lb]\" &gt;&gt; /etc/ansible/hosts echo \"$IP2\" &gt;&gt; /etc/ansible/hosts rm -rf /root/.ansible/*mkdir -p /root/.ansible/roles/&#123;httpd,haproxy&#125;/&#123;tasks,templates&#125;touch /root/.ansible/roles/&#123;httpd,haproxy&#125;/tasks/install.ymltouch /root/.ansible/roles/&#123;httpd,haproxy&#125;/tasks/templa.ymltouch /root/.ansible/roles/&#123;httpd,haproxy&#125;/tasks/start.ymltouch /root/.ansible/roles/&#123;httpd,haproxy&#125;/tasks/main.ymlcat &gt;&gt; /root/.ansible/roles/httpd/tasks/install.yml &lt;&lt; 'EOF'- name: install httpd yum: name=httpdEOFecho \"this is &#123;&#123; SITE &#125;&#125;\" &gt;&gt; /root/.ansible/roles/httpd/templates/index.html.j2 cat &gt;&gt; /root/.ansible/roles/httpd/tasks/templa.yml &lt;&lt; 'EOF'- name: copy index.html template: src=/root/.ansible/roles/httpd/templates/index.html.j2 dest=/var/www/html/index.htmlEOFcat &gt;&gt; /root/.ansible/roles/httpd/tasks/start.yml &lt;&lt; 'EOF'- name: start service service: name=httpd state=startedEOFcat &gt;&gt; /root/.ansible/roles/httpd/tasks/main.yml &lt;&lt; 'EOF'- include: install.yml- include: templa.yml- include: start.ymlEOFcat &gt;&gt; /root/.ansible/roles/haproxy/tasks/install.yml &lt;&lt; 'EOF'- name: install haproxy yum: name=haproxyEOFcat &gt;&gt; /root/.ansible/roles/haproxy/templates/haproxy.cfg.j2 &lt;&lt; 'EOF'global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend main *:8080 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static default_backend appbackend static balance roundrobin server static 127.0.0.1:4331 checkbackend app balance roundrobinEOFecho -e \" server web1 $IP3:80 check\" &gt;&gt; /root/.ansible/roles/haproxy/templates/haproxy.cfg.j2echo -e \" server web2 $IP4:80 check\" &gt;&gt; /root/.ansible/roles/haproxy/templates/haproxy.cfg.j2 cat &gt;&gt; /root/.ansible/roles/haproxy/tasks/templa.yml &lt;&lt; 'EOF'- name: copy index.html template: src=/root/.ansible/roles/haproxy/templates/haproxy.cfg.j2 dest=/var/www/html/index.html dest=/etc/haproxy/haproxy.cfgEOFcat &gt;&gt; /root/.ansible/roles/haproxy/tasks/start.yml &lt;&lt; 'EOF'- name: start service service: name=haproxy state=startedEOFcat &gt;&gt; /root/.ansible/roles/haproxy/tasks/main.yml &lt;&lt; 'EOF'- include: install.yml- include: templa.yml- include: start.ymlEOFcat &gt;&gt; /root/.ansible/lb_role.yml &lt;&lt; 'EOF'---- hosts: webs remote_user: root roles: - role: httpd- hosts: lb remote_user: root roles: - role: haproxyEOFcd /root/.ansible/ansible-playbook -$1 lb_role.ymlecho \"Please Curl $IP2:8080\"","categories":[{"name":"中间件","slug":"中间件","permalink":"http://ymlog.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://ymlog.cn/tags/Ansible/"}]},{"title":"OSPF协议","slug":"OSPF","date":"2020-02-23T07:00:39.000Z","updated":"2020-07-04T17:18:46.426Z","comments":true,"path":"2020/02/23/OSPF/","link":"","permalink":"http://ymlog.cn/2020/02/23/OSPF/","excerpt":"念两句诗身世杯中酒，万事皆空。古来三五个英雄。雨打风吹何处是，汉殿秦宫。梦入少年丛，歌舞匆匆。老僧夜半误鸣钟。惊起西窗眠不得，卷地西风。","text":"念两句诗身世杯中酒，万事皆空。古来三五个英雄。雨打风吹何处是，汉殿秦宫。梦入少年丛，歌舞匆匆。老僧夜半误鸣钟。惊起西窗眠不得，卷地西风。 OSPF距离矢量路由协议 ​ 路由器相互之间只更新路由表信息，并且逐条更新，依照传闻的更新，任何一台路由器对路由表的更改，都将直接影响到下游。 链路状态路由协议 ​ 每台路由器都选择一个IP地址作为自己的名字，（Router-ID） ​ 将自己的每个接口的网络信息，带宽信息进行描述，做成链路状态信息 ​ 将Router-ID和链路状态一起发送给自己的邻居，并且也帮助其他设备转发 ​ 最终会得到全网所有路由器的链路状态信息，通过分析可以得到全网拓扑图 ​ 使用最短路径算法（SPF），得到去往每个目的地的最短路线，得到路由表 简介 ospf在Cisco设备中的管理距离为120 不使用传输层的TCP/UDP进行数据封装，更新消息直接放在网络层后，协议号为89 OSPF使用触发更新的机制，和邻居共享链路状态信息，而不是共享路由信息 OSPF有邻居的概念，使用Hello消息来建立和维护邻居，在以太网中，10s更新一次，40s没收到就判定邻居失效。 OSPF建立邻居有7个状态 OSPF使用224.0.0.5和224.0.0.6来更新LSA(链路状态通告) ospf宣告的环回口不管子网掩码是多少，传播的时候都时32位 名词介绍 Router-ID：相当于路由器的名字，因为需要靠Router-ID去辨识每个节点，所以在一个网络中不允许出现Router-ID一样。Router-ID会以稳定性作为第一要素。 1、Router-ID会优先选择路由器LoopBack接口的IP地址，如果有多个选择数值，选择最大的。 2、Router-ID在没有LoopBack的情况下，会选择物理接口IP数值最大的，注意：这个接口必须要是UP状态 3、Router-ID允许手动指定，但往往不能即使生效，除非重启，不然还是稳定保持不变 区域：Area，由于每台路由器都有全网的拓扑，如果这个网络比较庞大，那么任何一个网段的变化，都会导致OSPF路由器中链路状态数据库的数据发生变化，从而触发路由器对所有的目的地最佳路线进行重算。为了节约资源和加快路由器运行速度，所以OSPF可以进行区域划分，每台路由器只需要计算本区域的拓扑。对于其他区域的网段，只需要知道怎么离开本区域就行了。 OSPF有两种区域，一种是骨干区域，区域号为0，这个是固定的，只要是骨干区域，区域号必须是0，还有一种是非骨干区域，非骨干区域的区域号除了0都可以。非骨干区域必须和骨干区域相连，在正常情况下，所有的区域都可以学习到全网所有的路由条目，在人为优化的情况下，可以让非骨干区域只学习到本区域的路由，去其他区域从默认路由走，从而精简路由表。 邻居建立过程 down 表示OSPF启动了，由于某些原因，还没开始发送Hello init 表示收到了对方发给我的Hello消息，但是没有在对方的Hello消息中，看的自己的Router-ID 2-way 在收到对方发给我的Router-ID中发现了自己的Router-ID 开始选举谁做指定路由器DR exstart（预开始） 开始选举谁来主导这个链路状态信息交换的过程，选举（Slave，Master） 注意，此阶段互相传递的消息格式是链路状态数据库摘要（但是内容为空）。 exchange（预交换） 由Slave发送自己的链路状态数据的摘要给Master，由Master确认之后再将Slave需要的链路状态信息发回去 loading 开始发送链路状态请求，然后接收对方发送的完整链路状态信息 Full 完成当前阶段的链路状态数据库同步，之后只需要维持邻居关系和触发更新 Neighbor ID Pri State Dead Time Address Interface3.3.3.3 1 FULL/DR 00:00:37 192.168.23.3 Ethernet0/0Neighbor_ID: 邻居表里记录了邻居的Router-IDPri: 选举DR和BDR的用的优先级，默认是1State: 邻居建立过程中的状态和角色 [down,init,2-way,exstart,exchange,loading,full | DR,BDR,DRother]Dead_Time: 邻居的死亡计时40s，每当收到邻居hello包的时候，就重置，计时到0，就删除邻居Address: 建立邻居的IPInterface: 建立邻居的接口 DR和BDRshow ip ospf interface e0/0 查看OSPF接口信息，这个信息是和OSPF有关的 在多路访问的网络（交换机所在网络）里，OSPF建立邻居关系，导致最终邻居关系较复杂，更新消息重复而多于，所以在MA网络中，选举一个路由器作为指定路由器（DR），在非DR中，再选一个BDR作为备份。当任何的更新来临时，会先发送给DB和BDR，再由DR发送给所有的DRother路由器 选取DR和BDR的时候，先看优先级，越大越优，如果是0，就不参与DR和BDR选举。如果优先级一样，就看Router-ID谁大，谁大谁就是DR，不过必须在第一台设备启动后的40s内选举，超出这个时间，就不可以抢占DR和BDR。 DR和BDR在监听224.0.0.5和224.0.0.6这个地址，DRother只监听224.0.0.5这个地址，当需要更新的时候，DRother会向224.0.0.6去更新，DR会向224.0.0.5去更新消息 为了让ospf网络快速收敛，可以考虑在合适的接口上配置p2p网络类型，让ospf邻居不进行40s等待 信息查看 路由器配置 R1 enconf tno ip do lo line con 0no exec-tlogg synho R1int lo0ip add 1.1.1.1 255.255.255.255int e0/0ip add 192.168.13.1 255.255.255.0no shint range e0/0 , lo0ip ospf 1 area 1end R2 enconf tno ip do lo line con 0no exec-tlogg synho R2int lo0ip add 2.2.2.2 255.255.255.255int e0/0ip add 192.168.23.2 255.255.255.0no shint range e0/0 , lo0ip ospf 1 area 1end R3 enconf tno ip do lo line con 0no exec-tlogg synho R3int lo0ip add 3.3.3.3 255.255.255.255int e0/1ip add 192.168.13.3 255.255.255.0no shint e0/2ip add 192.168.23.3 255.255.255.0no shint e0/0ip add 192.168.34.3 255.255.255.0no shint range e0/1 -2ip ospf 1 area 1int range e0/0 , lo0ip ospf 1 area 0end R4 enconf tno ip do lo line con 0no exec-tlogg synho R4int lo0ip add 4.4.4.4 255.255.255.255int e0/0ip add 192.168.34.4 255.255.255.0no shint e0/1ip add 192.168.45.4 255.255.255.0no shint range e0/0 -1 , lo0ip ospf 1 area 0end R5 enconf tno ip do lo line con 0no exec-tlogg synho R5int lo0ip add 5.5.5.5 255.255.255.255int e0/1ip add 192.168.45.5 255.255.255.0no shint e0/0ip add 192.168.56.5 255.255.255.0no shint range e0/1 , lo0ip ospf 1 area 0int range e0/0 ip ospf 1 area 2end R6 enconf tno ip do lo line con 0no exec-tlogg synho R6int lo0 ip add 6.6.6.6 255.255.255.255 int e0/0ip add 192.168.56.6 255.255.255.0no shint range e0/0 , lo0ip ospf 1 area 2end 当前路由器角色 查看当前路由器的角色，此时R3是ABR(Area Border Router) $ show ip protocalsRouting Protocol is \"ospf 1\" Router ID 3.3.3.3 #Router_ID It is an area border router #ABR Number of areas in this router is 2. 2 normal 0 stub 0 nssa Maximum path: 4 #最大负载均衡路径 DR/BDR 查看当前网络信息，包括DR，BDR，R1的e0/0接口信息 R1#sh ip ospf int e0/0Ethernet0/0 is up, line protocol is up Internet Address 192.168.13.1/24, Area 1, Attached via Interface Enable [区域为aera 1] Process ID 1, Router ID 1.1.1.1, Network Type BROADCAST, Cost: 10 [网络类型：Broadcast] [传输延迟1s] [状态BDR] [优先级1] $ Transmit Delay is 1 sec, State BDR, Priority 1 [DR路由器的RouterID] [接口地址] $ Designated Router (ID) 3.3.3.3, Interface address 192.168.13.3 [BDR路由器的RouterID] [接口地址] $ Backup Designated router (ID) 1.1.1.1, Interface address 192.168.13.1 [时间间隔] $ $ $ $ Timer intervals configured, Hello 10, Dead 40, Wait 40, Retransmit 5 oob-resync timeout 40 Hello due in 00:00:05 #下一次发送Hello包是什么时候 Neighbor Count is 1, Adjacent neighbor count is 1 Adjacent with neighbor 3.3.3.3 (Designated Router) P2P网络 使用point-to-point网络连接R5和R6，在P2P网络内，不选DR和BDR。默认网络为Broadcast。P2P网络可以不用发组播，就能建立邻居。 R5(R6同理):int e0/0ip ospf network point-to-point 但是，只有没有多路访问的网络(网络不存在交换机)方便使用p2p连接，不然就会出现三个路由器两两交替抢占邻居的现象，即一会收到A的Hello包，和A建立邻居，一会收到B的Hello包，和B建立邻居，等到A的Hello包再来，因为P2P网络只能点对点，所以又只好断掉B的邻居和A建立邻居，循环往复。 链路数据数据库字段# 查看show ip ospf database 字段解释： Link ID：(link state id),链路ID ADV Router：(advertising router)发送LSA的路由器 Age ：正计时，寿命1h，OSPF有周期性更新的行为，周期为30min，每到30min，数据库进行泛洪，将所有数据全部发出，刷新Age Seq：序列号 ，十六进制，序列号有新的就用新的，OSPF认为0x80000000是错误的，会先更新，然后删除。类似RIP中的16跳。 Checksum ：校验，MTU分组发送的时候需要校验 Link count：链路条数 LSA和多区域 LSA（Link-State Advertisement ） ，链路状态通告：链路状态通告，里面包含了路由器的ID和链路状态相关的IP地址，带宽等信息。目前在OSPF内，一共有11中LSA LSU（Link-State Advertisement）， 链路状态更新：链路状态更新，更新里面含有LSA LSDB（Link-State Database）， 链路状态数据库：数据库中会记录每个LSA更新的路由器ID，会记录序列号，序列号用16进制表示。数据库每个LSA一个计时器，这个计时器是LSA老化时间，正常情况下1h就会然这条LSA失效，但OSPF每隔30min泛洪会更新一次LSA。 stub Stub（末梢区域）：OSPF如果不想让非骨干区域学习到OSPF_AS外的条目，达到精简路由表的目的，可以在ABR上对末梢区域进行 area 1 stub 配置，这样ABR就不会向那个区域发送AS外的条目，还会产生一条 0.0.0.0/0 的路由，保障没有路由的情况下，这个区域也可以访问外界。本区域的所有路由器你都别忘了配置Stub，不然邻居关系无法建立。该区域不存在4、5类LSA。 stub no-summary Stub no-summary：如果做到极致精简，可以让末梢区域连OSPF其他区域路由也不学习，可以在ABR上对末梢区域进行 area 1 stub no-summary。no-summary 只需要在ABR上加。Stub no-summary 也被称为完全末梢区域。该区域不存在4、5类LSA，以及除了ABR默认路由三类LSA以外的3类 nssa NSSA（not so stub area）：次末梢区域。由于Stub区域无法存在4、5类LSA，所以stub区域无法引入外部路由，如果使用NSSA区域来做末梢，就看可以引入外部路由条目，不过是以7类LSA的方式进入，并且会在NSSA区域边界路由器上被转为5类。area 1 nssa 默认情况下，NSSA不会像非骨干区域注入一条默认路由，不过可以手动注入一条默认路由的7类LSA：area 1 nssa default-infor orig T-nssa T-NSSA （total-not so stub area）完全次末梢区域，除了可以存在7类LSA引入外部路由以外，其他功能和stub no-summary一致。area 1 nssa no-summary 总结：· `area 1 stub` area1是末梢区域`area 1 stub no-summary` area1是完全末梢区域`area 1 nssa` area1是次末梢区域`area 1 nssa default-infor-origin` area1是次末梢区域，并且通告默认路由`area 1 nssa no-summary` area1完全次末梢区域 OSPF Codes 标识 含义 O 区域内的路由 O IA 不同区域之间的路由 OE1 区域外的路由(不是OSPF协议的路由)，会累加METRIC值（默认20） OE2 区域外的路由(不是OSPF协议的路由)，不累加METRIC值（默认20），由外部重分布进来默认使用OE2。 ON1 区域外的路由，由NSSA的ASBR重发布进来的，会累加Metric值 ON2 区域外路由，由NSSA的ASBR重发布进来的。NSSA区域中的路由器没有LSA-5，用LSA7算出的external路由，就标记为ON1/2 十一种LSAOSPF路由器会发送LSA通告，如果路由器太多，收到的通告就会很多，在进行SPF算法的时候，网络拓扑图太大，计算复杂，而且每当网络状态更新，都需要重复这样一次计算，计算量庞大。 收到的LSA通告太多了，OSPF路由器的负担很 内部动荡会引起全网路由器的完全SPF计算 资源消耗过多，LSDB庞大，设备性能下降，影响数据转发 每台路由器都需要维护的路由表越来越大，单区域内路由无法汇总 LSA类型代码 描述 1 路由器LSA，本地路由器产生，用于描述自身的链路信息，如接口、带宽、ip地址 2 网络LSA，由DR产生，用于向全网告知自己所在的局域网信息 。 3 网络汇总LSA，ABR产生，将其他区域的路由条目转发到本区域，会丢失拓扑信息 4 ASBR汇总LSA，ASBR产生，告知本区域路由如何离开自治系统 5 AS外部LSA，ASBR产生，告知本区域路由器外面的路由条目 6 组成员LSA 7 NSSA外部LSA，nssa区域路由器重发布外界路由产生，导入其他区域会被ABR修改为5类LSA 8 外部属性LSA 9 Opaque LSA （链路本地范围） 10 Opaque LSA （本地区域范围） 11 Opaque LSA （AS范围） 11类LSA — 路由器LSA，每台路由器都会产生，用于描述自身的接口状态。 $ sh ip ospf database Router Link States (Area 1)Link ID ADV Router Age Seq# Checksum Link count1.1.1.1 1.1.1.1 1678 0x80000006 0x00997D 22.2.2.2 2.2.2.2 1621 0x80000007 0x00559F 23.3.3.3 3.3.3.3 1724 0x80000009 0x009362 2 路由链路状态表（区域1）连接的ID，从哪个路由器学到的，寿命，序列号，校验位，链路数# 查看详细信息$ sh ip ospf database router 1.1.1.1 22类LSA ：网络LSA，由DR产生，用于向全网告知自己所在的局域网信息 。 R1#sh ip ospf database network 192.168.13.3 OSPF Router with ID (1.1.1.1) (Process ID 1) Net Link States (Area 1)#头部信息 Routing Bit Set on this LSA in topology Base with MTID 0 LS age: 56 Options: (No TOS-capability, DC) LS Type: Network Links Link State ID: 192.168.13.3 (address of Designated Router) Advertising Router: 3.3.3.3 LS Seq Number: 80000001 Checksum: 0x7E26 Length: 32 Network Mask: /24#当前区域内的路由器 Attached Router: 3.3.3.3 Attached Router: 1.1.1.1 33类LSA —路由器汇总LSA，由ABR（区域边界路由器）产生，用来将其他区域的路由进行汇总，然后转发到本区域。ARB传递的是路由表类似的LSA，会丢失掉拓扑信息，所以区域之间是无法得知拓扑。 R6#sh ip ospf database summary 3.3.3.3 44类LSA，ASBR汇总LSA，Link state ASBR，由ABR产生，用来告知本区域的路由器如何离开本OSPF自治系统 #注入外部路由，并形成一条默认路由int e0/2ip add dhcpno ship ospf 1 area 0router ospf 1default-information originate always 四类LSA： Summary ASB Link States (Area 1)R1#sh ip ospf database asbr-summary 4.4.4.4 55类LSA，由ASBR产生，用来告知本区域的路由器外面的条目 5类LSA： Type-5 AS External Link StatesR1#sh ip ospf database external OSPF Router with ID (1.1.1.1) (Process ID 1) Type-5 AS External Link States Routing Bit Set on this LSA in topology Base with MTID 0 LS age: 212 Options: (No TOS-capability, DC, Upward) LS Type: AS External Link Link State ID: 0.0.0.0 (External Network Number ) Advertising Router: 4.4.4.4 LS Seq Number: 80000001 Checksum: 0xFAEC Length: 36 Network Mask: /0 Metric Type: 2 (Larger than any link state path) MTID: 0 Metric: 10 Forward Address: 192.168.70.2 External Route Tag: 1 7用于在NSSA区域表示外界路由，由NSSA区域的边界路由产生，发布到其他区域时，会被ABR转换为5类的LSA。 # 需要在路由器上都配好 router ospf 1area 1 nssa #在R1上引入外部路由，也就是NSSA区域的路由器上引入外部路由ip route 11.11.11.11 255.255.255.255 null0router ospf 1 re st su R2的链路状态数据库中，11.11.11.11是7类LSA Type-7 AS External Link States (Area 1)Link ID ADV Router Age Seq# Checksum Tag11.11.11.11 1.1.1.1 123 0x80000001 0x006BF6 0在NSSA边界路由器，11.11.11.11被转换为了5类LSAR5的链路状态数据库 Type-5 AS External Link StatesLink ID ADV Router Age Seq# Checksum Tag0.0.0.0 4.4.4.4 343 0x80000002 0x00F8ED 111.11.11.11 3.3.3.3 323 0x80000001 0x00C3A0 0 有五类LSA但没有四类的LSA一定是因为存在NSSA区域导致的。 路由汇总由于OSPF不传递路由表信息，而是直接发送LSA信息，所以在一个区域内，所有路由器都有本区域的拓扑，所以在单个区域内无法完成路由汇总。 在OSPF中，汇总只能发生在ABR和ASBR上，这两种路由器转发的路由表的LSA信息。而其他路由器是转发拓扑信息 在R4添加int lo10ip add 172.16.1.1 255.255.255.0int lo20ip add 172.16.2.1 255.255.255.0int lo30ip add 172.16.3.1 255.255.255.0router ospf 1redistribute connected subnets # 可以观察到R1、R3、R4等路由器都受到了路由条目明细，现在在ASBR上对路由做汇总# 这里要注意，不能再ABR(R3)上对OSPF_as以外的路由进行汇总summary-address 172.16.0.0 255.255.0.0 注入默认路由在Stub网络里，注入默认路由无效，但是可以在NSSA网络注入。 router ospf 1default-information originate#这条命令用来产生一条五类的LSA，包含的是缺省路由信息。其它路由器收到这条LSA后，会计算出缺省路由0.0.0.0/0。#命令生效的条件是该路由器上存在缺省路由。如果没有，而且仍然想发布这种LSA，要在命令后面加always，即default-information originate always 构造虚链路OSPF路由器要成为ABR的条件，除了要同时连接多个区域，必须满足有一个接口连接area 0。 虚链路会导致故障变得复杂，线路变得不稳定，所以一般是个临时解决方案，一个全新设计的网络架构里面虚链路是不合理的。 virtual-link是ospf自带的虚链路解决方式，这种方式存在诸多问题，比如通过虚链路学习的LSA是DNA，含有DNA（do not age）的时间不会改变，这样会导致错误的LSA信息得不到更新，甚至虚链路邻居关系都不需要Hello包来维持。 R2： router ospf 1area 1 virtual-link 3.3.3.3area 1 virtual-link 4.4.4.4 R3 router ospf 1area 1 virtual-link 2.2.2.2 这时候，R3和R2建立了两个邻居关系，其中一个接口用的是OSPF_VL0 # 查看虚链路show ip ospf virtual-links HAMC只提供完整性和可用性，不提供机密性。OSPF分为接口和区域认证，但都是明文加密的 认证和RIP&amp;EIGRP类似。 OSPF小练习 区域配置R{1~4} ： area 0 R{3-5} , R{4-6} ：area 1 R{3,4}的环回口：area 0 R{5,6}的环回口：area 1 R{5,6,7}：area 2 优化命令 enconf tno ip do loline con 0no exec-tlogg syn R1 ho R1int e0/0ip add 192.168.12.1 255.255.255.0no ship ospf 1 area 0 int e0/1ip add 192.168.23.1 255.255.255.0no ship ospf 1 area 0int e0/2ip add 192.168.184.1 255.255.255.0no ship ospf 1 area 0int lo0 ip add 1.1.1.1 255.255.255.0ip ospf 1 area 0do sh ip int bri R2 ho R2int e0/0ip add 192.168.12.2 255.255.255.0no ship ospf 1 area 0 int e0/1ip add 192.168.24.2 255.255.255.0no ship ospf 1 area 0int e0/2ip add 192.168.184.2 255.255.255.0no ship ospf 1 area 0int lo0 ip add 2.2.2.2 255.255.255.0ip ospf 1 area 0do sh ip int bri R3 ho R3int e0/0ip add 192.168.13.3 255.255.255.0no ship ospf 1 area 0 int e0/1ip add 192.168.35.3 255.255.255.0no ship ospf 1 area 1int e0/2ip add 192.168.184.3 255.255.255.0no ship ospf 1 area 0int lo0 ip add 3.3.3.3 255.255.255.0ip ospf 1 area 0do sh ip int bri R4 ho R4int e0/0ip add 192.168.24.4 255.255.255.0no ship ospf 1 area 0 int e0/1ip add 192.168.46.4 255.255.255.0no ship ospf 1 area 1int e0/2ip add 192.168.184.4 255.255.255.0no ship ospf 1 area 0int lo0ip add 4.4.4.4 255.255.255.0ip ospf 1 area 0do sh ip int bri R5 ho R5int e0/0ip add 192.168.35.5 255.255.255.0no ship ospf 1 area 1int e0/1ip add 192.168.57.5 255.255.255.0no ship ospf 1 area 2int lo0ip add 5.5.5.5 255.255.255.0ip ospf 1 area 1do sh ip int bri R6 ho R6int e0/0ip add 192.168.46.6 255.255.255.0no sh ip ospf 1 area 1int e0/1 ip add 192.168.67.6 255.255.255.0no ship ospf 1 area 2int lo0ip add 6.6.6.6 255.255.255.0ip ospf 1 area 1do sh ip int bri R7 ho R7int e0/0ip add 192.168.57.7 255.255.255.0no ship ospf 1 area 2int e0/1ip add 192.168.67.7 255.255.255.0no ship ospf 1 area 2int lo0ip add 7.7.7.7 255.255.255.0ip ospf 1 area 2do sh ip int bri 目前来说，R1的1.1.1.1是ping不通R7的7.7.7.7的，因为R5和R6构不成边界路由器ABR。所以需要在R3-R5，R4-R6之间构建VPN隧道。 配置隧道R3int tun 0tu so 192.168.35.3 tu de 192.168.35.5ip add 172.16.35.3 255.255.255.0ip ospf 1 area 0R5:int tun 0tu so 192.168.35.5 tu de 192.168.35.3ip add 172.16.35.5 255.255.255.0ip ospf 1 area 0R4int tun 0tu so 192.168.46.4 tu de 192.168.46.6ip add 172.16.46.4 255.255.255.0ip ospf 1 area 0R6int tun 0tu so 192.168.46.6 tu de 192.168.46.4ip add 172.16.46.6 255.255.255.0ip ospf 1 area 0 当虚通道建立好的时候，就可以用R1ping通R7了。 R1、R2在R{1~4}的区域中分别为DR和BDR R1:int e0/2ip ospf priority 100R2:int e0/2ip ospf priority 90之后使用do clear ip ospf process 重置ospf 的进程 其余的链路使用P2P网络 R1:int range e0/0 -2ip ospf net point-to-pointR2:int range e0/0 -1ip ospf net point-to-pointR3:int range e0/0 -1ip ospf net point-to-pointR4:int range e0/0 -1ip ospf net point-to-pointR5int range e0/0 -1ip ospf net point-to-pointR6int range e0/0 -1ip ospf net point-to-pointR7int range e0/0 -1ip ospf net point-to-point 默认路由注入4、R1,R2缺省路由 R1:interface Loopback1 ip address 100.1.1.1 255.255.255.0 ip ospf 1 area 0router ospf 1 default-information originate always R2:interface Loopback1 ip address 100.1.1.1 255.255.255.0 ip ospf 1 area 0router ospf 1 default-information originate always metric 10 metrci - 度量值，越小越优 特殊区域5、area 2为特殊区域 R5:router ospf 1area 2 nssa no-summaryR6:router ospf 1area 2 nssa no-summaryR7router ospf 1redistribute connected subnetsarea 2 nssa ! ! ! OSPF 5类LSA比7类LSA更优先 没有开启nssa之前的路由表： O*E2 0.0.0.0/0 [110/10] via 172.16.46.4, 00:08:22, Tunnel0 1.0.0.0/32 is subnetted, 1 subnetsO 1.1.1.1 [110/1011] via 172.16.46.4, 00:01:58, Tunnel0 2.0.0.0/32 is subnetted, 1 subnetsO 2.2.2.2 [110/1011] via 172.16.46.4, 00:23:01, Tunnel0 3.0.0.0/32 is subnetted, 1 subnetsO 3.3.3.3 [110/1011] via 172.16.46.4, 00:02:22, Tunnel0 4.0.0.0/32 is subnetted, 1 subnetsO 4.4.4.4 [110/1001] via 172.16.46.4, 00:23:01, Tunnel0 5.0.0.0/32 is subnetted, 1 subnetsO IA 5.5.5.5 [110/1021] via 172.16.46.4, 00:02:22, Tunnel0 6.0.0.0/8 is variably subnetted, 2 subnets, 2 masksC 6.6.6.0/24 is directly connected, Loopback0L 6.6.6.6/32 is directly connected, Loopback0 7.0.0.0/32 is subnetted, 1 subnetsO 7.7.7.7 [110/11] via 192.168.67.7, 00:42:06, Ethernet0/1 100.0.0.0/32 is subnetted, 1 subnetsO 100.1.1.1 [110/1011] via 172.16.46.4, 00:01:58, Tunnel0 172.16.0.0/16 is variably subnetted, 3 subnets, 2 masksO 172.16.35.0/24 [110/2010] via 172.16.46.4, 00:02:22, Tunnel0C 172.16.46.0/24 is directly connected, Tunnel0L 172.16.46.6/32 is directly connected, Tunnel0O 192.168.12.0/24 [110/1020] via 172.16.46.4, 00:23:01, Tunnel0O 192.168.13.0/24 [110/1020] via 172.16.46.4, 00:02:22, Tunnel0O 192.168.23.0/24 [110/1020] via 172.16.46.4, 00:01:58, Tunnel0O 192.168.24.0/24 [110/1010] via 172.16.46.4, 00:23:01, Tunnel0O IA 192.168.35.0/24 [110/1020] via 172.16.46.4, 00:02:22, Tunnel0 192.168.46.0/24 is variably subnetted, 2 subnets, 2 masksC 192.168.46.0/24 is directly connected, Ethernet0/0L 192.168.46.6/32 is directly connected, Ethernet0/0O 192.168.57.0/24 [110/20] via 192.168.67.7, 00:42:06, Ethernet0/1 192.168.67.0/24 is variably subnetted, 2 subnets, 2 masksC 192.168.67.0/24 is directly connected, Ethernet0/1L 192.168.67.6/32 is directly connected, Ethernet0/1O 192.168.184.0/24 [110/1010] via 172.16.46.4, 00:02:22, Tunnel0O 192.168.197.0/24 [110/1020] via 172.16.46.4, 00:01:58, Tunnel0 装完NSSA 屏蔽外部路由，形成一条默认路由0.0.0.0/0，指向R5和R6 O*IA 0.0.0.0/0 [110/11] via 192.168.67.6, 00:00:05, Ethernet0/1 [110/11] via 192.168.57.5, 00:00:05, Ethernet0/0 7.0.0.0/8 is variably subnetted, 2 subnets, 2 masksC 7.7.7.0/24 is directly connected, Loopback0L 7.7.7.7/32 is directly connected, Loopback0 192.168.57.0/24 is variably subnetted, 2 subnets, 2 masksC 192.168.57.0/24 is directly connected, Ethernet0/0L 192.168.57.7/32 is directly connected, Ethernet0/0 192.168.67.0/24 is variably subnetted, 2 subnets, 2 masksC 192.168.67.0/24 is directly connected, Ethernet0/1L 192.168.67.7/32 is directly connected, Ethernet0/1 路由汇总6、R3的路由汇总 R3:======$这些回环接口配置的ip地址宣告进了area 1，所以在area 1中汇总int lo1ip add 172.16.1.1 255.255.255.0int lo2ip add 172.16.2.1 255.255.255.0int lo3ip add 172.16.3.1 255.255.255.0int range lo1,lo2,lo3ip ospf 1 area 1router ospf 1area 1 range 172.16.0.0 255.255.0.0R5:======router ospf 1area 1 range 172.16.0.0 255.255.0.0R2:======router ospf 1area 1 range 172.16.0.0 255.255.0.0 Question？：为什么R1读取不到R3的172.16.0.0/16的条目，而R5可以读到，因为R3和R5有一个Tunnel 吗？ 在汇总之前，R1的路由表 172.16.0.0/16 is variably subnetted, 5 subnets, 2 masksO IA 172.16.1.1/32 [110/11] via 192.168.184.3, 00:00:05, Ethernet0/2O IA 172.16.2.1/32 [110/11] via 192.168.184.3, 00:00:05, Ethernet0/2O IA 172.16.3.1/32 [110/11] via 192.168.184.3, 00:00:05, Ethernet0/2O 172.16.35.0/24 [110/1010] via 192.168.184.3, 00:37:33, Ethernet0/2O 172.16.46.0/24 [110/1010] via 192.168.184.4, 00:37:33, Ethernet0/2 OSPF认证7、area 0的明文认证 R1-R3,先不开启R4的明文认证router ospf 1area 0 authentication#注意，下面的所有代码都是R5和R6没有添加明文认证的，这里添加上明文认证#难关area 0学习不到7.7.7.0的路由router ospf 1area 0 authentication 等到40s死亡计时过了之后，就会发现R4失效： *Jan 1 03:13:17.836: %OSPF-5-ADJCHG: Process 1, Nbr 2.2.2.2 on Ethernet0/0 from FULL to DOWN, Neighbor Down: Dead timer expiredR4(config)#router*Jan 1 03:13:19.671: %OSPF-5-ADJCHG: Process 1, Nbr 2.2.2.2 on Ethernet0/2 from FULL to DOWN, Neighbor Down: Dead timer expiredR4(config)#router ospf 1R4(config-router)#*Jan 1 03:13:21.215: %OSPF-5-ADJCHG: Process 1, Nbr 3.3.3.3 on Ethernet0/2 from FULL to DOWN, Neighbor Down: Dead timer expired 一旦在R4上开启认证，R4又会重新从Down变成Full R4:router ospf 1area 0 authentication R3-5，R4-6密文认证 R3:int e0/1ip ospf message-digest-key 1 md5 cis_padip ospf authentication message-digest# 配置完之后，R3路由表中，R5的Dead Time会跌出30，然后直到消失，这是在R5的相应接口上也配置认证,彼此又会建立相应的连接。int e0/0ip ospf message-digest-key 1 md5 cis_padip ospf authentication message-digest 抑制路由8、禁止area 2内的路由被其他区域学到 R5:=====router ospf 1area 1 range 192.168.57.0 255.255.255.0 not-advertisearea 1 range 192.168.67.0 255.255.255.0 not-advertisearea 2 nssa translate type7 suppress-faR6:=====router ospf 1area 1 range 192.168.57.0 255.255.255.0 not-advertisearea 1 range 192.168.67.0 255.255.255.0 not-advertisearea 2 nssa translate type7 suppress-fa OSPF命令配置OSPF协议 router ospf [Process_ID] #进程ID本地有效network 1.1.1.0 0.0.0.255 area 0 #将1.1.1.0网段(包含子网掩码)宣告进OSPF网络router-id 1.1.1.1 #设置Router-ID，注意需要重启生效#基于链路的配置int range e0/0 -1 #行入e/0、e0/1接口ip ospf 1 area 0 #将该接口加入OSPF，并且按照配置的子网掩码宣告其接口上 配置OSPF优先级 int e0/0ip ospf priority 10 # 默认为1# 重置OSPF进程，重新选举do clear ip ospf process LSA # 查看1类LSAshow ip ospf database router x.x.x.x# 查看2类LSAshow ip ospf database network x.x.x.x# 查看3类LSAshow ip ospf database summary x.x.x.x# 查看4类LSAshow ip ospf database asbr-summary x.x.x.x# 查看5类LSAshow ip ospf database external x.x.x.x# 查看7类LSAshow ip ospf database router x.x.x.x","categories":[{"name":"路由技术","slug":"路由技术","permalink":"http://ymlog.cn/categories/%E8%B7%AF%E7%94%B1%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"OSPF协议","slug":"OSPF协议","permalink":"http://ymlog.cn/tags/OSPF%E5%8D%8F%E8%AE%AE/"}]},{"title":"Linux Virtual Server","slug":"LVS","date":"2020-02-19T13:33:30.000Z","updated":"2020-07-04T17:19:01.490Z","comments":true,"path":"2020/02/19/LVS/","link":"","permalink":"http://ymlog.cn/2020/02/19/LVS/","excerpt":"念两句诗险夷原不滞胸中，何异浮云过太空?夜静海涛三万里，月明飞锡下天风。","text":"念两句诗险夷原不滞胸中，何异浮云过太空?夜静海涛三万里，月明飞锡下天风。 LVS简介在已有的负载均衡技术中，IP负载均衡是效率最高的。它将一组服务器构建成一个高性能、高可用的虚拟服务器。如图，LVS一共有以下两部分组成： Load Balance Machine，提供调度的机器，负责接收用户请求后转发给后端Server集群 Real Server ，真实的服务器集群，负责提供各种服务 其中，LB机器上运行LVS，LVS有用户空间和内核空间两部分组成： IPVS（IP Virtual Server）：工作在内核空间中，是真正生效实现调度的代码。 ipvsadm：工作在用户空间，负责为ipvs内核框架编写规则，定义谁是集群，谁是后端真实服务器。 LB集群原理：当用户的请求过来时，会直接分发到Director Server上，然后它把用户请求根据设置好的调度算法，智能均衡的分配到后端真正的服务器上（Real Server） LVS一共有三种模式，分别是： Virtual Server via Network Address Translation（VS/NAT） Virtual Server via IP Tunneling（VS/TUN） Virtual Server via Direct Routing（VS/DR） LVS一共有8中调度算法 轮询（Round Robin）调度器通过”轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。 加权轮询（Weighted Round Robin）调度器通过”加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 最少链接（Least Connections）调度器通过”最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用”最小连接”调度算法可以较好地均衡负载。 加权最少链接（Weighted Least Connections）在集群系统中的服务器性能差异较大的情况下，调度器采用”加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 基于局部性的最少链接（Locality-Based Least Connections）”基于局部性的最少链接” 调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器 是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用”最少链接”的原则选出一个可用的服务 器，将请求发送到该服务器。 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）”带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个 目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务 器组，按”最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器，若服务器超载；则按”最小连接”原则从这个集群中选出一 台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的 程度。 目标地址散列（Destination Hashing）”目标地址散列”调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 源地址散列（Source Hashing）”源地址散列”调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 最短的期望的延迟？ 最少队列调度？ 相关术语 DS：Director Server。指的是前端负载均衡器节点。 RS：Real Server。后端真实的工作服务器。 VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 RIP：Real Server IP，后端服务器的IP地址。 CIP：Client IP，访问客户端的IP地址。 VS/NAT工作模型 流程： 当用户访问服务器提供服务时，发往VIP地址的请求包到达LB机器 LB机器检查数据包的目标IP和目标Port，去匹配LVS中的规则，然后根据负载均衡算法从集群中选择RS响应请求，并将连接添加到记录已连接的Hash表中 将数据包的目的地址和端口重写–&gt; 选中的RS的IP:Port，然后转发RS。 RS返回数据报时，SrcIP：RIP.Rport DstIP DIP.Dport。 LB机器将数据报中的源IP地址和源Port重写为DS的源地址和源Port 连接终止或超时后，连接记录就会在已连接的Hash表中删除 特性： RS应该使用私有IP地址，RS的网关是DIP地址 DIP要和RIP属于同一个网段 请求和响应报文都需要经过DS（性能瓶颈） 支持端口映射 RS可以使用任意操作系统 VS/DR工作模型 流程： 当用户访问服务器提供服务时，发往VIP地址的请求包到达LB机器。 LB机器根据负载均衡算法，选出合适的RS，将目的Mac修改为RS的Mac，其余不变，并将连接记录添加到Hash表。 RS处理完报文后，将响应报文直接发送给客户端 连接终止或超时后，连接记录就会在已连接的Hash表中删除 数据报流动： 非ARP接口： 因为DR需要所有设备在同一个局域网内，而arp广播，会发送LAN的所有机器（LB机器和RS机器），我们现在只需要LB机器去响应VIP请求，要求只能是DR进行响应VIP的arp请求，而RS不能够响应。我们需要设置arp参数（RS)，限制其不能响应VIP的arp请求。 arp_ignore：arp响应 arp_announce：arp通告 特性： 保证前端路由将目标地址为VIP报文通通发给DS RS可以使用私有IP地址，也可以使用公网IP地址，如果使用公网地址，此时通过Internet对RIP进行直接访问 RS和DS必须在同一个物理网络当中 请求报文经过DS到RS，但是响应报文不经过DS（消除nat模式下的性能瓶颈） 不支持地址转化，也不支持端口映射 RS的网关决不能指向DS（因为我们允许RS通过DS） RS上的lo接口配置VIP地址 VS/TUN工作模型 流程： 当用户访问服务器提供服务时，发往VIP地址的请求包到达LB机器。 调度器根据各个服务器的负载情况，动态地选择一台服务器， 将请求报文封装在另一个IP报文中，再将封装后的IP报文转发给选出的服务器 服务器收到报文后，先将报文解封获得原来目标地址为VIP的报文，服务器发 现VIP地址被配置在本地的IP隧道设备上，所以就处理这个请求，然后根据路由表将响应报文直接返回给客户。 数据报流动： 特点： TUN的建立需要时动态的，类似DMVPN 因为又添加了IP报头，所以IP隧道会消耗一定的资源 不需要DS返回响应，和DR类似 Tun可以做加密，IPSec等 三种模型的比较1. Virtual Server via NAT：VS/NAT 的优点是服务器可以运行任何支持TCP/IP的操作系统，它只需要一个IP地址配置在调度器上，服务器组可以用私有的IP地址。缺点是它的伸缩能力有限，因为在VS/NAT中请求和响应报文都需要通过负载调度器。可以有三种方法解决这个问题：混合方法、VS/TUN和 VS/DR。在DNS混合集群系统中，有若干个VS/NAT负载调度器，每个负载调度器带自己的服务器集群，同时这些负载调度器又通过RR-DNS组成简 单的域名。但VS/TUN和VS/DR是提高系统吞吐量的更好方法。对于那些将IP地址或者端口号在报文数据中传送的网络服务，需要编写相应的应用模块来转换报文数据中的IP地址或者端口号。这会带来实现的工作量，同时应用模块检查报文的开销会降低系统的吞吐率。 2. Virtual Server via IP Tunneling：在VS/TUN 的集群系统中，负载调度器只将请求调度到不同的后端服务器，后端服务器将应答的数据直接返回给用户。这样，负载调度器就可以处理大量的请求，它甚至可以调 度百台以上的服务器（同等规模的服务器），而它不会成为系统的瓶颈。VS/TUN技术对服务器有要求，即所有的服务器必须支持“IP Tunneling”或者“IP Encapsulation”协议。目前，VS/TUN的后端服务器主要运行Linux操作系统，我们没对其他操作系统进行测试。因为“IP Tunneling”正成为各个操作系统的标准协议，所以VS/TUN应该会适用运行其他操作系统的后端服务器。 3. Virtual Server via Direct Routing：跟VS/TUN方法一样，VS/DR调度器只处理客户到服务器端的连接，响应数据可以直接从独立的网络路由返回给客户。这可以极大地提高LVS集群系统的伸缩性。跟VS/TUN相比，这种方法没有IP隧道的开销，但是要求负载调度器与实际服务器都有一块网卡连在同一物理网段上，服务器网络设备（或者设备别名）不作ARP响应，或者能将报文重定向（Redirect）到本地的Socket端口上。 LVS实验1、LVS/NAT实验配置： DS / LB机器 地址类型 IP地址 VIP 192.168.1.105 DIP 192.168.70.10 RS / WEB服务器 站点 IP地址 默认网关 RS1 RIP：172.10.10.20/16 GATEWAY： 172.10.10.2 RS2 RIP：172.10.10.30/16 GATEWAY：172.10.10.2 DS / LB机器的网卡，添加了一块桥接的网卡，之后访问就直接访问那块桥接网卡的IP地址。这样真实的IP地址就不会暴露在公网了。 eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.10.10.1 netmask 255.255.0.0 broadcast 172.10.255.255eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.1.2 netmask 255.255.255.0 broadcast 192.168.1.255 RS站点部署 使用httpd服务，这里介绍以下httpd服务，主配置文件：/etc/httpd/conf/httpd.conf，默认站点目录：/var/www/html。 需要把RS机器的默认网关修改为DS机器的IP地址 #node02 node03yum -y install httpdsystemctl restart httpdecho \"THIS IS NODE02\" &gt; /var/www/html/index.htmlsed -i '/GATEWAY/d' /etc/sysconfig/network-scripts/ifcfg-ens32echo \"GATEWAY=192.168.70.10\" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-ens32systemctl restart network DS站点部署 # 安装ipvsadm，lvs的管理工具yum -y install ipvsadm# 打开转发配置NAT，0是关闭echo \"1\" &gt; /proc/sys/net/ipv4/ip_forward# 清除Ptables NAT表的规则iptables -t nat -F# 添加iptables规则，让去往ens35的流量转发给192.168.70.10 公网--&gt;私网iptables -t nat -A POSTROUTING -s 192.168.70.10/24 -o ens35 -j MASQUERADE#清除ipvsadm的所有规则ipvsadm --clear#设置wrr加权轮询策略并添加主机ipvsadm -A -t 192.168.1.105:80 -s wrr#添加主机，将到达192.168.1.105的流量转到192.168.70.20ipvsadm -a -t 192.168.1.105:80 -r 192.168.70.20:80 -m -w 2#添加主机，将到达192.168.1.105的流量转到192.168.70.30ipvsadm -a -t 192.168.1.105:80 -r 192.168.70.30:80 -m -w 1# ipvsadm常用选项# -A : 添加Virtual Server Address（VIP+Port）# -s : 定义负载均衡策略# -e : 修改匹配规则# -r : 指定RS的地址和端口# -m : 指定为NAT# -w : 指定权重#查看策略信息ipvsadm -ln 之前在docker上做了一遍，到添加虚拟服务地址VSA的时候报错了，大概是LVS是要通过LINUX内核来实现，docker下完成不了对内核的改动，所以用不了。 [root@00564133da53 /]# sudo ipvsadm -A -t 192.168.1.2:80 -s wrrCan't initialize ipvs: Protocol not availableAre you sure that IP Virtual Server is built in the kernel or as module? 2、LVS/DR环境准备： DS / LB机器 地址类型 IP地址 VIP 192.168.70.100 DIP 192.168.70.10 RS / WEB服务器 站点 IP地址 VIP地址 RS1 RIP：192.168.70.20 192.168.70.100 lo RS2 RIP：192.168.70.30 192.168.70.100 lo RS部署 #!/bin/bash#不能让Gateway指向node1sed -i '/GATEWAY/d' /etc/sysconfig/network-scripts/ifcfg-ens32sed -i '/^$/d' /etc/sysconfig/network-scripts/ifcfg-ens32echo \"GATEWAY=192.168.70.2\" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-ens32systemctl restart networksystemctl restart httpdyum -y install net-toolsvip=192.168.70.100ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0#1是关闭echo \"1\" &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho \"2\" &gt; /proc/sys/net/ipv4/conf/lo/arp_announceecho \"1\" &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho \"2\" &gt; /proc/sys/net/ipv4/conf/all/arp_announce#在所有RS上部署 RS脚本： #!/bin/bashyum -y install httpd net-toolssystemctl restart httpdecho \"THIS IS NODE03\" &gt; /var/www/html/index.htmlvip=192.168.70.100ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip lo:0echo \"1\" &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho \"2\" &gt; /proc/sys/net/ipv4/conf/lo/arp_announceecho \"1\" &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho \"2\" &gt; /proc/sys/net/ipv4/conf/all/arp_announce DS部署 ifconfig ens32:0 192.168.70.100 broadcast 192.168.70.255 netmask 255.255.255.0 up#本地重定向,去往192.168.70.100的流量从本地ens32:0走route add -host 192.168.70.100 dev ens32:0 ipvsadm -A -t 192.168.70.100:80 -s wrripvsadm -a -t 192.168.70.100:80 -r 192.168.70.20:80 -m -w 1ipvsadm -a -t 192.168.70.100:80 -r 192.168.70.30:80 -m -w 2ipvsadm -ln DS脚本 #!/bin/bashyum -y install net-tools ipvsadm echo \"0\" &gt; /proc/sys/net/ipv4/ip_forward#ifconfig ens32:0 192.168.70.100 broadcast 192.168.70.255 netmask 255.255.255.0 up#route add -host 192.168.70.100 dev ens32:0 ipvsadm -A -t 192.168.70.100:80 -s wrripvsadm -a -t 192.168.70.100:80 -r 192.168.70.20:80 -g -w 9ipvsadm -a -t 192.168.70.100:80 -r 192.168.70.30:80 -g -w 1ipvsadm -lnipvsadm -Cfor i in &#123;1..10&#125;;do curl 192.168.70.100:80; done","categories":[{"name":"中间件","slug":"中间件","permalink":"http://ymlog.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"LVS","slug":"LVS","permalink":"http://ymlog.cn/tags/LVS/"}]},{"title":"Keepalived高可用","slug":"Keepalived","date":"2020-02-19T11:34:05.000Z","updated":"2020-07-04T17:19:24.864Z","comments":true,"path":"2020/02/19/Keepalived/","link":"","permalink":"http://ymlog.cn/2020/02/19/Keepalived/","excerpt":"念两句诗夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。长恨此身非我有，何时忘却营营？夜阑风静縠纹平。小舟从此逝，江海寄馀生。","text":"念两句诗夜饮东坡醒复醉，归来仿佛三更。家童鼻息已雷鸣。敲门都不应，倚杖听江声。长恨此身非我有，何时忘却营营？夜阑风静縠纹平。小舟从此逝，江海寄馀生。 Keepalived简介 是Linux一个轻量级的高可用解决方案，Keepalive起初是为了LVS设计的，专门用来监控集群系统中各个服务节点状态，如果某个服务器节点出现故障，keepalive将检测到后自动将节点剔除 keepalived后来加入VRRP协议，（虚拟路由冗余协议），目的是解决静态路由出现的单点故障问题，通过VRRP协议可以实现网络不间断稳定运行，因此Keepalived也具有Ha功能 两大功能：健康检查和失败切换 健康检查：采用TCP三次握手，ICMP请求，HTTP请求，UDP echo请求等方式对负载均衡后端真实服务器进行保活。 失败切换：主要应用于配置主备模式负载均衡器，利用VRRP协议维持主备的心跳，当主负载均衡出现问题的时候，由备负载均衡器承载对应的业务，从而在最大限度上减少流量的损失 IPVS疯转，Keepalived里面所有对LVS的相关操作并不直接使用ipvsadm客户端程序，而是直接使用ipvs提供的函数进程操作。 VRRP协议VRRP协议： VRRP协议是一种容错的主备协议，保证当主机的下一跳路由出现故障的时候，由另外一台路由来替代出现故障的路由器进行工作，通过VRRP可以在网络发生故障时，透明的进行设备切换而不影响主机之间数据通信 VRRP虚拟路由器：VRRP虚拟路由器是由多台物理路由器组成，对外共享一个或多个IP地址，这个IP地址是虚拟出来的，不属于任何一台路由器，称之为VIP。 VRRP路由器：VRRP路由器就是一台路由器，只是上面运行了VRRP协议 主路由器：虚拟路由内部有多台物理路由器，但通常只有一台物理路由器对外提供服务，主路由器是选举算法选出对外提供各种网络功能 备份路由器：VRRP组中除了主路由器之外的所有路由器，不对外提供任何服务，只接受主路由器的通告，当主路由器挂掉时，重新进行选举算法，接替master路由器 三种状态：Initialize、Master、Backup 选举机制：优先级 抢占模式下，一旦有优先级高的路由器加入，即成为Master； 非抢占模式下只要Master不挂，优先级高的路由器只能等待。 只有作为Master的VRRP路由器会一直发送VRRP广播报文。 Keepalived架构KeepAlived源码模块： check core libipfwc libipvs* vrrp core：keepalived核心程序，比如全局配置解析，进程启动等 vrrp：实现vrrp协议的功能 check：keepalived的healthchecker子进程的目录，包括了所有健康检查方式以及对应的配置解析信息，LVS配置解析也在这里 libipfwc：iptables(ipchains库)，主要用来配置LVS中的firewall-mark libipvs*：LVS用到的文件 Schedulerl/OMultiplexer是一个I/O复用分发调度器，它负载安排Keepalived所有内部的任务请求 Memory Mngt是一个内存管理机制，这个框架提供了访问内存的一些通用方法 Control Plane时keepalived的控制版面，可以实现对配置文件编译和解析 Core Componets Watchdog：是计算机可靠领域简单而又非常有效的检测工具，Keepalived正式通过它监控Checkers和VRRP进程的 Checkers：这时Keepalived最基础的功能，也是最主要的功能，可以实现对服务器运行状态检测和故障隔离 VRRP Stack：这时Keepalived后来引用VRRP功能，可以实现HA集群中失败切换功能，负责负载均衡器之间的实拍切换FailOver IPVS Wrapper：这个是IPVS功能的一个实现，IPVSwrapper模块可以设置好IPVS规则发送至内核空间并且提供给IPVS模块，最终实现IPVS模块的负载功能 Netlink Reflector：用来实现高可用集群Failover是虚拟IP（VIP）的设置和切换 keepalived进程： keepalived配置文件keepalived配置文件分为三类： global：全局配置文件 vrrpd配置 lvs配置，如果仅使用keepalived做HA，lvs可以不用配 总体[root@haproxy /]# cat /etc/keepalived/keepalived.conf | grep -Ev '^#|^$'! Configuration File for keepalivedglobal_defs &#123; #全局定义 notification_email &#123; acassen@firewall.loc #通知email failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc #Email发送者 smtp_server 192.168.200.1 #SMTP服务器 smtp_connect_timeout 30 #连接超时 router_id LVS_DEVEL #Router-id,是路由标识，通常是主机名 vrrp_skip_check_adv_addr #VRRP协议跳过健康检查通告 vrrp_strict #VRRP自定义脚本 vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; #VRRP组 state MASTER #master状态 interface eth0 #接口 virtual_router_id 51 #虚拟路由器ID，同一个局域网内 priority 100 #优先级 advert_int 1 authentication &#123; #认证 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #VIP地址，之后用户访问只需要用vip地址即可 192.168.200.16 192.168.200.17 192.168.200.18 &#125;&#125;#后面是LVS相关，这里先不写 全局Keepalived的详细配置 全局配置&#123; #静态IP static_ipaddress &#123; #等价于ip命令：ip addr add 192.168.1.1/24 brd + dev eth0 scope global 192.168.1.1/24 brd + dev eth0 scope global &#125; #静态路由 static_routes &#123; src $SRC_IP to $DST_IP dev $SRC_DEVICE ... src $SRC_IP to $DST_IP via $GW dev $SRC_DEVICE &#125;&#125; VRRPVRRPD：vrrp同步组和vrrp实例 VRRP Sync Groups同步组里的任何一个成员产生问题，则进行master和backup切换。比如内网和外网的实例不在一个同步组，其中一个网段异常，则VIP不会漂移。vrrp_sync_group VG_1 &#123; group &#123; inside_network #这里是实例名，比如VI_1 outside_network &#125; notify_master /path/to/to_master.sh #当切换到master时，执行脚本... notify_backup /path_to/to_backup.sh notify_fault \"/path/fault.sh VG_1\" notify /path/to/notify.sh #切换后发送邮件通知 smtp_alert&#125;vrrp实例主要定义漂移组的ip地址vrrp_instance inside_network &#123; state MASTER #定义初始Initial状态，启动后根据优先级马上竞选，state不代表这台一直是master interface eth0 #实例绑定的网卡 track_interface &#123; eth0 eth1&#125; #设置额外的监控，里面任何一个网卡出现问题，都会进入fault状态 virtual_router_id 51 #VRID 虚拟路由器ID priority 100 advert_int 1 #检查隔离，默认1s authentication &#123; auth_type PASS autp_pass 1234 &#125; #认证设置，authe_type可以是pass和ah virtual_ipaddress &#123;192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1&#125; #发生切换时添加/删除路由 virtual_routes &#123;src 192.168.100.1 to 192.168.109.0/24 via 192.168.200.254 dev eth1&#125; nopreempt #设置为不抢占，只能设置为state=BACKUP，且优先级最高的机器上 preemtp_delay 300 debug #Debug级别&#125; LVSvirtual_server 192.168.200.100 443 &#123; #设置一个Virtual Server：VIP+Port delay_loop 6 #servce polling的delay时间 lb_algo rr #LVS调度算法，有rr wrr lc wlc lblc sh dh lb_kind NAT #LVS集群模式，有NAT、DR、TUN persistence_timeout 50 #会话保持时间 protocol TCP #使用TCP协议，有TCP、UDP sorry_server 192.168.200.200 1358 #备用机，所有的real server失效后再用 real_server 192.168.201.100 443 &#123; #真实物理主机 weight 1 #权重默认为1，0为失效 inhibit_on_failure #在健康检查失败后，将weight设置为0，而不是从ipvs中删除#配置任意一种健康检查方式：HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK SSL_GET &#123; url &#123; path / digest ff20ad2481f97b1754ef3e12ecd3a9cc #SSL检查后的摘要信息(genhash工具算出) &#125; connect_timeout 3 #连接超时时间 nb_get_retry 3 #重连次数 delay_before_retry 3 #重连间隔时间 &#125; HTTP_GET &#123; url &#123; path /testurl/test.jsp digest 640205b7b0fc66c1ea91c463fac6334d &#125; &#125; TCP_CHECK &#123; #TCP健康检查 connect_port 80 bindto 192.168.1.1 connect_timeout 4 &#125; SMTP_CHECK &#123; host &#123; connect_ip &lt;IP ADDRESS&gt; connect_port &lt;PORT&gt; bindto &lt;IP ADDRESS&gt; &#125; &#125; &#125;&#125; lvs实例 lvs配置实例virtual_server 192.168.1.1 80 &#123; delay_loop 3 lb_algo wlc lb_kind DR persistence_timeout 1200 protocol TCP ha_suspend real_server 192.168.1.11 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 3 &#125; &#125; real_server 192.168.1.12 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 3 &#125; &#125; &#125; Keepalived + Nginx 环境准备VIP：192.168.70.199 机器 IP地址 服务 Node1 192.168.70.10 nginx 、 keepalived Node2 192.168.70.20 nginx 、 keepalived Web1 192.168.70.30 httpd Web2 192.168.70.40 httpd Web/1-2yum -y install httpdsystemctl restart httpdecho \"THIS IS $HOSTNAME..\" &gt; /var/www/html/index.html Node01node01，主节点 #配置Nginx反向代理yum -y install epel-releaseyum -y install nginxcat &gt;&gt; /etc/nginx/conf.d/lb.conf &lt;&lt; 'EOF'#负载均衡中的后端服务器池upstream webserver &#123; server 192.168.70.30; server 192.168.70.40;&#125;#将本地的8080端口请求转发到代理服务器池中server &#123; listen 8080; location / &#123; proxy_pass http://webserver; &#125;&#125;EOFsystemctl restart nginx# 配置Keepalived高可用yum -y install keepalivedmv /etc/keepalived/keepalived.conf&#123;,.bak&#125; #注意事项，check_nginx和花括号要有空格，track_script要写在VIP后面cat &gt;&gt; /etc/keepalived/keepalived.conf &lt;&lt; 'EOF'global_defs &#123; router_id node01&#125;#定义健康检测脚本，执行间隔为1s，如果脚本执行异常，也就是Nginx down了，则优先级-20vrrp_script check_nginx &#123; script \"/root/check.sh\" interval 1 weight -20&#125;vrrp_instance VI_1 &#123;#node01为Master角色 state MASTER#使用的接口为ens32，如果不通系统需要改，Keepalived服务起来时，VIP就挂在ens32接口上 interface ens32#VID，同一个局域网需要相同 virtual_router_id 51#主节点优先级，定义110，次节点为100 priority 110 advert_int 1#VIP地址，如果时主主备份可以定义多个 virtual_ipaddress &#123; 192.168.70.199 &#125;#脚本跟踪，记住空格 track_script &#123; check_nginx&#125;&#125;EOFsystemctl restart keepalived#这一段不能用cat的形式录入，不然$会丢失[root@node01 ~]# cat check.sh #!/bin/bashecho \"THIS SCRIPT IS RAN！！！\"Num=$(ps -C nginx --no-header | wc -l)if [ $Num -eq 0 ];then#Num=0意味着Nginx挂了 exit 1else exit 0fichmod +x /root/check.sh Node02node02，备份节点 #配置Nginx反向代理yum -y install epel-releaseyum -y install nginxcat &gt;&gt; /etc/nginx/conf.d/lb.conf &lt;&lt; 'EOF'upstream webserver &#123; server 192.168.70.30; server 192.168.70.40;&#125;server &#123; listen 8080; server_name 192.168.20.10; location / &#123; proxy_pass http://webserver; &#125;&#125;EOFsystemctl restart nginx#配置Keepalive高可用yum -y install keepalivedmv /etc/keepalived/keepalived.conf&#123;,.bak&#125; cat &gt;&gt; /etc/keepalived/keepalived.conf &lt;&lt; 'EOF'global_defs &#123; router_id node02&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens32 virtual_router_id 51 priority 100 advert_int 1 virtual_ipaddress &#123; 192.168.70.199 &#125;&#125;EOFsystemctl restart keepalived 实验效果测试节点 Down Keepalive Down Nginx Keepalived + haproxy 实验环境准备VIP：192.168.70.199 机器 IP地址 服务 Node1 192.168.70.10 haproxy 、keepalived Node2 192.168.70.20 haproxy 、keepalived Web1 192.168.70.30 mariadb Web2 192.168.70.40 mariadb MySQL双主node03 yum -y install mariadb-server sed -i '/^\\[mysqld\\]$/a\\binlog-ignore = information_schema' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\binlog-ignore = mysql' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\skip-name-resolve' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\auto-increment-increment = 1' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\log-bin = mysql-bin' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\auto_increment_offset = 1' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\server-id = 1' /etc/my.cnf.d/server.cnfcat /etc/my.cnf.d/server.cnf | grep -Ev '#|^$'mysql -uroot -e \"grant replication slave on *.* to 'repuser'@'192.168.70.40' identified by '123456';\" mysql -uroot -e \"show master status;\"mysql -uroot -e \"change master to master_host='192.168.70.40',master_port=3306,master_user='repuser',master_password='123456',master_log_file='mysql-bin.000003',master_log_pos=407;\"mysql -uroot -e \"start slave;\"#授权用户，便于测试mysql -uroot -e \"grant all privileges on *.* to 'zhoujing'@'%' IDENTIFIED BY '000000'; \" node04 yum -y install mariadb-server sed -i '/^\\[mysqld\\]$/a\\binlog-ignore = information_schema' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\binlog-ignore = mysql' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\skip-name-resolve' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\auto-increment-increment =2 ' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\log-bin = mysql-bin' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\auto_increment_offset = 2' /etc/my.cnf.d/server.cnfsed -i '/^\\[mysqld\\]$/a\\server-id = 2' /etc/my.cnf.d/server.cnfmysql -uroot -e \"grant replication slave on *.* to 'repuser'@'192.168.70.30' identified by '123456';\" mysql -uroot -e \"show master status;\"mysql -uroot -e \"change master to master_host='192.168.70.30',master_port=3306,master_user='repuser',master_password='123456',master_log_file='mysql-bin.000003',master_log_pos=402;\"mysql -uroot -e \"start slave;\" mysql -uroot -e \"grant all privileges on *.* to 'zhoujing'@'%' IDENTIFIED BY '000000'; \" 检查MySQL主主同步是否成功： HaProxy代理Node01 / 02 的Haproxy配置相同 yum -y install haproxy[root@node01 ~]# cat /etc/haproxy/haproxy.cfg global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statslisten mysql_proxy bind 0.0.0.0:3306 mode tcp balance source server mysqldb1 192.168.70.30:3306 weight 1 check server mysqldb2 192.168.70.40:3306 weight 2 checklisten stats mode http bind 0.0.0.0:8080 stats enable stats uri /dbs stats realm haproxy\\ statistics stats auth admin:adminsystemctl restart haproxy Keepalived高可用node01 #node01上写触发脚本yum -y install keepalived[root@node01 ~]# cat /etc/keepalived/keepalived.confglobal_defs &#123; router_id node01&#125;vrrp_script chk_http_port &#123;#脚本所在位置 script \"/root/check_proxy_pid.sh\" interval 1 weight -20&#125;vrrp_instance VI_1 &#123; state MASTER interface ens32 virtual_router_id 51 priority 110 advert_int 1 virtual_ipaddress &#123; 192.168.70.199 &#125; track_script &#123; chk_http_port &#125;&#125;[root@node01 ~]# cat check_proxy_pid.sh #!/bin/bashecho \"THIS SCRIPT IS RAN！！！\"Num=$(ps -C haproxy --no-header | wc -l)if [ $Num -eq 0 ];then exit 1else exit 0fisystemctl restart keepalived node02 yum -y install keepalived[root@node01 ~]# cat /etc/keepalived/keepalived.confglobal_defs &#123; router_id node01&#125;vrrp_instance VI_1 &#123; state MASTER interface ens32 virtual_router_id 51 priority 110 advert_int 1 virtual_ipaddress &#123; 192.168.70.199 &#125; track_script &#123; chk_http_port &#125;&#125;systemctl restart keepalived 【完】","categories":[{"name":"中间件","slug":"中间件","permalink":"http://ymlog.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Keepalived","slug":"Keepalived","permalink":"http://ymlog.cn/tags/Keepalived/"}]},{"title":"Docker环境下构建HaProxy","slug":"Docker_Build_HaProxy","date":"2020-02-17T04:27:52.000Z","updated":"2020-07-04T17:19:33.319Z","comments":true,"path":"2020/02/17/Docker_Build_HaProxy/","link":"","permalink":"http://ymlog.cn/2020/02/17/Docker_Build_HaProxy/","excerpt":"念两句诗岁暮阴阳催短景，天涯霜雪霁寒宵。五更鼓角声悲壮，三峡星河影动摇。野哭几家闻战伐，夷歌数处起渔樵。卧龙跃马终黄土，人事音书漫寂寥。","text":"念两句诗岁暮阴阳催短景，天涯霜雪霁寒宵。五更鼓角声悲壮，三峡星河影动摇。野哭几家闻战伐，夷歌数处起渔樵。卧龙跃马终黄土，人事音书漫寂寥。 Haproxy简介说明 一款高性能+代理负载均衡软件，目前使用广泛，支持实现TCP/HTTP的负载均衡 免费开源 最大并发量能达到5w 支持多种负载均衡算法，同时支持session 支持虚拟主机 拥有服务监控页面，可以了解 系统实时运行状态 通常不做正向代理，有更好的选择(Squid) 通常不做缓存代理，有更好的选择（Varnish） 不会改变请求和响应报文 不用于Web服务器 不是基于数据报的负载均衡器，看不到IP数据报 haproxy文档：https://cbonte.github.io/haproxy-dconv/ Haproxy配置文件rpm -ql haproxy/etc/haproxy/haproxy.cfg #主配置文件/usr/lib/systemd/system/haproxy.service #守护进程[root@16a3b18f2dda /]# cat /etc/haproxy/haproxy.cfg | grep -Ev '#|^$'global #全局配置项 log 127.0.0.1 local2 #syslog服务器位置及类型 chroot /var/lib/haproxy #chroot路径：工作目录 pidfile /var/run/haproxy.pid #进程文件 maxconn 4000 #最大连接数 user haproxy #用户 group haproxy #组 daemon #以守护进程运行 stats socket /var/lib/haproxy/stats #socket通信状态defaults #默认配置项 mode http #运行模式或协议 log global #定义每个实例启动事件和流量日志 option httplog #http日志 option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s #http-request超时时间 timeout queue 1m #队列超时时间 timeout connect 10s #连接超时时间 timeout client 1m #客户端超时时间 timeout server 1m #服务端超时时间 timeout http-keep-alive 10s #保持长连接超时时间 timeout check 10s #check超时时间 maxconn 3000 #定义最大并发数frontend main *:5000 #前端配置，定义了一系列监听套接字，这些套接字可接受客户端请求并建立连接，监听5000端口，（bind *:80)#ACL规则：(location url)#测试请求的URL是以指定模式开头 acl url_static path_beg -i /static /images /javascript /stylesheets#测试请求&lt;String&gt;是否以指定模式结尾 acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static#如果user_backend没能匹配，指定后端的名称为app default_backend app #定义后端配置：定义一系列“后端”服务器，代理会将请求转发给这些服务器#static组后端backend static balance roundrobin #负载均衡算法为轮询 server static 127.0.0.1:4331 check#app组后端backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check 配置文件结构 全局配置项 默认配置项 前端配置项 后端配置项 监听配置：通过关联前端配置想和后端配置项（frontend &amp; backend）定义一个完整代理。通常只对TCP流量有用。 Docker &amp; Harpoxy三台机器： 角色 IP地址 功能 WEB1 172.18.12.10 httpd – THIS IS WEB1… WEB2 172.18.12.20 httpd – THIS IS WEB2… Proxy 172.18.12.30 CentOS7 / Haproxy #!/bin/bash#安装docker环境yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install docker-ce -ysystemctl start dockersystemctl enable dockersudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123;\"registry-mirrors\": [\"https://ukdws02a.mirror.aliyuncs.com\"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker#创建docker桥接网络，用于给容器分配IP地址docker network create --driver bridge --subnet=172.18.12.0/16 --gateway 172.18.1.1 mynet#创建后端站点，分别为web1和web2docker run -e TZ=\"Asia/Shanghai\" -itd -h web1.com --name web1 --network=mynet --ip 172.18.12.10 httpddocker run -e TZ=\"Asia/Shanghai\" -itd -h web2.com --name web2 --network=mynet --ip 172.18.12.20 httpdecho \"THIS IS WEB1...\" &gt; /root/index.htmldocker cp /root/index.html web1:/usr/local/apache2/htdocs/sleep 1echo \"THIS IS WEB2...\" &gt; /root/index.htmldocker cp /root/index.html web2:/usr/local/apache2/htdocs/#创建代理服务器haproxy，镜像为centos7#参数说明：--privilege + /usr/bin/init 是为了能够让程序以root运行，Container默认的Root只是相当于普通用户#TZ ： 指定时区#-h ： 指定域名#--network： 指定网络类型为我创建的网络docker run -e TZ='Asia/Shanghai' --privileged -itd -h haproxy.com --name myhaproxy --network=mynet --ip 172.18.12.30 centos:7 /usr/sbin/init#查看是否连同#docker exec -it myhaproxy bash -c 'curl 172.18.12.10'#docker exec -it myhaproxy bash -c 'curl 172.18.12.20'#安装haproxy，并配置后端节点docker exec -it myhaproxy bash -c 'yum -y install haproxy -q'docker exec -it myhaproxy bash -c 'systemctl restart haproxy'docker exec -it myhaproxy bash -c \"echo 'server web1 172.18.12.10:80 check' &gt;&gt; /etc/haproxy/haproxy.cfg\"docker exec -it myhaproxy bash -c \"echo 'server web1 172.18.12.20:80 check' &gt;&gt; /etc/haproxy/haproxy.cfg\"docker exec -it myhaproxy bash -c 'systemctl restart haproxy'#测试echo \"等待服务加载....\"sleep 3docker exec -it myhaproxy bash -c \"echo '-------------负载均衡演示---------------' &amp;&amp; for i in &#123;1..10&#125;; do curl 172.18.12.30:5000; done\"#净化检测命令echo \"------------开始删除配置------------\"docker rm myhaproxy --forcedocker rm web1 web2 --forcedocker network rm mynetecho \"------------检查是否有残留------------\"docker network lsecho -e \" \"docker ps -arm /root/index.html* -rf 负载均衡结果演示","categories":[{"name":"容器","slug":"容器","permalink":"http://ymlog.cn/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ymlog.cn/tags/Docker/"}]},{"title":"RIP & EIGRP & ISIS","slug":"RIP & EIGRP & ISIS","date":"2020-02-12T11:44:41.000Z","updated":"2020-07-04T17:18:18.394Z","comments":true,"path":"2020/02/12/RIP & EIGRP & ISIS/","link":"","permalink":"http://ymlog.cn/2020/02/12/RIP%20&%20EIGRP%20&%20ISIS/","excerpt":"念两句诗流光容易把人抛，红了樱桃，绿了芭蕉。","text":"念两句诗流光容易把人抛，红了樱桃，绿了芭蕉。 *简介 路由协议可以分为静态路由协议和动态路由协议，动态路由协议有两类。一类是用于内部网路互联互通的IGP协议，其中代表的有RIP、EIGRP、OSPF、ISIS等，另一类是用于区域与区域之间互通的外部网关协议，目前只有BGP。 本章主要总结内部网关协议中的RIP、EIGRP和ISIS。其中RIP和EIGRP是距离矢量协议，而ISIS和OSPF同属于链路状态协议。 距离矢量协议：传递路由条目，网络能见度只有一跳 ——基于Bellman算法 链路状态协议：传递链路信息，网络能见度是整个拓扑结构——基于SPF(Short Path First)，最短路径算法 RIP RIP使用跳数来描述一条路由的好坏，每经过一台路由器，跳数加一，当跳数为16跳的时候，这条路由就会作废。 RIP消息封装的时候，使用UDP，端口号是520，并且源端口和目的端口都是520 RIP迄今为止有三个版本，分别为：RIP1，RIP2，RIPng，目前IPv4使用的是Version2 IPV6使用的是Version RIPing。 RIP在Cisco设备的管理距离为120 RIPv1 RIPv2 使用广播更新路由表 使用组播更新路由表 有类路由协议 无类路由协议 不支持VLSM 支持VLSM 不支持手工汇总 支持手工汇总 不支持路由表及Tag 支持路由标记 更新消息中的路由条目没有Next-hop信息 有Next-hop信息 有类路由协议更新不携带子网掩码，所以RIP宣告不能加mask，如果宣告1.1.1.0/24，最后宣告的还是1.0.0.0/8。 RIPv2使用的组播地址为 224.0.0.9 。 RIP的消息通知机制： RIP默认30s会从所有参与RIP的接口发出路由表信息，当180s没有收到某条路由的时候，就会判断那 条路由可能失效了，但是依旧会放在路由表里面，只是不会再给别人了，当240s都没有收到这条路由的时候，就会彻底删除。 RIP配置 宣告RIP路由： router rip #启动RIP协议network 1.0.0.0 #将1.0.0.0加入到更新路由表中，将1.0.0.0所在接口也加入更新接口中network 192.168.12.0 #当宣告完之后，R1就可以Ping通R4了#修改RIP时间router riptimers basic 30 180 180 240 #分别是Updates、Invalid、Holddown、Flush RIP机制查看R1的路由表,可以发现去往R2~R4逐跳递增： R 2.0.0.0&#x2F;8 [120&#x2F;1] via 192.168.12.2, 00:00:27, Ethernet0&#x2F;0R 3.0.0.0&#x2F;8 [120&#x2F;2] via 192.168.12.2, 00:00:27, Ethernet0&#x2F;0R 4.0.0.0&#x2F;8 [120&#x2F;3] via 192.168.12.2, 00:00:06, Ethernet0&#x2F;0#并且这里的时间也是正向计时，一到30s就重置。如果是失效的路由条目，则会经历180s和240s 查看RIP协议相关： R1#sh ip protocols--------------------------------------------------------------Routing Protocol is \"rip\" Outgoing update filter list for all interfaces is not set Incoming update filter list for all interfaces is not set # 每隔30s发送一次更新消息，下一次预计在14s之后。 Sending updates every 30 seconds, next due in 14 seconds # 180s判断为down，240删除无效 Invalid after 180 seconds, hold down 180, flushed after 240 Redistributing: rip # 默认版本 Default version control: send version 2, receive version 2 # 配置接口 Interface Send Recv Triggered RIP Key-chain Ethernet0/0 2 2 Loopback0 2 2 Interface Send Recv Triggered RIP Key-chain # 自动网络汇总生效，会将所有子网划分的地址汇总为主类，主类就是子网掩码按照ABC类来 Automatic network summarization is in effect # 最大负载均衡为4 Maximum path: 4 # 已经宣告的路由，这里也可以看出我们宣告的1.1.1.0变成了1.0.0.0，不加子网掩码 Routing for Networks: 1.0.0.0 192.168.12.0 # 路由信息来源 上一次更新时间是累加的，到30s刷新，和上面的预计14s形成呼应 Routing Information Sources: Gateway Distance Last Update #16s之前更新过 192.168.12.2 120 00:00:16 #默认管理距离为120 Distance: (default is 120) 关于RIP的30s、180s、240s，这里shutdown了R4的e0/0接口，在R3上观察现象，之后R3删除后，才会反应到R1上： #R3 -- 180的downR 1.0.0.0/8 [120/2] via 192.168.23.2, 00:00:21, Ethernet0/0R 2.0.0.0/8 [120/1] via 192.168.23.2, 00:00:21, Ethernet0/0R 4.0.0.0/8 [120/1] via 192.168.34.4, 00:01:32, Ethernet0/1R 192.168.12.0/24 [120/1] via 192.168.23.2, 00:00:21, Ethernet0/0#R3 -- 240s后，R1、R2、R3的4.4.4.0都被删除了R 1.0.0.0/8 [120/2] via 192.168.23.2, 00:00:16, Ethernet0/0R 2.0.0.0/8 [120/1] via 192.168.23.2, 00:00:16, Ethernet0/0R 4.0.0.0/8 is possibly down, routing via 192.168.34.4, Ethernet0/1R 192.168.12.0/24 [120/1] via 192.168.23.2, 00:00:16, Ethernet0/0 RIP汇总RIP的自动汇总功能总是打开的，我们可以手动关闭： R1(config-router)#no auto-summaryint lo1ip add 172.16.1.1 255.255.255.0int lo2ip add 172.16.2.1 255.255.255.0int lo3ip add 172.16.3.1 255.255.255.0router ripnet 172.16.1.0net 172.16.2.0net 172.16.3.0#当完成这一切，在R2的路由表上可以看到R 172.16.1.0 [120&#x2F;1] via 192.168.12.1, 00:00:02, Ethernet0&#x2F;0R 172.16.2.0 [120&#x2F;1] via 192.168.12.1, 00:00:02, Ethernet0&#x2F;0R 172.16.3.0 [120&#x2F;1] via 192.168.12.1, 00:00:02, Ethernet0&#x2F;0#现在在R1的出接口对路由进行汇总R1(config)#int e0&#x2F;0R1(config-if)#ip summary-address rip 172.16.0.0 255.255.0.0 #之后再看R2的路由表，就会发现RIP好慢，明细路由还是要经历180-240的过程C： 172.16.0.0&#x2F;16 is variably subnetted, 4 subnets, 2 masksR 172.16.0.0&#x2F;16 [120&#x2F;1] via 192.168.12.1, 00:00:22, Ethernet0&#x2F;0R 172.16.1.0&#x2F;24 [120&#x2F;1] via 192.168.12.1, 00:00:52, Ethernet0&#x2F;0R 172.16.2.0&#x2F;24 [120&#x2F;1] via 192.168.12.1, 00:00:52, Ethernet0&#x2F;0R 172.16.3.0&#x2F;24 [120&#x2F;1] via 192.168.12.1, 00:00:52, Ethernet0&#x2F;0 不得不介绍一下清理路由表的办法了，RIP实在是太慢了： clear ip route * 。 RIP认证R1(config)#key chain Cisco &#x2F;&#x2F;设置钥匙的名字 R1(config-keychain)#key 1 &#x2F;&#x2F;第一把钥匙R1(config-keychain-key)#key-string Cisco1 &#x2F;&#x2F;第一把钥匙的内容R1(config-keychain-key)#key 2R1(config-keychain-key)#key-string Cisco2 R1(config-keychain-key)#int e0&#x2F;0 &#x2F;&#x2F;在接口上配置加密R1(config-if)#ip rip authentication key-chain Cisco &#x2F;&#x2F;用钥匙Cisco给RIP的加密R1(config-if)#ip rip authentication mode md5 &#x2F;&#x2F;加密格式为md5，也可以明文加密 当在R1上配置完认证之后，就会发现R2在R1上学到的条目进入了 180-240 的过程。此时R2已经不能学习到R1的路由条目了，除非在R2上也配置认证。 Key-chain的其他配置 R2(config-keychain-key)#?Key-chain key configuration commands: accept-lifetime Set accept lifetime of key cryptographic-algorithm Set cryptographic authentication algorithm default Set a command to its defaults exit Exit from key-chain key configuration mode key-string Set key string no Negate a command or set its defaults send-lifetime Set send lifetime of key RIP防环 定义最大跳数，一个路由最远可以到15跳的地方，如果是16跳，就会认为不可达 水平分割，如果从接口上收到某条路由的更新，那么就不会将该路由再发回去 毒性逆转，和水平分隔矛盾，只能二选一，如果从接口上收到某路由的更新，那么就立即从收到的接口将该路由发回去，但是跳数是16，这样就不会从这个方向去学习路由了。 毒性路由，如果某个接口down了，就会立即更新该接口的网段，但是跳数是16，这样邻居收到后就立即删除 抑制计时器，180s没有收到路由更新就会判断可能失效，240s没有收到就会直接删除 触发更新，如果路由发生了变化，立即进行更新而不用等待30s 毒性路由实验：shutdownR4的lo0接口，然后在R3上观察现象 #R3R 1.0.0.0&#x2F;8 [120&#x2F;2] via 192.168.23.2, 00:00:01, Ethernet0&#x2F;0R 2.0.0.0&#x2F;8 [120&#x2F;1] via 192.168.23.2, 00:00:01, Ethernet0&#x2F;0R 4.0.0.0&#x2F;8 [120&#x2F;1] via 192.168.34.4, 00:00:18, Ethernet0&#x2F;1R4(config-if)#shutdownR 1.0.0.0&#x2F;8 [120&#x2F;2] via 192.168.23.2, 00:00:02, Ethernet0&#x2F;0R 2.0.0.0&#x2F;8 [120&#x2F;1] via 192.168.23.2, 00:00:02, Ethernet0&#x2F;0#竟然只用了几秒钟中就反应过来了。 RIP命令router rip #启动RIP协议 version 2 network 1.1.1.0 #将1.0.0.0加入到更新路由表中，将1.0.0.0所在接口也加入更新接口中 timers basic 30 180 180 240 #分别是Updates、Invalid、Holddown、Flush no auto-summary #关闭自动汇总 #手动汇总(config-if)# ip summary-address rip 172.16.0.0 255.255.0.0 认证配置：key chain NAME #设置钥匙的名字 key 1 #第一把钥匙key-string STRING #第一把钥匙的内容int e0&#x2F;0 #在接口上配置ip rip authentication key-chain NAME #用钥匙给RIP的加密ip rip authentication mode md5 #加密格式为md5，也可以明文加密 EIGRP增强型内部网关路由选择协议(Enhanced Interior Gateway Routing protocol,EIGRP) EIGRP协议的特点： EIGRP有自治系统，一个EIGRP网络，必须所有的路由器都属于同一个自治系统才可以传递路由。 EIGRP使用DUAL扩散更新算法来保障无环路最优路径计算 是无类路由协议，每个路由条目都包含子网掩码 传输模块RTP（Reliable Transport Protocol），使用组播224.0.0.10 EIGRP的非周期、有边界、和部分；非周期：只在度量和网络拓扑变化时才更新，部分：只发送变化的路由条目，有边界：更新仅发给受影响的路由 更新消息直接存放于IP包头之后，所有没有传输层。在IP包头协议字段中用88表示。 管理距离在Cisco设备上有三种，分别是5,90,170 EIGRP的更新是可靠传输的，任何一个给邻居的路由信息都必须得到邻居的确认。 EIGRP的度量值(Metric)计算会包含：带宽(Bandwidth)、延迟(delay)、可靠性(reliability)、负载(loading)、最大传输单元(MTU) EIGRP的数据报： Hello，用于邻居的发现和恢复，Hello数据报使用组播方式发送，而且使用不可靠的发送方式 ACK，是不包含数据的Hello数据报，ACK总是用单播方、不可靠的发送方式 Update，传递路由更新信息，仅传递给有需要的路由，单台路由单播发送，多台路由组播发送 Query &amp; Reply，查询和答复，是DUAL用来管理它的扩散计算的 EIGRP三张表1、邻居表 ​ EIGRP路由器在启动之后，就会每隔5秒钟，发送一个hello消息，且从任何接口的222.0.0.10组播地址收到hello，就会立即将对方加入到自己的邻居表 ​ 邻居表中的邻居都会有一个死亡事假你，是3倍hello消息间隔，每次收到邻居的hello都会重置死亡计时器，死亡计时器一旦到零，就会直接删除和这个邻居有关的一切路由信息。 查看EIGRP的邻居表 R1#show ip eigrp neighbors EIGRP-IPv4 Neighbors for AS(100) 平均往返时间H Address Interface Hold Uptime SRTT RTO Q Seq (sec) (ms) Cnt Num1 192.168.15.5 Et0/1 11 00:01:03 1280 5000 0 80 192.168.12.2 Et0/0 10 00:02:24 9 100 0 15Hold Uptime：SRTT：平均往返时间RTO：重传计时，基于SRTTQCnt：重传队列SeqNum： 度量值Metric计算 2、拓扑表 R1#sh ip eigrp topology EIGRP-IPv4 Topology Table for AS(100)/ID(1.1.1.1)Codes: P - Passive, A - Active, U - Update, Q - Query, R - Reply, r - reply Status, s - sia Status P 192.168.23.0/24, 1 successors, FD is 307200 via 192.168.12.2 (307200/281600), Ethernet0/0P 192.168.34.0/24, 2 successors, FD is 332800 via 192.168.12.2 (332800/307200), Ethernet0/0 via 192.168.15.5 (332800/307200), Ethernet0/1P 192.168.12.0/24, 1 successors, FD is 281600 via Connected, Ethernet0/0P 5.5.5.0/24, 1 successors, FD is 409600 via 192.168.15.5 (409600/128256), Ethernet0/1P 192.168.45.0/24, 1 successors, FD is 307200 via 192.168.15.5 (307200/281600), Ethernet0/1P 2.2.2.0/24, 1 successors, FD is 409600 via 192.168.12.2 (409600/128256), Ethernet0/0P 3.3.3.0/24, 1 successors, FD is 435200 via 192.168.12.2 (435200/409600), Ethernet0/0P 192.168.15.0/24, 1 successors, FD is 281600 via Connected, Ethernet0/1P 1.1.1.0/24, 1 successors, FD is 128256 via Connected, Loopback0P 4.4.4.0/24, 1 successors, FD is 435200 via 192.168.15.5 (435200/409600), Ethernet0/1#拓扑表中记录了每个目的地的相关信息，比如后继路由器、可行 后继路由器、可行距离、通告距离。#FD：可行距离(Feasible Distance),到达目的地的最小度量值就是可行距离,类似Metric#FC：可行性条件(Feasibility Condition)，邻居比自己的FD小#FS：可行性后继路由器(Feasible Successor)，满足FC后，这个邻居就会变成该网络的可行后继路由器#通告距离：就是去往这个目的地的下一跳到目的地的度量值，相当于邻居表到这个目的地的度量值 当拓扑表中最佳后继路由器失效了，会导致EIGRP向所有的邻居发起查询，并且会将邻居标记为（q） 如果3分钟内，邻居都没有任何形式的回复，那么就会主动断开和这个邻居的关系 3、EIGRP路由表 R1#show ip route eigrp 2.0.0.0/24 is subnetted, 1 subnetsD 2.2.2.0 [90/409600] via 192.168.12.2, 00:10:49, Ethernet0/0 3.0.0.0/24 is subnetted, 1 subnetsD 3.3.3.0 [90/435200] via 192.168.12.2, 00:08:41, Ethernet0/0 4.0.0.0/24 is subnetted, 1 subnetsD 4.4.4.0 [90/435200] via 192.168.15.5, 00:08:41, Ethernet0/1 5.0.0.0/24 is subnetted, 1 subnetsD 5.5.5.0 [90/409600] via 192.168.15.5, 00:09:29, Ethernet0/1D 192.168.23.0/24 [90/307200] via 192.168.12.2, 00:10:29, Ethernet0/0D 192.168.34.0/24 [90/332800] via 192.168.15.5, 00:08:43, Ethernet0/1 [90/332800] via 192.168.12.2, 00:08:43, Ethernet0/0D 192.168.45.0/24 [90/307200] via 192.168.15.5, 00:09:29, Ethernet0/1[AD/FD]#eigrp的管理距离内部路由：90外部路由：170汇总路由：5 metric maximum hops 102 修改最大跳数 路由汇总 – 在路由出口手动汇总 EIGRP的自动汇总默认是关闭着的，无论是手动汇总还是自动汇总都会影响本地路由表，这个条目管理距离为5，并且吓一跳距离为NULL0，NULL0和loopback一样，都是软件模拟出来的接口，不过Loopback在通信过程中会正常响应，而NULL0会将数据直接丢弃不会回复，等于NULL0就是黑洞。 汇总的时候产生的NULL0是为了尽快结束路由查找，因为汇总丢失了明细，所以当出现路由访问的时候，明细路由应该优先形成匹配，如果明细路由没有被匹配上，说明地址不存在，可以直接丢弃。 ip summary-address eigrp 100 172.16.0.0 255.255.0.0no auto-summary EIGRP的配置 R1(config-if)#router eigrp 100 R1(config-router)#network 192.168.12.0 0.0.0.255R1(config-router)#network 1.1.1.0 0.0.0.255EIGRP是无类路由，宣告加上通配符掩码可以保留子网掩码R1(config-router)#do sh run | sec eigrp router eigrp 100 network 1.1.1.0 0.0.0.255 network 192.168.12.0 bandwidth 9000 #设置带宽delay 999 #设置延迟 EIGRP的认证key-chain配置和RIP一样，剩下的是套在接口上，这里我们配置R3-R4的EIGRP认证 R3(config-keychain)#int e0/1R3(config-if)#ip authentication key-chain eigrp 100 CiscoR3(config-if)#ip authentication mode eigrp 100 md5 把R5任意接口down掉，此时发现，R3ping R4的e0/0接口还是能ping通，我一度以为是认证对EIGRP无效，搞了半天，才发现他们是直连，C。接着R1pingR4就ping不通了。 EIGRP的汇总int lo1ip add 172.16.1.1 255.255.255.0int lo2ip add 172.16.2.1 255.255.255.0int lo3ip add 172.16.3.1 255.255.255.0router eigrp 100network 172.16.1.0 0.0.0.255network 172.16.2.0 0.0.0.255network 172.16.3.0 0.0.0.255int e0/0ip summary-address eigrp 100 172.16.0.0 255.255.0.0 #EIGRP默认开启自动汇总R5#show ip route eigrp 汇总前： 172.16.0.0/24 is subnetted, 3 subnets D 172.16.1.0 [90/409600] via 192.168.15.1, 00:01:13, Ethernet0/0 D 172.16.2.0 [90/409600] via 192.168.15.1, 00:01:13, Ethernet0/0 D 172.16.3.0 [90/409600] via 192.168.15.1, 00:01:13, Ethernet0/0汇总后： R2#show ip route eigrp 172.16.0.0/16 is variably subnetted, 4 subnets, 2 masksD 172.16.0.0/16 [90/409600] via 192.168.12.1, 00:00:35, Ethernet0/0D 172.16.1.0/24 [90/486400] via 192.168.23.3, 00:00:35, Ethernet0/1D 172.16.2.0/24 [90/486400] via 192.168.23.3, 00:00:35, Ethernet0/1D 172.16.3.0/24 [90/486400] via 192.168.23.3, 00:00:35, Ethernet0/1 会发现，即使是汇总，和R1相邻的路由器上也可以收到明细路由，但是R3等不和R1相邻的路由器上，就只能收到汇总后的路由。 D 172.16.0.0/16 [90/435200] via 192.168.23.2, 00:00:02, Ethernet0/0 EIGRP–FD值修改EIGRP的AD值和FD值，可以通过掉接口的带宽和延迟做到。 现在可以看到R1去往34网段负载均衡，我们现在想让R1只从R2走，所以这里调高R1的e0/1接口的带宽和延迟，接口的带宽和延迟可以用show interfaces e0/1查看。 #R1路由表D 192.168.34.0/24 [90/332800] via 192.168.15.5, 00:00:17, Ethernet0/1 [90/332800] via 192.168.12.2, 00:00:17, Ethernet0/0#R1拓扑表P 192.168.34.0/24, 2 successors, FD is 332800 via 192.168.12.2 (332800/307200), Ethernet0/0 via 192.168.15.5 (332800/307200), Ethernet0/1 调整带宽，如果是在接口下修改，可能会影响多条路径，建议使用偏移列表offset-set。 offset只能增加从某个接口进入或者出去的路由 R1(config-if)#bandwidth 5000再看拓扑表：#R1P 192.168.34.0/24, 1 successors, FD is 332800 via 192.168.12.2 (332800/307200), Ethernet0/0 via 192.168.15.5 (588800/307200), Ethernet0/1#R1的路由表中，也只会选择从R2走了调整时延类似：R1(config-if)#delay 10000 时延和带宽可以影响FD，影响EIGRP度量值的五个要素：带宽(Bandwidth)、延迟(delay)、可靠性(reliability)、负载(loading)、最大传输单元(MTU)。 FD=metric = 256 * &#123; 10^7/bw + delaysum / 10 &#125; ISISISIS采用了 面向无连接的CLNS协议，但需要保留IP地址做ISIS的Router-ID。其中CLNP地址的写法为： 49.0001.0000.0000.0001.00 49：是标志地址的作用，这里是私有地址的意思 0001：区域号 0000.0000.0001：设备ID 00：端口号 —NSEL 简介 ISIS最早不是给TCP/IP设计的，是给CLNS无连接网络设计的，但是CLNS被淘汰了。ISIS的开发者给ISIS协议加上了TCP/IP的支持模块，将其变为集成的ISIS，但是依旧不如OSPF流行，所以渐渐被人遗忘。 近年来云计算数据中心崛起，数据中心网络日益复杂，而OSPF的区域划分很不自由，并且OSPF是基于IP来进行信息传递的，而数据中心并不是完全的TCP/IP的网络环境，所以OSPF使用受到很大的限制。FC网络不允许浪费传输效率 ISIS在Cisco设备中的管理距离为115 ISIS配置 router isis #启动协议net 49.0001.0000.0000.0001.00 #宣告CLNP地址int e0/0,lo0 #在接口下配置ISISip router isis ISIS邻居R3#show isis neighbors System Id Type Interface IP Address State Holdtime Circuit IdR1 L1 Et0/0 192.168.123.1 UP 22 R3.01 R1 L2 Et0/0 192.168.123.1 UP 27 R3.01 R2 L1 Et0/0 192.168.123.2 UP 22 R3.01 R2 L2 Et0/0 192.168.123.2 UP 26 R3.01 R4 L2 Et0/1 192.168.34.4 UP 9 R4.01 ISIS的Hello包正常情况下，10s一次，30s没收到就判定死亡。ISIS有指定路由器的概念，但是ISIS的世界中，路由器不叫路由器，而叫中间系统，所以DR就变成了DIS DIS的Hello包是3.3s一次，10s没收到就判定DIS死亡，剩下的路由器会重新选举一台路由器作为DIS。 DIS没有备份的概念，谁都可以随时抢占。DIS会优先判定优先级，优先级为0的设备，依旧可以做DIS。 DIS在优先级一样的情况下，会通过比较MAC地址数值大小，越打越优。 ISIS角色 Level-1 Router： 区域内部路由器，用来在区域内部学习和交换LSP（相当于OSPF的LSA） L1路由器只能和L1或者L12路由器建立邻居 L1路由器可以知道整个区域的拓扑，但是其他区域连路由都学不到，通过默认路由离开这个区域 Level-2 Router 区域间路由器，用来在区域间传递LSP信息 L2路由器只能和L2或者L12路由器建立邻居 L2路由器知道整个AS的区域情况，可以学习到每个区域的路由条目 Level-1-2 Router 用来将L1和L2路由器相连，一般是区域边界路由器（相当于OSPF的ABR） L12路由器可以和L1和L2建立邻居 L12路由器拥有L1和L2所有的能力 默认情况下，路由器启动ISIS后，就是L12路由器 L12路由器会给L1路由器下发一个默认路由 L1邻居关系 同一个区域才可以建立L1邻居关系 L2邻居关系 不管是不是一个区域，都可以建立L2邻居关系 由于ISIS路由器默认是L12路由器，相当于同时开启L1和L2，所以会建立两个邻居关系。 #修改ISIS当前路由器的角色is-type level-1#或者在接口上修改邻居类型isis circuit-type level-1 在ISIS数据库中，1200s倒计时，每900s一次泛洪。 R1#sh isis database level-1IS-IS Level-1 Link State Database:LSPID LSP Seq Num LSP Checksum LSP Holdtime ATT/P/OLR1.00-00 * 0x00000008 0x1564 785 1/0/0R2.00-00 0x00000009 0xC590 1062 1/0/0R3.00-00 0x00000008 0x50F3 1105 1/0/0R3.01-00 0x00000003 0x734B 740 0/0/0R4.00-00 0x00000006 0x83FE 75 1/0/0R4.01-00 0x00000002 0xBA8F 123 0/0/0R4.02-00 0x00000002 0x9AAF 64 0/0/0 ATT：如果这个被写为1，说明必须产生一条默认路由指向这个路由器 P：如果L2或者L12路由器链断开，可以使用带P置为的LSP数据进行打通 OL：overload，以前的路由器性能不佳，会超载。但是现在OL被利用来作为故障修复，设备升级的时候的故障路标。 我们会发现R3收到了两个LSP，那个R3.00-00是本体，R3.01-00是PSN（伪节点）发来的。 show isis database detail ISIS汇总路由器汇总只能做在区域边界的L1/L2或者L2路由器上，并且只能汇总自己这个区域的。 R5：添加环回口lo1~lo3，并且添加到isis进行路由汇总 Loopback1 172.16.1.1 YES manual up upLoopback2 172.16.2.1 YES manual up upLoopback3 172.16.3.1 YES manual up upR5(config-router)#int range lo1 -3R5(config-if-range)#ip router isisR5(config-if-range)#router isisR5(config-router)# summary-address 172.16.0.0 255.255.0.0 ISIS其他ISIS度量值本来是衡量4个数值，但是目前来说，一个也不支持，所以当前的集成ISIS度量值可以理解为跳数，没经过一个入口，路由metric + 10； ISIS默认路由注入，default-information originate，这个命令只有在L1/L2或者L2路由器上有效。ISIS的L1/2路由器默认会给L1路由器下发默认路由，通过数据库ATT位置来通知的。可以在L2或者L1/2路由器上配置默认路由器来影响其他L1/2或者L2路由器。默认路由需要在ISIS下宣告。 ISIS命令 R1pingR5 在R5上创建lo1-3：172.16.x.1/24，并且通告金isis，level-2，要求R4学到的是汇总的条目 在R5上下发默认路由，让所有的路由器都可以学习到，并且可以ping同R5没有被宣告的100.1.1.1/24 lo100的地址。 #R1router isis net 49.0001.0000.0000.0001.00interface Loopback0 ip address 1.1.1.1 255.255.255.0 ip router isis interface Ethernet0/0 ip address 192.168.123.1 255.255.255.0 no shutdown ip router isis #R2 router isis net 49.0001.0000.0000.0002.00interface Loopback0 ip address 2.2.2.2 255.255.255.0 ip router isis interface Ethernet0/0 ip address 192.168.123.2 255.255.255.0 no shutdown ip router isis interface Ethernet0/1 ip address 192.168.24.2 255.255.255.0 no shutdown ip router isis #R3router isis net 49.0001.0000.0000.0003.00interface Loopback0 ip address 3.3.3.3 255.255.255.0 ip router isis interface Ethernet0/0 ip address 192.168.123.3 255.255.255.0 no shutdown ip router isis interface Ethernet0/1 ip address 192.168.34.3 255.255.255.0 no shutdown ip router isis #R4router isis net 49.00020000.0000.0004.00 interface Loopback0 ip address 4.4.4.4 255.255.255.0 ip router isis interface Ethernet0/0 ip address 192.168.34.4 255.255.255.0 no shutdown ip router isis interface Ethernet0/1 ip address 192.168.24.4 255.255.255.0 no shutdown ip router isis interface Ethernet0/2 ip address 192.168.45.4 255.255.255.0 no shutdown ip router isis #R5router isis net 49.0003.0000.0000.0005.00interface Loopback0 ip address 5.5.5.5 255.255.255.0 no shutdown ip router isis interface Ethernet0/0 ip address 192.168.45.5 255.255.255.0 no shutdown ip router isis #配置完这些R1就可以Ping通R5了----------------------#R5 --- 汇总int lo10ip add 172.16.1.1 255.255.255.0ip router isisint lo20ip add 172.16.2.1 255.255.255.0ip router isisint lo30ip add 172.16.3.1 255.255.255.0ip router isisrouter isis summary-address 172.16.0.0 255.255.0.0#配置完这些，R4上就可以看到：i L2 172.16.0.0/16 [115/20] via 192.168.45.5, 00:00:04, Ethernet0/2----------------------#R5 --- 默认路由interface Loopback2 ip address 100.1.1.5 255.255.255.255router isisdefault-information originateshow isis database level-1 #查看链路状态数据库show isis neighbors #查看ISIS邻居","categories":[{"name":"路由技术","slug":"路由技术","permalink":"http://ymlog.cn/categories/%E8%B7%AF%E7%94%B1%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"小型路由协议","slug":"小型路由协议","permalink":"http://ymlog.cn/tags/%E5%B0%8F%E5%9E%8B%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"}]},{"title":"Linux权限","slug":"Linux_privilege","date":"2020-01-17T04:42:03.000Z","updated":"2020-07-04T17:19:14.693Z","comments":true,"path":"2020/01/17/Linux_privilege/","link":"","permalink":"http://ymlog.cn/2020/01/17/Linux_privilege/","excerpt":"念两句诗滚滚长江东逝水，浪花淘尽英雄。是非成败转头空。青山依旧在，几度夕阳红。白发渔樵江渚上，惯看秋月春风。一壶浊酒喜相逢。古今多少事，都付笑谈中。","text":"念两句诗滚滚长江东逝水，浪花淘尽英雄。是非成败转头空。青山依旧在，几度夕阳红。白发渔樵江渚上，惯看秋月春风。一壶浊酒喜相逢。古今多少事，都付笑谈中。 常用命令类型 举例 用户 who, whoami, su, useradd, userdel, passwd, usermod, /etc/passwd 组 groupadd, groupdel, groupmod, /etc/group 文件 chmod, chown, chgrp 其他 sudo、exit 用户和组用户和组的概念在Linux中，用户分为管理员用户和普通用户，普通用户又分为系统用户和登录用户，每一个用户都有用户名和独一无二的用户id。管理员的用户id为0，普通用户中，系统用户的用户id为1~499，登录用户的用户id为500+。组也分为管理员组和普通用户组，不过又可以分为基本组（主组）和附加组（额外组）。基本组的组名与用户名相同，附加组是为了方便管理用户，一个用户可以有多个附加组。 Linux安全上下文： 运行中的程序我们称之为进程（process），进程能够访问其所有资源的权限，取决于进程发起者身份。 相关配置文件Linux中与用户和组相关的配置文件 目录 含义 /etc/passwd 用户及其属性信息（名称、UID、基本组ID等） /etc/group 组及其属性信息 /etc/shadow 用户密码及其相关属性 /etc/gshadow 组密码及其相关属性 为了方便管理属于同一组的用户，Linux 系统中还引入了用户组的概念。通过使用用户组号码（GID，Group IDentification），我们可以把多个用户加入到同一个组中，从而方便为组中的用户统一规划权限或指定任务。另外，在 Linux 系统中创建每个用户时，将自动创建一个与其同名的基本用户组，而且这个基本用户组只有该用户一个人。如果该用户以后被归纳入其他用户组，则这个其他用户组称之为扩展用户组。一个用户只有一个基本用户组，但是可以有多个扩展用户组，从而满足日常的工作需要。 1、/etc/passwd&#x2F;etc&#x2F;passwd存放用户信息，由6个冒号组成7个信息1.用户名2.密码（x表示加密密码）3.UID（用户标识）4.GID（组标识）5.用户全名或本地账号6.家目录7.登录之后使用的终端命令For example:nginx:x:997:993:Nginx web server:&#x2F;var&#x2F;lib&#x2F;nginx:&#x2F;sbin&#x2F;nologin 1 2 3 4 5 6 7 2、/etc/group用户组的所有信息都存放在&#x2F;etc&#x2F;group文件中。此文件的格式是由冒号(:)隔开若干个字段，具体如下：【组名】:【口令】:【组标识号】:【组内用户列表】组名：是用户组的名称，由字母或数字构成，不应重复。口令：存放的是用户组加密后的口令字。一般Linux系统的用户组都没有口令，即这个字段一般为空或者*。组标识号：与用户标识号类似，也是一个整数，被系统内部用来标识组。别称GID.组内用户列表：是属于这个组的所有用户的列表，不同用户之间用逗号(,)分隔。如：root:x:0: 3、/etc/shadowroot:$6$iDHbyICea.JiS60r.c0::0:99999:7:::参数一： 用户名称参数二： 用户加密后的密码参数三： 用户密码最近一次修改时间，算法是今天的时间减去jan，1，1970得到的时间间隔参数四： 用户最少多少天后才能改密码的天数（默认为0，表示可以在任何时间修改）参数五： 用户最多多少天后一定要修改密码的天数，系统会强制用户修改密码（默认为99999，改为1 也能让密码改不了）参数六： 过期前多少天时间会被警告（改为-1 则永远不会提示）参数七： 过期后多少天内账号变为inactive状态，可登陆，但不能操作参数八： 多少天后账号会过期，无法登陆参数九： 保留参数 4、/etc/gshadow&#x2F;etc&#x2F;gshadow 格式如下，每个用户组独占一行；groupname:password:admin,admin,…:member,member,…第一字段：用户组第二字段：用户组密码，这个段可以是空的或!，如果是空的或有!，表示没有密码；第三字段：用户组管理者，这个字段也可为空，如果有多个用户组管理者，用,号分割；第四字段：组成员，如果有多个成员，用,号分割；For example: house1:!:: 查看当前用户一般使用who命令可以查看当前用户： # 显示当前所有已登录的用户信息（包括 闲置时间, 用户状态, 各列标题）[root@experience ~]# who -uTHNAME LINE TIME IDLE PID COMMENTroot + pts/0 2020-01-17 08:49 . 6883 (192.168.19.1)root + pts/1 2020-01-17 10:36 . 7377 (192.168.19.1) 用户操作命令用户1、useradd 增可以使用 useradd 命令创建用户账户。使用该命令创建用户账户时，默认的用户家目录会被存放在/home 目录中，默认的 Shell 解释器为/bin/bash，而且默认会创建一个与该用户同名的基本用户组 参数 作用 -d 指定用户的家目录（默认为/home/username） -e 账户的到期时间，格式为 YYYY-MM-DD -u 指定该用户的默认 UID -g 指定一个初始的用户基本组（必须已存在） -G 指定一个或多个扩展用户组 -N 不创建与用户同名的基本用户组 -s 指定该用户的默认 Shell 解释器 一旦用户的解释器被设置为-s nologin，则代表该用户不能登录到系统中,有哪些解释器可以再/etc/passwd中查看，详情请参见Linux的目录结构。 查看当前用户的属组和属主 [root@DZQ etc]# id rootuid&#x3D;0(root) gid&#x3D;0(root) groups&#x3D;0(root) For example:useradd -d /home/userx -g nginx user02#创建一个名为user02的用户，但是家文件的文件名为userx，且属主是user02，属组是nginx[root@nginxs ~]# ll -d /home/userxdrwx------ 2 user02 nginx 62 Dec 20 00:11 /home/userx 2、userdel 删删除用户时, 如果用户所属组是创建用户时自动创建的和用户名称同名的组, 并且该组内没有其他用户, 则该组也会被删掉。 参数: -f 强制删除用户, 即使用户当前已登录 -r 删除用户, 同时删除用户主目录。如果不加r，则在/home目录下，还会有用户目录 3、usermod 改用户的信息保存在/etc/passwd 文件中，可以直接用文本编辑器来修改其中的用户参数项目，也可以用 usermod 命令修改已经创建的用户信息 参数 作用 -c 填写用户账户的备注信息 -d -m 参数-m 与参数-d 连用，可重新指定用户的家目录并自动把旧的数据转移过去 -e 账户的到期时间，格式为 YYYY-MM-DD -g 变更所属用户组 -G 变更扩展用户组 -L 锁定用户禁止其登录系统 -U 解锁用户，允许其登录系统 -s 变更默认终端 -u 修改用户的 UID 4、passwd当创建完用户，需要给用户添加密码，比如： useradd dzq passwd dzq---输入你想要的密码------之后以用户dzq的身份登录---su - dzqpasswd---输入你刚刚用root身份创建的密码，就可以修改密码了------之后再次登录到系统中，就可以使用：------ssh dzq@192.168.255.10------密码：passwd--- 组1、groupadd语法： groupadd [-g gid [-o]] [-r] [-f] group 参数说明： -g：指定新建工作组的 id； -r：创建系统工作组，系统工作组的组ID小于 500； -K：覆盖配置文件 “/ect/login.defs”； -o：允许添加组 ID 号不唯一的工作组。 -f,–force: 如果指定的组已经存在，此选项将失明了仅以成功状态退出。当与 -g 一起使用，并且指定的GID_MIN已经存在时，选择另一个唯一的GID（即-g关闭）。 实例： 创建一个新的组，并添加组 ID。 ＃groupadd －g 344 runoob 2、groupmod语法 groupmod [-g &lt;群组识别码&gt; &lt;-o&gt;][-n &lt;新群组名称&gt;][群组名称] 参数： -g &lt;群组识别码&gt; 设置欲使用的群组识别码。 -o 重复使用群组识别码。 -n &lt;新群组名称&gt; 设置欲使用的群组名称。 实例 修改组名 [root@runoob.com ~]# groupadd linuxso [root@runoob.com ~]# tail -1 /etc/group linuxso:x:500: [root@runoob.com ~]# tail -1 /etc/group linuxso:x:500: [root@runoob.com ~]# groupmod -n linux linuxso [root@runoob.com ~]# tail -1 /etc/group linux:x:500: 3、groupdel语法： groupdel [群组名称] 实例： 删除一个群组 # groupdel hnuser 4、gpasswd 参数 作用 -a –add USER 添加用户到组 -d –delete USER 移除组中用户 -Q –root CHROOT_DIR 更改组的chroot目录 -r –delete-password 删除组密码 -M –members USER,… 批量添加用户到组 -A –administrators ADMIN,…设置组管理员 执行管理员权限这里把执行管理员权限分为三种方式，分别是：直接切换管理员账户、临时使用管理员权限、将管理员权限写入到配置文件。 1、su - 切换用户使用su命令可以切换用户，在没有参数的情况下调用时，su默认以root的身份运行一个交互式的shell。对于向后兼容性，su默认不改变当前目录，只设置环境变量HOME和SHELL(如果目标不是root，则加上USER和LOGNAME)。 这个版本的su使用PAM作为认证、账户和会话管理。在其他su实验中发现一些配置选项（例如：对轮组的支持）必须通过PAM进行配置 su 后面加上 “-” 表示完全切换到新用户，即把环境变量信息也变更为新用户相应信息。如果没有指明用户名，则切换到root，如：su 2、sudo - 临时权限sudo 命令用于给普通用户提供额外的权限来完成原本 root 管理员才能完成的任务，格式为“sudo [参数] 命令名称” 参数 作用 -h 列出帮助信息 -l 列出当前用户可执行的命令 -u 用户名或 UID 值 以指定的用户身份执行命令 -k 清空密码的有效时间，下次执行 sudo 时需要再次进行密码验证 -b 在后台执行指定的命令 -p 更改询问密码的提 3、修改配置文件配置文件 /etc/sudoers ,只有root管理员才可以使用visudo命令编辑sudo服务配置文件。visudo禁止多个用户同时修改配置sudoers文件。进入普通用户时，还是需要sudo才可以执行相关权限。 第一步：vim /etc/sudoers，将第99行左右的位置，添加想要赋予权限的用户 [root@localhost ~]# sed '99,102p' -n /etc/sudoers## Allow root to run any commands anywhere root ALL=(ALL) ALLNIKI ALL=(ALL) ALL## Allows members of the 'sys' group to run networking, software, 第二步：登录普通用户 [root@localhost ~]# su - NIKILast login: Mon Aug 12 01:26:04 EDT 2019 on pts/0 第三部：sudo -l，这里填的密码是NIKI用户自己的密码 [NIKI@localhost ~]$ sudo -l[sudo] password for NIKI: Sorry, try again.[sudo] password for NIKI: ----------------------User NIKI may run the following commands on localhost: (ALL) ALL 第四步：显示 不用sudo [NIKI@localhost ~]$ ls /root/ls: cannot open directory /root/: Permission denied 用sudo [NIKI@localhost ~]$ sudo ls /root1.txt de dem demo mou nin.sh rubbish script.sh test.py w.sh w.sh~ 但是考虑到生产环境中不允许某个普通用户拥有整个系统中所有命令的最高执行权（这也不符合前文提到的权限赋予原则，即尽可能少地赋予权限），因此 ALL 参数(第99行）就有些不合适了。因此只能赋予普通用户具体的命令以满足工作需求，这也受到了必要的权限约束。如果需要让某个用户只能使用 root 管理员的身份执行指定的命令，切记一定要给出该命令的绝对路径，否则系统会识别不出来。我们可以先使用 whereis 命令找出命令所对应的保存路径，然后把配置文件第 99 行的用户权限参数修改成对应的路径即可 [linuxprobe@linuxprobe ~]$ exitlogout[root@linuxprobe ~]# whereis catcat: /usr/bin/cat /usr/share/man/man1/cat.1.gz /usr/share/man/man1p/cat.1p.gz[root@linuxprobe ~]# visudo96 ##97 ## Allow root to run any commands anywhere98 root ALL=(ALL) ALL99 linuxprobe ALL=(ALL) /usr/bin/cat 此时，用户只能用sudo执行cat命令。 这样虽然赋予了普通用户执行管理员命令的权限，但每次执行之前都要输入密码，可以通过以下配置，使得用户执行sudo时，不用密码验证。 [root@linuxprobe ~]# visudo………………省略部分文件内容………………96 ##97 ## Allow root to run any commands anywhere98 root ALL=(ALL) ALL99 linuxprobe ALL=NOPASSWD: /usr/sbin/poweroff 文件linux一切皆文件，但文件类型和权限有所不同，用字符来区分。 概述文件类型-：普通文件d：目录文件l：链接文件b：块设备文件c：字符设备文件p：管道文件 文件权限 r w x 读 写 执行 4 2 1 对于文件而言 r w x 可以读文件的内容 可以编辑文件的内容 可以执行这个文件 对于目录而言 r w x 读目录中的文件属性信息 可以在目录中添加或删除文件数据信息 是否可以进入到目录 权限详解[root@nginxs qiandao]# ll total 8 -rw-r--r-- 1 root root 1424 Aug 15 06:05 Dockerfile -rw-r--r-- 1 root root 1413 Aug 15 06:05 README.md drwxr-xr-x 4 root root 28 Aug 15 06:05 root #权限数字对应权限组说明： 总共分为4部分 【文件或文件夹】【owner权限】【group权限】【others权限】 【文件是-，文件夹是d】【r/w/x相加】【r/w/x相加】【r/w/x相加】Linux档案的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限 特殊权限可读可写可执行不能够满足我们对安全和灵活性的需求，因此便有了 SUID、SGID 与 SBIT 的特殊权限位 SUIDSUID 是一种对二进制程序进行设置的特殊权限，可以让二进制程序的执行者临时拥有属主的权限（仅对拥有执行权限的二进制程序有效）。 例如，所有用户都可以执行 passwd 命令来修改自己的用户密码，而用户密码保存在/etc/shadow 文件中。仔细查看这个文件就会发现它的默认权限是 000，也就是说除了 root 管理员以外，所有用户都没有查看或编辑该文件的权限。但是，在使用 passwd 命令时如果加上 SUID 特殊权限位，就可让普通用户临时获得程序所有者的身份，把变更的密码信息写入到 shadow 文件中。这很像我们在古装剧中见到的手持尚方宝剑的钦差大臣，他手持的尚方宝剑代表的是皇上的权威，因此可以惩戒贪官，但这并不意味着他永久成为了皇上。因此这只是一种有条件的、临时的特殊权限授权方法。 查看 passwd 命令属性时发现所有者的权限由 rwx 变成了 rws，其中 x 改变成 s 就意味着该文件被赋予了 SUID 权限。另外有读者会好奇，那么如果原本的权限是 rw-呢？如果原先权限位上没有 x 执行权限，那么被赋予特殊权限后将变成大写的 S。 [root@nginx ~]# ll /usr/bin/passwd -rwsr-xr-x. 1 root root 27856 Aug 8 21:39 /usr/bin/passwd chmod 4700 test.txt #添加suid权限-rws------ 1 root root 0 Dec 20 01:48 test.txtchmod 700 test.txt #取消suid权限-rwx------ 1 root root 0 Dec 20 01:48 test.txt对于当前位没有x执行权限，那么则显示大写的Schmod 4600 test.txt -rwS------ 1 root root 0 Dec 20 01:48 test.txt SGIDSGID 主要实现如下两种功能： 1、让执行者临时拥有属组的权限（对拥有执行权限的二进制程序进行设置）； 2、在某个目录中创建的文件自动继承该目录的用户组（只可以对目录进行设置）。 [root@DZQ dev]# ll mem crw-r----- 1 root kmem 1, 1 Aug 6 08:50 mem 1、在某个目录中创建的文件自动继承该目录的用户组2、由于 ps 命令被增加了 SGID 特殊权限位，所以当用户执行该命令时，也就临时获取到了 system 用户组的权限，从而可以顺利地读取设备文件了 SBITSticky Bit ,SBIT 特殊权限位可确保用户只能删除自己的文件，而不能删除其他用户的文件。换句话说，当对某个目录设置了 SBIT 粘滞位权限后，那么该目录中的文件就只能被其所有者执行删除操作了与前面所讲的 SUID 和 SGID 权限显示方法不同，当目录被设置 SBIT 特殊权限位后，文件的其他人权限部分的 x 执行权限就会被替换成 t 或者 T，原本有 x 执行权限则会写成 t，原本没有 x 执行权限则会被写成 T。 [linuxprobe@linuxprobe tmp]$ ls -ald /tmpdrwxrwxrwt. 17 root root 4096 Feb 11 13:03 /tmp 要是也想对其他目录来设置 SBIT 特殊权限位，用 chmod 命令就可以了。对应的参数 o+t 代表设置 SBIT 粘滞位权限 [root@linuxprobe ~]# chmod -R o+t linux/[root@linuxprobe ~]# ls -ld linux/drwxr-xr-t. 2 root root 6 Feb 11 19:34 linux/ 隐藏权限chattrchattr 命令用于设置文件的隐藏权限，格式为“chattr [参数] 文件”。如果想要把某个隐藏功能添加到文件上，则需要在命令后面追加“+参数”，如果想要把某个隐藏功能移出文件，则需要追加“-参数”。 参数 作用 i 无法对文件进行修改；若对目录设置了该参数，则仅能修改其中的而不能新建或删除文件 a 仅允许补充（追加）内容，无法覆盖/删除内容（Append Only） S 文件内容在变更后立即同步到硬盘（sync） s 彻底从硬盘中删除，不可恢复（用 0 填充原文件所在硬盘区域） A 不再修改这个文件或目录的最后访问时间（atime） b 不再修改文件或目录的存取时间 D 检查压缩文件中的错误 d 使用 dump 命令备份时忽略本文件/目录 c 默认将文件或目录进行压缩 u 当删除该文件后依然保留其在硬盘中的数据，方便日后恢复 t 让文件系统支持尾部合并（tail-merging） X 可以直接访问压缩文件中的内容 lsattr用chattr执行改变文件或目录的属性，可执行lsattr指令查询其属性。 参数 作用 -a 显示所有文件和目录，包括以”.”为名称开头字符的额外内建，现行目录”.”与上层目录”..” -d 显示，目录名称，而非其内容。 -R 递归处理，将指定目录下的所有文件及子目录一并处理 for example使用隐藏权限，防止某个文件被串改。[root@nginx myhouse]# chattr +i hello.md [root@nginx myhouse]# lsattr ----i----------- ./hello.md 文件操作命令chmodchmod 可以藉以控制文件如何被他人所调用。 for example: chmod 700 test.md chmod wxr-rx-rx test.md 参数 作用 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -v 显示详细的处理信息 -R 处理指定目录以及其子目录下的所有文件 chownchown 将指定文件的拥有者改为指定的用户或组 参数 作用 user 新的文件拥有者的使用者 ID group 新的文件拥有者的使用者组(group) -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -v 显示详细的处理信息 -R 处理指定目录以及其子目录下的所有文件 For example:更改一个目录文件以及其下子文件或者子目录的属主和属组。mkdir myhousecd myhouse/touch hello.md# ll#-rw-r--r-- 1 root root 0 Dec 20 08:36 hello.mdcd ..# ll # drwxr-xr-x 2 root root 22 Dec 20 08:36 myhousechown -Rc dzq:nginx myhouse/#changed ownership of ‘myhouse/hello.md’ from root:root to dzq:nginx#changed ownership of ‘myhouse/’ from root:root to dzq:nginxll#total 0#drwxr-xr-x 2 dzq nginx 22 Dec 20 08:36 myhousecd myhouse/ll#total 0#-rw-r--r-- 1 dzq nginx 0 Dec 20 08:38 hello.md----由此可见，myhouse所属的用户和组都已经被更改，且其子目录里的hello.md也被更改了。 chgrp变更文件或目录的所属群组。 chgrp -v bin myhouse/#将myhouse属组更改为bin与chown的区别,chown是将文件或者目录的属主更改，而chgrp是更改属组chown root myhouse/当chown以chown root:nginx world2.md的形式更改时，即更改了属主又更改了属组 [root@node ~]# ll-rwxrwxrwx 1 root root 9 Jan 17 12:26 demo#改变属主[root@node ~]# chown NIKI demo[root@node ~]# ll-rwxrwxrwx 1 NIKI root 9 Jan 17 12:26 demo#改变属组[root@node ~]# chgrp NIKI demo[root@node ~]# ll-rwxrwxrwx 1 NIKI NIKI 9 Jan 17 12:26 demo 文件访问控制列表对指定的用户进行单独的权限控制，就需要用到文件访问控制列表（ACL，Access Control List） setfaclSet File Acess Control List chmod命令可以把文件权限分为u,g,o三个组，而setfacl可以对每一个文件或目录设置更精确的文件权限。换句话说，setfacl可以更精确的控制权限的分配。比如：让某一个用户对某一个文件具有某种权限。 参数 作用 -m 更改当前文件的ACL -M, –modify-file=file 从文件中读取访问列表条目ACL进行修改 -x 根据访问控制列表移除条目 -b 删除所有扩展访问控制列表条目 -k 移除默认访问控制列表 -n –no-mask 不重新计算有效权限掩码 -d –default 应用到默认访问控制列表的操作 -R 递归操作子目录 -L 依照系统逻辑，跟随符号链接 -P 依照自然逻辑，不跟随符号链接 [root@localhost ~]# setfacl -Rm u:root:rwx /root/dem getfacl显示文件上的ACL信息 常见用法 [root@nginx ~]# getfacl hello2.md # file: hello2.md# owner: root# group: rootuser::rw-group::r--other::r--[root@nginx ~]# setfacl -m u:dzq:rwx hello2.md [root@nginx ~]# getfacl hello2.md # file: hello2.md# owner: root# group: rootuser::rw-user:dzq:rwxgroup::r--mask::rwxother::r--","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[]},{"title":"Linux网络存储","slug":"Linux_network_storage","date":"2020-01-16T11:36:23.000Z","updated":"2020-07-04T17:19:18.024Z","comments":true,"path":"2020/01/16/Linux_network_storage/","link":"","permalink":"http://ymlog.cn/2020/01/16/Linux_network_storage/","excerpt":"念两句诗天南地北双飞客，老翅几回寒暑。君应有语：渺万里层云，千山暮雪，只影向谁去？千秋万古，为留待骚人，狂歌痛饮，来访雁丘处。","text":"念两句诗天南地北双飞客，老翅几回寒暑。君应有语：渺万里层云，千山暮雪，只影向谁去？千秋万古，为留待骚人，狂歌痛饮，来访雁丘处。 1、FTP服务FTP（File Transfer Protocol）文件传输协议，主要功能是在服务器与客户端之间进行文件的传输。FTP协议使用明码传输，为了使用更安全的FTP协议，可以采用vsftpd（Very Secure Ftp Daemon）。 协议摘要两种工作模式 主动模式：FTP服务器主动向客户端发起请求 被动模式：FTP服务器等待客户端发起连接请求（FTP默认工作模式） 三种用户等级 匿名用户。是一种最不安全的认证模式，任何人都可以无需密码验证而直接登录到FTP服务器。匿名用户默认访问目录是：var/ftp 本地用户：使用Linux本地的账户密码进行认证，默认访问目录是/home/person 虚拟用户：是这三种模式中最安全的一种认证模式，它需要为FTP服务单独建立用户数据库文件，虚拟出用来进行口令验证的账户信息，而这些账户信息在服务器系统中实际上是不存在的，仅供FTP服务程序进行认证使用。这样，即使黑客破解了账户信息也无法登录服务器，从而有效降低了破坏范围和影响。 限制用户活动目录（change root，简称chroot）：将使用者的工作范围限定在用户的家目录。 两个指定端口​ 21端口用来建立连接，20端口用于传输数据。 配置文件​ FTP使用系统的syslogd来进行数据记录，记录了包括用户曾经下达过的命令与用户传输数据（传输时间，文件大小等）记录，记录文件在/var/log下。 主配置文件​ VSftpd服务程序的主配置文件在/etc/vsftpd/vsftpd.conf下 [root@localhost ~]# grep -Ev '^#' /etc/vsftpd/vsftpd.confanonymous_enable=YESlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_std_format=YESlisten=NOlisten_ipv6=YESpam_service_name=vsftpduserlist_enable=YEStcp_wrappers=YES 参数 作用 listen=[YES|NO] 是否以独立运行的方式监听服务 listen_address=IP地址 设置要监听的IP地址 listen_port=21 设置FTP服务的监听端口 download_enable＝[YES|NO] 是否允许下载文件 userlist_enable=[YES|NO]userlist_deny=[YESNO] 设置用户列表为“允许”还是“禁止”操作 max_clients=0 最大客户端连接数，0为不限制 max_per_ip=0 同一IP地址的最大连接数，0为不限制 anonymous_enable=[YES|NO] 是否允许匿名用户访问 anon_upload_enable=[YES|NO] 是否允许匿名用户上传文件 anon_umask=022 匿名用户上传文件的umask值 anon_root=/var/ftp 匿名用户的FTP根目录 anon_mkdir_write_enable=[YES|NO] 是否允许匿名用户创建目录 anon_other_write_enable=[YES|NO] 是否开放匿名用户的其他写入权限（包括重命名、删除等操作权限） anon_max_rate=0 匿名用户的最大传输速率（字节/秒），0为不限制 local_enable=[YES|NO] 是否允许本地用户登录FTP local_umask=022 本地用户上传文件的umask值 local_root=/var/ftp 本地用户的FTP根目录 chroot_local_user=[YES|NO] 是否将用户权限禁锢在FTP目录，以确保安全 local_max_rate=0 本地用户最大传输速率（字节/秒），0为不限制 PAM配置以下配置是PAM在FTP文件中的配置，写入/etc/vsftpd/vsftpd.conf 参数 作用 anonymous_enable=NO 禁止匿名开放模式 local_enable=YES 允许本地用户模式 guest_enable=YES 开启虚拟用户模式 guest_username=virtual 指定虚拟用户账户 pam_service_name=vsftpd.vu 指定 PAM 文件 allow_writeable_chroot=YES 允许对禁锢的FTP 根目录执行写入操作，而且不拒绝用户的登录请求 FTP用户禁止登录表[root@centos niki]# cat /etc/vsftpd/user_listrootbindaemonadmlpsyncshutdownhaltmailnewsuucpoperatorgamesnobody[root@centos niki]# cat /etc/vsftpd/ftpusers# Users that are not allowed to login via ftprootbindaemonadmlpsyncshutdownhaltmailnewsuucpoperatorgamesnobody FTP-SElinux[root@linuxprobe ~]# getsebool -a | grep ftpftp_home_dir --&gt; offftpd_anon_write --&gt; offftpd_connect_all_unreserved --&gt; offftpd_connect_db --&gt; offftpd_full_access --&gt; offftpd_use_cifs --&gt; offftpd_use_fusefs --&gt; offftpd_use_nfs --&gt; offftpd_use_passive_mode --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_enable_ftp_server --&gt; offsftpd_anon_write --&gt; offsftpd_enable_homedirs --&gt; offsftpd_full_access --&gt; offsftpd_write_ssh_home --&gt; offtftp_anon_write --&gt; offtftp_home_dir --&gt; off[root@linuxprobe ~]# setsebool -P ftpd_full_access=on 安装FTP服务yum -y install vsftpd#清空Iptables，因为Iptables防火墙管理工具默认禁止FTP传输协议的端口号iptables -F#下一步是使用service iptables save保存防火墙规则，但这里没有，我们需要安装iptables-servicessystemctl stop firewalldyum install iptables-services -ysystemctl enable iptablessystemctl start iptablesservice iptables save#安装客户端工具yum -y install ftp 1. 匿名登录模式 参数 作用 anonymous_enable=YES 允许匿名访问模式 anon_umask=022 匿名用户上传文件的umask值 anon_upload_enable=YES 允许匿名用户上传文件 anon_mkdir_write_enable=YES 允许匿名用户创建目录 anon_other_write_enable=YES 允许匿名用户修改目录名称或删除目录 什么是umask值？ umask值用于设置用户在创建文件时的默认权限，当我们在系统中创建目录或文件时，目录或文件所具有的默认权限就是由umask值决定的。 #首先清空文件cat /dev/null &gt; /etc/vsftpd/vsftpd.conf#然后写入cat &gt;&gt; /etc/vsftpd/vsftpd.conf &lt;&lt; EOF#匿名用户上传文件的umask值anon_umask=022#允许匿名用户上传文件anon_upload_enable=YES#允许匿名用户创建目录anon_mkdir_write_enable=YES#允许匿名用户修改目录名称或者删除目录anon_other_write_enable=YES#允许匿名访问anonymous_enable=YESEOF#防止干扰systemctl stop firewalldsetenforce 0#重启VSftpd服务systemctl restart vsftpd#开机自启systemctl enable vsftpd 2. 本地用户登录 参数 作用 anonymous_enable=NO 禁止匿名访问模式 local_enable=YES 允许本地用户模式 write_enable=YES 设置可写权限 local_umask=022 本地用户模式创建文件的 umask 值 userlist_enable=YES 启用“禁止用户名单”，名单文件为 ftpusers 和 user_list userlist_deny=YES 开启用户作用名单文件功能 &gt; /etc/vsftpd/vsftpd.confcat &gt;&gt; /etc/vsftpd/vsftpd.conf &lt;&lt; EOFanonymous_enable=NOlocal_enable=YESwrite_enable=YESlocal_umask=022pam_service_name=vsftpd #不加这一句登录就会报530的错EOF#防止干扰systemctl stop firewalldsetenforce 0#本地用户需要使用本地Linux的账号登录，这里创建一个账户并添加用户名和密码useradd nikiecho \"monian\" | passwd --stdin nikiecho \"This is $PWD\" &gt; /home/niki/tool.txt#重启VSftpd服务systemctl restart vsftpd#开机自启systemctl enable vsftpd 如果是530登录异常： https://blog.csdn.net/wlchn/article/details/50855447 3. 虚拟用户登录虚拟用户登录配置文件关系图： pam_serivice_name：用户认证文件 guest_username：指定虚拟用户账户 user_config_dir：用户配置目录 虚拟用户认证即使知道了登录FTP服务器的账号密码，也不会对Linux主机造成破坏，因为虚拟认证的账号密码在Linux服务器内并不存在。正如同这里的dzq --- 123 以及gz --- 456 ，在Linux系统中并没有相关的用户。而这些虚拟的用户会统一映射到Virtual这个用户下。 关于FTP服务器使用虚拟用户登录的时候为什么还要再建立一个本地账户的解释： 由于Linux系统中的每一个文件都有所有者、所属组属性，例如使用虚拟账户“张三”新建了一个文件，但是系统中找不到账户“张三”，就会导致这个文件的权限出现错误。为此，需要再创建一个可以映射到虚拟用户的系统本地用户。简单来说，就是让虚拟用户默认登录到与之有映射关系的这个系统本地用户的家目录中，虚拟用户创建的文件的属性也都归属于这个系统本地用户，从而避免Linux系统无法处理虚拟用户所创建文件的属性权限。 #创建用户名和密码并Hash，奇数行是用户名，偶数行是密码rm -rf /etc/vsftpd/vuser*cat &gt;&gt; /etc/vsftpd/vuser.list &lt;&lt; EOFdzq123gz456EOF#将用户信息文件转换为数据库并使用Hash加密db_load -T -t hash -f vuser.list vuser.dbchmod 600 vuser.dbrm -f vuser.list#添加用户，指定解释器nologin,使用户无法登录系统useradd -s /sbin/nologin virtualchmod -Rf 755 /home/virtualcat &gt;&gt; /etc/pam.d/vsftpd.vu &lt;&lt; EOFauth required pam_userdb.so db=/etc/vsftpd/vuseraccount required pam_userdb.so db=/etc/vsftpd/vuserEOFmkdir /etc/vsftpd/vusers_dir/touch /etc/vsftpd/vusers_dir/dzqcat &gt;&gt; /etc/vsftpd/vusers_dir/gz &lt;&lt; EOFanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YESEOFcat &gt;&gt; /etc/vsftpd/vsftpd.conf &lt;&lt; EOFanonymous_enable=NOlocal_enable=YESguest_enable=YESguest_username=virtualallow_writeable_chroot=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_std_format=YESlisten=NOlisten_ipv6=YES#修改ftp默认配置中的pam认证文件,表示服务器是根据/etc/pam.d/vsftpd.vu进行认证的pam_service_name=vsftpd.vuuserlist_enable=YEStcp_wrappers=YES#该目录下定义了用户的配置，如权限之类user_config_dir=/etc/vsftpd/vusers_dirEOFsystemctl restart vsftpd db_load介绍：将用户信息文件转换为数据库并使用Hash加密 参数 作用 -T 选项-T允许应用程序能够将文本文件转译载入进数据库。由于我们之后是将虚拟用户的信息以文件方式存储在文件里的，为了让Vsftpd这个应用程序能够通过文本来载入用户数据，必须要使用这个选项。如果指定了选项-T，那么一定要追跟子选项-t -t 子选项-t，追加在在-T选项后，用来指定转译载入的数据库类型。扩展介绍下，-t可以指定的数据类型有Btree、Hash、Queue和Recon数据库。 -f 参数后面接包含用户名和密码的文本文件，文件的内容是：奇数行用户名、偶数行密码 默认登录目录是/home/virtual/ PAM认证原文链接：https://blog.csdn.net/zhangym199312/article/details/78021998 PAM简介 Sun公司于1995 年开发的一种与认证相关的通用框架机制 PAM 是关注如何为服务验证用户的API，通过提供一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分，使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序，同时，PAM是一种认证框架，自身不做认证 PAM(Pluggable Authentication Modules)即可插拔式认证模块，它是一种高效而且灵活便利的用户级别的认证方式，它也是当前Linux服务器普遍使用的认证方式。当然，在不同版本的Linux统中部署PAM认证是有所不同的。它提供了对所有服务进行认证的中央机制，适用于login，远程登录（telnet,rlogin,fsh,ftp,点对点协议（PPP）），su等应用程序中。系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略；应用程序开发者通过在服务程序中使用PAM API(pam_xxxx( ))来实现对认证方法的调用；而PAM服务模块的开发者则利用PAM SPI来编写模块（主要是引出一些函数pam_sm_xxxx( )供PAM接口库调用），将不同的认证机制加入到系统中；PAM接口库（libpam）则读取配置文件，将应用程序和相应的PAM服务模块联系起来。 PAM架构如下图所示： 认证顺序： Service（服务）—-&gt;PAM配置文件—–&gt;pam_*.so 首先查看服务，查看服务上是否定义的有pam验证的信息，根据这些验证信息，去读取pam配置文件，之后，pam配置文件里面定义各种规则（我们管理员需要定义的），生效，调用pam_*.so模块。 2、Samba服务简介SMB简介： ​ Samba（Server Message Block，服务消息块）是在Linux和Unix系统上实现SMB协议的一个免费软件，提供CIFS(Common Internet File System)协议，由服务器及客户端程序构成，SMB(Server Messages Block,信息服务块)是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。 CIFS简介： CIFS(Common Internet File System)文件系统也称通用Internet文件系统,它使程序可以访问远程Internet计算机上的文件并要求此计算机的服务。CIFS使用客户/服务器模式。客户程序请求远在服务器上的服务程序为它提供服务，服务器获得请求并返回响应。CIFS是公开的开放的SMB协议版本。SMB协议现在是在局域网上用于服务器文件访问和打印的协议。像SMB协议一样，CIFS在高层运行。可以看做是应用程序协议如文件传输协议和超文本传输协议的一个实现。 CIFS功能： 访问服务器本地文件并读写这些文件 与其它用户一起共享一些文件块 在断线时自动恢复与网络的连接 使用统一码文件名 CIFS 是 SMB 协议的衍生品，即 CIFS 是 SMB 协议的一种特殊实现，由美国微软公司开发。 配置文件Samba功能 使Linux主机称为window网络中的一份子，与window系统相互分享资源 让linux主机能使用window共享的文件和打印机 使Linux主机称为Wins名称服务器，提供NetBIOS名字解析服务器 提供用户身份验证功能 支持SSL安全套接层协议 Samba提供服务 文件和打印机共享 用户验证和授权 名字解析 浏览（服务通告） Samba守护进程 Smbd： 实现共享和验证授权功能 Nmbd： 实现名字解析和浏览服务 Samba的RPM包： samba-common: 服务端和客户端所需要的文件 samba： 服务端软件 samba&#x3D;winbind： 可选的winbind服务 samba-client： 客户端软件 samba-swat： Web配置工具 Samba服务的配置文件在/etc/samba/smb.conf下，其主要的参数和作用如下： [global] #全局参数。 workgroup = MYGROUP #工作组名称 server string = Samba Server Version %v #服务器介绍信息，参数%v为显示SMB版本号 log file = /var/log/samba/log.%m #定义日志文件的存放位置与名称，参数%m为来访的主机名 max log size = 50 #定义日志文件的最大容量为50KB security = user #安全验证的方式，总共有4种 #1. share：来访主机无需验证口令；比较方便，但安全性很差 #2. user：需验证来访主机提供的口令后才可以访问；提升了安全性 #3. server：使用独立的远程主机验证来访主机提供的口令（集中管理账户） #4. domain：使用域控制器进行身份验证 passdb backend = tdbsam #定义用户后台的类型，共有3种 #1. smbpasswd：使用smbpasswd命令为系统用户设置Samba服务程序的密码 #2. tdbsam：创建数据库文件并使用pdbedit命令建立Samba服务程序的用户 #3. ldapsam：基于LDAP服务进行账户验证 load printers = yes load printers = yes #设置在Samba服务启动时是否共享打印机设备 cups options = raw #打印机的选项 [homes] #共享参数 comment = Home Directories #描述信息 browseable = no #指定共享信息是否在“网上邻居”中可见 writable = yes #定义是否可以执行写入操作，与“read only”相反 [printers] #打印机共享参数 comment = All Printers path = /var/spool/samba #共享文件的实际路径(重要)。 browseable = no guest ok = no #是否所有人可见，等同于\"public\"参数。 writable = no printable = yes [database] #共享名称为databasecomment = Do not arbitrarily modify the database file #警告用户不要随意修改数据库path = /home/database #共享目录为/home/databasepublic = no #关闭“所有人可见”writable = yes #允许写入操作 配置命令PdbeditSamba服务程序默认使用的是用户口令认证模式（user）。这种认证模式可以确保仅让有密码且受信任的用户访问共享资源，而且验证过程也十分简单。不过，只有建立账户信息数据库之后，才能使用用户口令认证模式。另外，Samba服务程序的数据库要求账户必须在当前系统中已经存在，否则日后创建文件时将导致文件的权限属性混乱不堪，由此引发错误。pdbedit命令用于管理SMB服务程序的账户信息数据库。 常用参数 含义 pdbedit -a username 新建Samba账户。 pdbedit -r username 修改Samba账户。 pdbedit -x username 删除Samba账户 pdbedit -L 列出Samba用户列表，读取passdb.tdb数据库文件。 报错：Failed to add entry for user qwer，是因为没有添加本地账户。 Semanagesemanage命令 是用来查询与修改SELinux默认目录的安全上下文。 详情：https://ipcmen.com/semanage semanage 含义 semanage -l 查询 semanage fcontext 主要用在安全上下文方面 semanage -a 增加，你可以增加一些目录的默认安全上下文类型设置 semanage -m 修改 semanage -d 删除 SELinux安全上下文 详情：http://c.biancheng.net/view/1151.html chcon和restorecon命令，如果一个文件的安全上下文和它默认的不匹配的话，一般情况会导致没有权限访问这个文件，这是Selinux的一种功能。 restorecon：把文件的安全上下文恢复成默认的安全上下文。 restorecon [选项】 文件或目录 -R：递归.当前目录和目录下所有的子文件同时恢复； -V：把恢复过程显示到屏幕上； Samba配置yum -y install samba#添加用户useradd niki#pdbedit是samba的用户管理命令，这里需要手动输入密码pdbedit -a -u niki#new password:monian#retype new password:monianmkdir /home/databasechown -Rf niki:niki /home/database#这里如果SELINUX关闭的话，下面几行关于安全上下文的命令可以不用敲#安装semanageyum -y install policycoreutils-python.x86_64#增加一条关于samba的安全上下文semanage fcontext -a -t samba_share_t /home/database#将/home/database的安全上下文回复restorecon -Rv /home/database/restorecon reset /home/database context unconfined_u:object_r:home_root_t:s0-&gt;unconfined_u:object_r:samba_share_t:s0&gt;/etc/samba/smb.confcat &gt;&gt; /etc/samba/smb.conf &lt;&lt; EOF[global]workgroup = MYGROUPserver string = Samba Server Version %vlog file = /var/log/samba/log.%mmax log size = 50security = userpassdb backend = tdbsamload printers = yescups options = raw[database]comment = Do not arbitrarily modify the database filepath = /home/databasepublic = nowritable = yesEOF systemctl restart smbsystemctl enable smb 挂载SambaWindows 需要进行登录，登录用户名为niki，密码为monian Linux yum install cifs-utilsmkdir /databasecat &gt;&gt; /root/auth.smb &lt;&lt; EOFusername=nikipassword=moniandomain=MYGROUPEOFcat &gt;&gt; /etc/fstab &lt;&lt; EOF//192.168.10.10/database /database cifs credentials=/root/auth.smb 0 0EOFmount -a 3、NFS服务配置文件参数NFS的配置文件在/etc/exports中，其基本格式为：/挂在文件目录 允许访问的IP地址(权限相关) 注意NFS客户端地址与权限之间没有空格。 参数 含义 ro 只读 rw 读写 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据 ​ NFS相关包nfs-utils:NFS主要组件，包含rpc、nfsd、和rpc.mountd这两个守护进程nfsbind：提供rpc端口映射的守护进程exportfs：在NFS服务器，维护nfs共享资源的命令showmount：用来查看nfs客户端的资源共享目录nfsstat：显示nfs状态信息rpcinfo：显示由rpc启动服务 systemctl start rpcbind &amp;&amp; systemctl start nfs-server软件包：nfs-utils服务类型：由systemd启动的守护进程配置单元： /usr/lib/systemd/system/nfs.service守护进程：rpc .nfsd rpc.mountd 端口号：2049 nfsd 111 rpcbind 20048 mountd服务端配置：/etc/exports相关软件包： rpcbind 服务端配置yum -y install nfs-utilsmkdir /nfschmod -Rf 777 /nfs/echo \"This is NFS\" &gt; /nfs/nfs.txtcat &gt;&gt; /etc/exports &lt;&lt; EOF/nfs *(rw,sync,no_root_squash)EOFsystemctl restart rpcbindsystemctl restart nfs-server.service 如果windows下连接报网络错误53的话，可能是以下情况： NFS服务器有一个”在非安全模式工作（允许更高的端口号）“的选项。Windows NFS客户端经常使用的是大的端口号。你可以在你的共享项设置中开启这个选项例如：/share *(insecure,rw) 客户端配置Windows 控制面板 ---- 程序 ---- 程序和功能： win+r --- cmd --- 挂在 文件管理器 Linux [root@linuxprobe ~]# showmount -e 192.168.10.10Export list for 192.168.10.10:/nfsfile 192.168.10.*[root@linuxprobe ~]# mkdir /nfsfile[root@linuxprobe ~]# mount -t nfs 192.168.10.10:/nfsfile /nfsfile#想要长期挂在，可以编辑/etc/fstab文件 showmount参数 作用 -e 显示NFS服务器的共享列表 -a 显示本机挂载的文件资源的情况NFS资源的情况 ​ 自动挂载​ 与mount命令不同，autofs服务程序是一种Linux系统守护进程，当检测到用户试图访问一个尚未挂载的文件系统时，将自动挂载该文件系统。换句话说，我们将挂载信息填入/etc/fstab文件后，系统在每次开机时都自动将其挂载，而autofs服务程序则是在用户需要使用该文件系统时才去动态挂载，从而节约了网络资源和服务器的硬件资源。 yum -y install nfs-utilsyum -y install autofsshowmount -e 192.168.19.132mkdir /mynfs#配置文件格式：【挂载目录】 【子配置文件】echo \"/mynfs /etc/nfs.misc\" &gt;&gt; /etc/auto.master#子配置文件格式：【挂载目录】 【挂载文件类型及权限】:【设备名称】#比如：iso -fstype=iso9660,ro,nosuid,nodev :/dev/cdrom#权限详情参见挂载时文件权限echo \"name1 -fstype=nfs 192.168.19.132:/nfs\" &gt;&gt; /etc/nfs.miscsystemctl restart autofscd /mynfs/name1/ 备份百度云#!/bin/bash#自动备份百度云文件#2020/4/16 Python2.7# # ----------------------------------------------------------------------------------------# 安装依赖 # pip install requests# pip install bypy## [root@localhost ~]# bypy info# Please visit: # 访问下边这个连接，复制授权码# https://openapi.baidu.com/oauth/2.0/authorize?scope=basic+netdisk&amp;redirect_uri=oob&amp;response_type=code&amp;client_id=q8WE4EpCsau1oS0MplgMKNBn# And authorize this app# Paste the Authorization Code here within 10 minutes.# Press [Enter] when you are done # 提示在下边粘贴授权码# a288f3d775fa905a6911692a0808f6a8# Authorizing, please be patient, it may take upto None seconds...# Authorizing/refreshing with the OpenShift server ...# OpenShift server failed, authorizing/refreshing with the Heroku server ...# Successfully authorized# Quota: 2.015TB# Used: 740.493GB# 由于百度PCS API权限限制，程序只能存取百度云端/apps/bypy目录下面的文件和目录。我们可以通过：# [root@localhost ~]# bypy list# /apps/bypy ($t $f $s $m $d):## 把本地当前目录下的文件同步到百度云盘：# bypy upload## 把云盘上的内容同步到本地:# bypy downdir## 比较本地当前目录和云盘根目录，看是否一致，来判断是否同步成功：# bypy compare# ----------------------------------------------------------------------------------------# /BaiDuDS 就是我们备份百度云的本地目录# 创建一个文件，用于存放上一次测量的Baiduyun备份大小。如果这次测量后大小相同，说明没有上传文件，不需要备份touch /tmp/sizesize_now=`du -sh /BaiDuDS | awk -F ' ' '&#123;print $1&#125;'`size_before=`cat /tmp/size`if [ \"$size_now\" = \"$size_before\" ];then echo \"File Hasn't Changed\"else echo \"File Has Changed , Update /tmp/size..\" echo \"$size_now\" &gt; /tmp/size echo \"BackUp to BaiduDuYun\" # 同步文件夹到远端 bypy downdirfi","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[]},{"title":"Linux系统存储","slug":"Linux_system_storage","date":"2019-12-25T11:27:45.000Z","updated":"2020-07-04T17:19:11.394Z","comments":true,"path":"2019/12/25/Linux_system_storage/","link":"","permalink":"http://ymlog.cn/2019/12/25/Linux_system_storage/","excerpt":"念两句诗冷眼向洋看世界，热风吹雨洒江天。云横九派浮黄鹤，浪下三吴起白烟。","text":"念两句诗冷眼向洋看世界，热风吹雨洒江天。云横九派浮黄鹤，浪下三吴起白烟。 磁盘管理磁盘设备根据接口进行命名，IDE接口的，以/dev/hd的形式命名。而SCSI、SATA、SAS、USB接口的，以sda,sdb,sdc的形式命名，不同的设备划分的名字从a-z。 IDE的英文全称为“Integrated Drive Electronics”，即“电子集成驱动器”，它的本意是指把“硬盘控制器”与“盘体”集成在一起的硬盘驱动器,这种类型的接口随着接口技术的发展已经被淘汰了，而其后发展分支出更多类型的硬盘接口，比如ATA、Ultra ATA、DMA、Ultra DMA等接口都属于IDE硬盘。以上是传统的并行ATA传输方式，后来又出现了串行ATA（Serial ATA，简称SATA），其最大数据传输率更进一步提高到了150MB/sec。SATA的全称是Serial Advanced Technology Attachment，是 由Intel、IBM、Dell、APT、Maxtor和seagate公司共同提出的硬盘接口规范。SATA规范将硬盘的外部传输速率理论值提高到了150MB/s。SATA的优势：支持热插拔 ，传输速度快，执行效率高。SATA接口需要硬件芯片的支持 ，例如Intel ICH5(R)、VIA VT8237、nVIDIA的MCP RAID和SiS964，如果主板南桥芯片不能直接支持的话，就需要选择第三方的芯片 ，例如SiliconImage 3112A芯片等，不过这样也就会产生一些硬件性能的差异，并且驱动程序也比较繁杂。 更多接口知识： https://www.cnblogs.com/LinuxSuDa/p/4513996.html 两种分区部分文件摘录于： https://blog.csdn.net/efhgyj/article/details/91174541 对于同一块硬盘，又可以有不同的分区，分区的划分以数字命名，如：sdb1,sdb2,sdb3。分区的方式有：MBR分区和GPT分区。 MBR分区 ​ MBR的意思是“主引导记录”，是IBM公司早年间提出的。它是存在于磁盘驱动器开始部分的一个特殊的启动扇区。这个扇区包含了已安装的操作系统系统信息，并用一小段代码来启动系统。如果你安装了Windows，其启动信息就放在这一段代码中——如果MBR的信息损坏或误删就不能正常启动Windows，这时候你就需要找一个引导修复软件工具来修复它就可以了。Linux系统中MBR通常会是GRUB加载器。MBR。当一台电脑启动时，它会先启动主板自带的BIOS系统，bios加载MBR，MBR再启动Windows，这就是mbr的启动过程。 GPT分区 GPT的意思是GUID Partition Table，即“全局唯一标识磁盘分区表”。他是另外一种更加先进新颖的磁盘组织方式，一种使用UEFI启动的磁盘组织方式。最开始是为了更好的兼容性，后来因为其更大的支持内存（mbr分区最多支持2T的磁盘），更多的兼容而被广泛使用，特别是苹果的MAC系统全部使用gpt分区。gtp不在有分区的概念，所有CDEF盘都在一段信息中存储。可以简单的理解为更先进但是使用不够广泛的技术。 两者之间的区别 因为兼容问题，gpt其实在引导的最开始部分也有一段MBR引导，也叫做“保护引导”，为了防止设备不支持UEFI 1、MBR最多支持2T，而GPT理论上是无限制的。 2、MBR最多支持四个主分区，GPT没有限制。如果你想跑多系统，MBR最多4个而GPT没有限制。 3、win7只能用MBR分区，从Win8开始微软建议你使用GPT。 4、GPT是由UEFI启动的，而UEFI是后来才提出的概念，兼容性和稳定性不如BIOS+MBR。 Windows系统分区 最先出现在Windows8中设置新磁盘，系统会询问你是想要使用MBR还是GPT分区，GPT是一种新的硬盘分区标准。GPT带来了很多新特性，最大支持18EB的大容量（EB=1024 PB，PB=1024 TB）；MBR最大只支持2TB，但拥有最好的兼容性。 MBR（Master Boot Record）分区： MBR的意思是“主引导记录”，它有自己的启动器，也就是启动代码，一旦启动代码被破坏，系统就没法启动，只有通过修复才能启动系统。最大支持2TB容量，在容量方面存在着极大的瓶颈，那么GPT在今后的发展就会越来越占优势，MBR也会逐渐被GPT取代。 GPT（GUID Partition Table）分区： GPT意为GUID分区表，这是一个正逐渐取代MBR的新标准，它由UEFI辅助而形成的，这样就有了UEFI用于取代老旧的BIOS，而GPT则取代老旧的MBR。这个标准没有MBR的那些限制。磁盘驱动器容量可以大得多，大到操作系统和文件系统都没法支持。它同时还支持几乎无限个分区数量，限制只在于操作系统，Windows支持最多128个GPT分区。通过UEFI，所有的64位的win10，win8，win7和Vista，以及所对应的服务器都能从GPT启动 有区别，GPT和MBR是不同的分区表类型。使用MBR分区表的硬盘最多只能划分4个主分区磁盘，并且MBR最大仅支持2TB的硬盘。如果需要分区的硬盘容量超过2TB了，则需要使用GPT分区表类型，此分区表类型不受分区个数、硬盘大小的限制。 UEFI，全称Unified Extensible Firmware Interface，即“统一的可扩展固件接口”，是一种详细描述全新类型接口的标准，是适用于电脑的标准固件接口，旨在代替BIOS（基本输入/输出系统）。此标准由UEFI联盟中的140多个技术公司共同创建，其中包括微软公司。UEFI旨在提高软件互操作性和解决BIOS的局限性。 要详细了解UEFI，还得从BIOS讲起。我们都知道，每一台普通的电脑都会有一个BIOS，用于加载电脑最基本的程式码，担负着初始化硬件，检测硬件功能以及引导操作系统的任务。UEFI就是与BIOS相对的概念，这种接口用于操作系统自动从预启动的操作环境，加载到一种操作系统上，从而达到开机程序化繁为简节省时间的目的。传统BIOS技术正在逐步被UEFI取而代之，在最近新出厂的电脑中，很多已经使用UEFI，使用UEFI模式安装操作系统是趋势所在。 总结 UEFI是新式的BIOS，legacy是传统BIOS。你在UEFI模式下安装的系统，只能用UEFI模式引导；同理，如果你是在Legacy模式下安装的系统，也只能在legacy模式下进系统。UEFI只支持64为系统且磁盘分区必须为GPT模式，传统BIOS使用INT13中断读取磁盘，每次只能读64KB，非常低效，而UEFI每次可以读1MB，载入更快。此外，Win8，更是进一步优化了UEFI支持，号称可以实现瞬时开机。 磁盘分区#选择一块需要划分区的磁盘[root@localhost ~]# fdisk /dev/sdb#或者查看磁盘里面的分区[root@node1 ~]# fdisk /dev/sdb -lDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x6b7b90db Device Boot Start End Blocks Id System/dev/sdb1 2048 10487807 5242880 8e Linux LVM/dev/sdb2 10487808 41943039 15727616 8e Linux LVM[root@node1 ~]# #查看内核当中是否识别新的分区[root@localhost ~]# cat /proc/partitions #通知内核重新读取磁盘分区[root@localhost ~]# partx -a /dev/sdb1partx: /dev/sdb: error adding partition 1#或者是：[root@localhost ~]# partprobe /dev/sdb1#上面那个是识别分区的，下面这个是识别磁盘的。#执行如下命令扫描磁盘: echo \"- - -\" &gt; /sys/class/scsi_host/host0/scan#查看内核分区[root@node1 ~]# cat /proc/partitions 分区管理的子命令Command (m for help): mCommand action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d 删除分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l 列出已知分区类型 m 打印帮助菜单 n 添加一个新分区 o create a new empty DOS partition table p 打印分区表 q 不保存退出 s create a new empty Sun disklabel t 改变分区系统的ID（类型） u change display/entry units v verify the partition table w 保存修改并退出 x extra functionality (experts only) 新建分区： Command (m for help): nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): p #选择主分区Partition number (2-4, default 2): 2 #一个有四个主分区，一个扩展分区，扩展分区可以用来分逻辑分区First sector (10487808-41943039, default 10487808): Using default value 10487808#分1个G给这个分区Last sector, +sectors or +size&#123;K,M,G&#125; (10487808-41943039, default 41943039): +1G Partition 2 of type Linux and of size 1 GiB is setCommand (m for help): p #查看当前分区表Disk &#x2F;dev&#x2F;sdd: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits &#x3D; sectors of 1 * 512 &#x3D; 512 bytesSector size (logical&#x2F;physical): 512 bytes &#x2F; 512 bytesI&#x2F;O size (minimum&#x2F;optimal): 512 bytes &#x2F; 512 bytesDisk label type: dosDisk identifier: 0x8809f989 Device Boot Start End Blocks Id System&#x2F;dev&#x2F;sdd1 2048 10487807 5242880 8e Linux LVM&#x2F;dev&#x2F;sdd2 10487808 12584959 1048576 83 Linux 删除分区 Command (m for help): dPartition number (1,2, default 2): Partition 2 is deletedCommand (m for help): pDisk /dev/sdd: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x8809f989 Device Boot Start End Blocks Id System/dev/sdd1 2048 10487807 5242880 8e Linux LVM 改变分区的格式 Command (m for help): l #列出当前分区的所有格式 0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden C: c6 DRDOS/sec (FAT---------------------------------，，，，------------------------------1c Hidden W95 FAT3 75 PC/IX be Solaris boot ff BBT Command (m for help): t #改变分区Selected partition 1Hex code (type L to list all codes): ff #选择system idChanged type of partition 'Linux LVM' to 'BBT'Command (m for help): p Device Boot Start End Blocks Id System/dev/sdd1 2048 10487807 5242880 ff BBT 当为磁盘分好分区之后，就要用合适的文件系统格式化这个分区，便于对这块磁盘进行文件存储等操作。 df命令du和df的区别？ du，disk usage,是通过搜索文件来计算每个文件的大小然后累加，du能看到的文件只是一些当前存在 的，没有被删除的。他计算的大小就是当前他认为存在的所有文件大小的累加和。 df，disk free，通过文件系统来快速获取空间大小的信息，当我们删除一个文件的时候，这个文件不 是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已 经删除的文件， df记录的是通过文件系统获取到的文件的大小，他比du强的地方就是能够看到已经删除 的文件，而且计算大小的时候，把这一部分的空间也加上了，更精确了。 当文件系统也确定删除了该文件后，这时候du与df就一致了。 du查看目录大小，df查看磁盘使用情况。 参数 含义 -a 显示全部的档案系统和各分割区的磁盘使用情形 -i 显示i -nodes的使用量 -k 大小用k来表示 (默认值) -t 显示某一个档案系统的所有分割区磁盘使用量 -x 显示不是某一个档案系统的所有分割区磁盘使用量 -T 显示每个分割区所属的档案系统名称 -H 人性化输出，换算关系是1000，而不是1024 查看块使用情况[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 17G 2.3G 15G 13% /devtmpfs 899M 0 899M 0% /devtmpfs 910M 0 910M 0% /dev/shmtmpfs 910M 9.4M 901M 2% /runtmpfs 910M 0 910M 0% /sys/fs/cgroup/dev/sda1 1014M 190M 825M 19% /boottmpfs 182M 0 182M 0% /run/user/0/dev/sdb1 2.0G 6.0M 1.8G 1% /root/m_test查看Inode使用情况[root@node1 test]# df -iFilesystem Inodes IUsed IFree IUse% Mounted ondevtmpfs 121503 368 121135 1% /devtmpfs 124468 1 124467 1% /dev/shmtmpfs 124468 720 123748 1% /runtmpfs 124468 16 124452 1% /sys/fs/cgroup/dev/mapper/centos-root 8910848 37480 8873368 1% //dev/sda1 524288 334 523954 1% /boottmpfs 124468 1 124467 1% /run/user/0/dev/sdb2 10240 4 10236 1% /root/test du命令查看某目录总体空间占比 [root@localhost ~]# du -sh /*157M /boot35M /etc76K /home-h, --human-readable print sizes in human readable format (e.g., 1K 234M 2G) --inodes list inode usage information instead of block usage -L, --dereference 取消所有引用符号链接 -s, --summarize 不显示每一级目录下每一级文件夹的占用空间，只显示当前目录 dd命令dd if=/dev/zero of=/dev/null&amp; pidif 是源of 是目的/dev/zero：吐零机/dev/null：数据黑洞bs=# 指定复制单元大小count=# 指定多少个bs磁盘拷贝 dd if=/dev/sda of=/dev/sdb将/dev/sda文件中的东西复制到/dev/sdb中两个参数 /dev/null --黑洞 /dev/zero --写0 文件系统概述Unix文件系统：FFS、UFS、JFS2网络文件系统：NFS 、CIFS集群文件系统：GFS2、OCF2分布式文件系统：ceph、Glusterfs、moosefsLinux文件系统:ext3,ext4,xfs 分类： 是否支持journal功能： 日志型文件系统：ext3、4、xfs... 非日志型文件系统：ext2、vfat文件系统的组成部分： 内核中的模块：ext4、xfs、vfat 用户空间的管理工具：mkfs、ext4、xfs、vfatLinux虚拟文件系统：VFS 格式化磁盘分区用不同的文件系统格式化磁盘分区 比如：将/dev/sdb1这个分区用ext4文件系统格式 [root@localhost ~]# mkfs.ext4 /dev/sdb1#一下两种方式是等价的mkfs.ext4 /dev/DEVICE == mkfs -t ext4 /dev/DEVICE#其中FS_TYPE是磁盘格式，可以是： ext4 xfs btrfs vfat等 swap交换分区#将/dev/sdb1分区以swap形式格式化[root@node1 ~]# mkswap /dev/sdd1mkswap: /dev/sdd1: warning: wiping old LVM2_member signature.Setting up swapspace version 1, size = 5242876 KiBno label, UUID=14fd926a-fac0-490b-9162-b00ccf8c7797#查看当前系统内存使用情况，包括物理内存、交换内存和内核缓冲内训[root@node1 ~]# free -m total used free shared buff/cache availableMem: 972 233 486 7 252 584Swap: 2047 0 2047#将格式化好的交换分区添加到交换内存中[root@node1 ~]# swapon /dev/sdd1[root@node1 ~]# free -m total used free shared buff/cache availableMem: 972 237 482 7 252 580Swap: 7167 0 7167free -m / -g -m 以MB为单位 -g 以GB为单位 #临时关闭交换分区swapoff /dev/sdb1 以上创建挂载swap分区只是临时有效，要想设备重启后依然生效，要将相关信息写入到/etc/fstab配置文件 查看文件系统部分资料来自于： https://blog.csdn.net/qq_34870631/article/details/88872938 blkid：查看块设备属性信息 [root@node1 ~]# blkid /dev/sdb1/dev/sdb1: UUID=\"OZC7Tc-r1R0-tikB-KtAN-zVYK-k3zz-fVeAUU\" TYPE=\"LVM2_member\" 【磁盘名称】 【UUID】 【磁盘类型】这里的磁盘类型是LVM2 UUID的作用： UUID为系统中的存储设备提供唯一的标识字符串，不管这个设备是什么类型的。如果你在系统中添加了新的存储设备如硬盘，很可能会造成一些麻烦，比如说启动的时候因为找不到设备而失败，而使用UUID则不会有这样的问题。 自动分配的设备名称并非总是一致的，它们依赖于启动时内核加载模块的顺序。如果你在插入了USB盘时启动了系统，而下次启动时又把它拔掉了，就有可能导致设备名分配不一致。 ubuntu中的许多关键功能现在开始依赖于UUID，例如grub──系统引导程序 Inode​ 日常在硬盘需要保存的数据实在太多了，因此 Linux 系统中有一个名为 super block 的“硬盘地图”。Linux 并不是把文件内容直接写入到这个“硬盘地图”里面，而是在里面记录着整个文件系统的信息。因为如果把所有的文件内容都写入到这里面，它的体积将变得非常大，而且文件内容的查询与写入速度也会变得很慢。Linux 只是把每个文件的权限与属性记录在inode 中，而且每个文件占用一个独立的 inode 表格，该表格的大小默认为 128 字节，里面记录着如下信息： ➢ 该文件的访问权限（read、write、execute）；➢ 该文件的所有者与所属组（owner、group）；➢ 该文件的大小（size）；➢ 该文件的创建或内容修改时间（ctime）；➢ 该文件的最后一次访问时间（atime）；➢ 该文件的修改时间（mtime）；➢ 文件的特殊权限（SUID、SGID、SBIT）；➢ 该文件的真实数据地址（point）。 mount挂载如果是临时挂载，则需要mount /dev/sdb1 /test，这样挂载重启后就会消失。想要永久挂载则需要更改/etc/fstab中的信息。 #mount:显示当前已经挂载的设备[root@node1 ~]# mount | tail -n 2/dev/mapper/V1-LV1 on /appdata type ext4 (rw,relatime,data=ordered)/dev/mapper/V1-thirdBack on /tmp/thirdUp type ext4 (ro,relatime,data=ordered)常用选项： -t：指名要挂载设备上的文件系统类型 -r：readonly，以只读的方式挂载 -w：不更新/etc/mtab -L：“Label”：以卷标指定挂载设备 -U：“UUID”：以UUID指定挂载设备 -B：绑定目录到另一个目录上 使用-o参数挂载时，可以去定义挂载文件系统的选项-o，--option&lt;list&gt; async:异步模式 sync:同步模式 atime/moatime：包含目录和文件 diratime/modiratime：目录的访问时间戳 auto/noauto：是否支持自动挂载 exec/noexec：是否支持将文件系统上的应用程序运行为进程 dev/nodev：是否支持在此文件系统上使用设备文件 suid/nouid：是否支持在此文件系统上使用uid标识 remount：重新挂载 ro： rw user/nouser：是否允许普通用户挂载此设备 acl：启用此文件系统上的ACL功能 默认挂载选项：defaults rw,suid,dev,exec,auto,nouser,async#以只读的形式挂载[root@node1 ~]# mount -o ro /dev/sdb3 test[root@node1 test]# cat /proc/mounts 关于/etc/fstab中的文件含义： [root@node1 ~]# cat /etc/fstab # /etc/fstab# Created by anaconda on Thu Aug 15 02:51:10 2019## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=b883fe76-ef59-4a95-bf91-db372d66c87f /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0【设备文件】 【挂载目录】 【格式类型】 【权限选项】 【是否备份】 【是否自检】 字段 意义 设备文件 一 般 为 设 备 的 路 径 + 设 备 名 称 ， 也 可 以 写 唯 一 识 别 码 （ UUID ，Universally Unique Identifier） 挂载目录 指定要挂载到的目录，需在挂载前创建好 格式类型 指定文件系统的格式，比如 Ext3、Ext4、XFS、SWAP、iso9660（此为光盘设备）等 权限选项 若设置为 defaults，则默认权限为：rw, suid, dev, exec, auto, nouser, async 是否备份 若为 1 则开机后使用 dump 进行磁盘备份，为 0 则不备份 是否自检 若为 1 则开机后自动进行磁盘自检，为 0 则不自检 卸载：umount /dev/sdb1。 如果卸载的时候卡死，可以试着用这条命令：fuser -mv -k /dev/sdb1 fuser使用手册： https://ipcmen.com/fuser yum install psmisc 软硬链接硬链接： 可以将它理解为一个“指向原始文件 inode 的指针”，系统不为它分配独立的 inode 和文件。所以，硬链接文件与原始文件其实是同一个文件，只是名字不同。我们每添加一个硬链接，该文件的 inode连接数就会增加 1；而且只有当该文件的 inode 连接数为 0 时，才算彻底将它删除。换言之，由于硬链接实际上是指向原文件 inode 的指针，因此即便原始文件被删除，依然可以通过硬链接文件来访问。需要注意的是，由于技术的局限性，我们不能跨分区对目录文件进行链接。软链接（也称为符号链接）：仅仅包含所链接文件的路径名，因此能链接目录文件，也可以跨越文件系统进行链接。但是，当原始文件被删除后，链接文件也将失效，从这一点上来说与 Windows 系统中的“快捷方式”具有一样的性质。 命令 –ln，格式为ln [选项] 目标 参数 作用 -s 创建“符号链接”（如果不带-s 参数，则默认创建硬链接） -f 强制创建文件或目录的链接 -i 覆盖前先询问 -v 显示创建链接的过程 创建两个代表软硬链接的文件夹，之后的测试就在这两个文件夹中进行[root@node1 diffLinks]# mkdir -p &#123;symbolic,hard&#125;准备两个文本[root@node1 diffLinks]# echo \"this is symbolic text\" &gt; symbolic/s.txt[root@node1 diffLinks]# echo \"this is hard text\" &gt; hard/h.txt[root@node1 diffLinks]# tree.├── hard│ └── h.txt└── symbolic └── s.txt2 directories, 2 files软链接[root@node1 diffLinks]# ln -s symbolic/s.txt sym.lnk硬链接[root@node1 diffLinks]# ln hard/h.txt had.lnk可以看到现在两个链接都可以正常查看[root@node1 diffLinks]# cat sym.lnk this is symbolic text[root@node1 diffLinks]# cat had.lnk this is hard text现在删除两个链接的源文件[root@node1 diffLinks]# rm symbolic/s.txt -f[root@node1 diffLinks]# rm hard/h.txt -f之后软链接就不可以查看了，硬链接还是可以查看，软链接有点像windows中的快捷方式，硬链接有点像是复制，但这里需要知道Linux文件删除的本质是什么？？？[root@node1 diffLinks]# cat sym.lnk cat: sym.lnk: No such file or directory[root@node1 diffLinks]# cat had.lnk this is hard text RAID阵列文章摘录于： https://blog.csdn.net/tianlesoftware/article/details/5429634 RAID（Redundant Arrays of Independent Disks），独立磁盘冗余阵列，简称磁盘阵列。 磁盘阵列分为两种：软阵列（Software Raid）和硬阵列（Hardware Raid）两种。 软阵列：即通过软件程序并由计算机CPU提供运行能力所构成，由于软件程式不是一个完整系统，故只能提供最基本的RAID容错功能，其他如热备用硬盘的设置，远程管理等功能均没有 硬阵列：是由独立操作系统的硬件提供整个磁盘阵列的控制和计算功能，不依靠系统的CPU资源，由于硬阵列是一个完整的系统，所有需要的功能均可以做进去，所以硬阵列所提供的功能和性能均比软阵列好。如果你想把系统也做到磁盘阵列中，硬阵列是唯一的选择，故我们在市场上RAID5级的磁盘阵列均为硬阵列，软阵列只适用于RAID 0和RAID 1 要使用磁盘RAID主要有两种方式，一种就是RAID适配卡，通过RAID适配卡插入PCI插槽，再接上硬盘实现RAID功能。第二种方式就是直接在主板上集成RAID控制芯片，让主板能直接实现磁盘RAID。 RAID 0条带化（Stripe）存储, 即Data Stripping数据分条技术。RAID 0可以把多块硬盘连成一个容量更大的硬盘群，可以提高磁盘的性能和吞吐量。RAID 0没有冗余或错误修复能力，成本低，要求至少两个磁盘，一般只是在那些对数据安全性要求不高的情况下才被使用。RAID 0连续以位或字节为单位分割数据，并行读/写于多个磁盘上，在所有的级别中，RAID 0的速度是最快的。理论上说，有N个磁盘组成的RAID0是单个磁盘读写速度的N倍。但是RAID 0没有冗余功能的，如果一个磁盘（物理）损坏，则所有的数据都无法使用。因此并不能算是真正的RAID结构。（1）、RAID 0最简单方式 就是把N块同样的硬盘用硬件的形式通过智能磁盘控制器或用操作系统中的磁盘驱动程序以软件的方式串联在一起，形成一个独立的逻辑驱动器，容量是单独硬盘的N倍,在电脑数据写时被依次写入到各磁盘中，当一块磁盘的空间用尽时，数据就会被自动写入到下一块磁盘中，它的好处是可以增加磁盘的容量。速度与其中任何一块磁盘的速度相同，如果其中的任何一块磁盘出现故障，整个系统将会受到破坏，可靠性是单独使用一块硬盘的1/n。（2）、RAID 0的另一方式 是用N块硬盘选择合理的带区大小创建带区集，最好是为每一块硬盘都配备一个专门的磁盘控制器,在电脑数据读写时同时向N块磁盘读写数据,速度提升n倍。提高系统的性能。 RAID 1RAID 1会将数据储存两份，称之为镜像(Mirror)存储。提高了可靠性，但磁盘利用率50%，也就是说，两块10G的磁盘组成RAID 1，最后磁盘容量也只有10G。 RAID 1是磁盘阵列中单位成本最高的，但提供了很高的数据安全性和可用性。当一个磁盘失效时，系统可以自动切换到镜像磁盘上读写，而不需要重组失效的数据。 RAID 3奇偶校验（XOR）条带存储，共享校验盘，数据条带存储单位为字节。RAID 3是以一个硬盘来存放数据的奇偶校验位，数据则分段存储于其余硬盘中。它象RAID 0一样以并行的方式来存放数，但速度没有RAID 0快。如果数据盘（物理）损坏，只要将坏硬盘换掉，RAID控制系统则会根据校验盘的数据校验位在新盘中重建坏盘上的数据。不过，如果校验盘（物理）损坏的话，则全部数据都无法使用。利用单独的校验盘来保护数据虽然没有镜像的安全性高，但是硬盘利用率得到了很大的提高，为n-1。RAID 3对于大量的连续数据可提供很好的传输率，但对于随机数据来说，奇偶盘会成为写操作的瓶颈。 RAID 5奇偶校验（XOR）条带存储，校验数据分布式存储，数据条带存储单位为块。RAID 5不单独指定的奇偶盘，而是在所有磁盘上交叉地存取数据及奇偶校验信息。在RAID 5上，读/写指针可同时对阵列设备进行操作，提供了更高的数据流量。RAID 5更适合于小数据块和随机读写的数据。RAID 3与RAID 5相比，最主要的区别在于RAID 3每进行一次数据传输就需涉及到所有的阵列盘；而对于RAID 5来说，大部分数据传输只对一块磁盘操作，并可进行并行操作。在RAID 5中有“写损失”，即每一次写操作将产生四个实际的读/写操作，其中两次读旧的数据及奇偶信息，两次写新的数据及奇偶信息。 RAID 5把校验块分散到所有的数据盘中。它使用了一种特殊的算法，可以计算出任何一个带区校验块的存放位置。这样就可以确保任何对校验块进行的读写操作都会在所有的RAID磁盘中进行均衡，从而消除了产生瓶颈的可能。RAID5的读出效率很高，写入效率一般，块式的集体访问效率不错。RAID 5提高了系统可靠性，但对数据传输的并行性解决不好，而且控制器的设计也相当困难。为了具有RAID-5级的冗余度，需要最少由三个磁盘组成的磁盘阵列（不包括一个热备用）。RAID-5可以通过磁盘阵列控制器硬件实现，也可以通过某些网络操作系统软件实现了。硬盘的利用率为n-1。当进行恢复时，比如我们需要需要恢复下图中的A0，这里就必须需要B0、C0、D0加0 parity才能计算并得出A0，进行数据恢复。所以当有两块盘坏掉的时候，整个RAID的数据失效。 RAID 10 和RAID 011、 RAID 10 是先做条带再做镜像。这种情况中，我们假设当DISK0损坏时，在剩下的3块盘中，只有当DISK1一个盘发生故障时，才会导致整个RAID失效，我们可简单计算故障率为1/3。 2、RAID 01 是先做备份在做条带。这种情况下，我们仍然假设DISK0损坏，这时左边的条带将无法读取。在剩下的3块盘中，只要DISK2，DISK3两个盘中任何一个损坏，都会导致整个RAID失效，我们可简单计算故障率为2/3。因此，RAID10比RAID01在安全性方面要强 ​ 从数据存储的逻辑位置来看，在正常的情况下RAID01和RAID10是完全一样的，而且每一个读写操作所产生的IO数量也是一样的，所以在读写性能上两者没什么区别。而当有磁盘出现故障时，比如前面假设的DISK0损坏时，我们也可以发现，这两种情况下，在读的性能上面也将不同，RAID10的读性能将优于RAID01。 把RAID0和RAID1技术结合起来，数据除分布在多个盘上外，每个盘都有其物理镜像盘，提供全冗余能力，允许一个以下磁盘故障，而不影响数据可用性，并具有快速读/写能力。RAID0+1要在磁盘镜像中建立带区集至少4个硬盘。 命令行实现格式为“mdadm [模式] &lt;RAID设备名称&gt; [选项] [成员设备名称]”。 参数 作用 -a 检测设备名称- n 指定设备数量 -l 指定 RAID 级别 -C 创建 -v 显示过程 -f 模拟设备损坏 -r 移除设备 -Q 查看摘要信息 -D 查看详细信息 -S 停止 RAID 磁盘阵列 [root@localhost ~]# yum -y install mdadm[root@localhost ~]# cat /proc/partitions major minor #blocks name 8 0 20971520 sda 8 1 1048576 sda1 8 2 19921920 sda2 8 16 20971520 sdb 8 48 20971520 sdd 8 64 20971520 sde 8 32 20971520 sdc--------------------more--------------------[root@localhost ~]# mdadm -Cv /dev/md0 -a yes -n 4 -l 10 /dev/sdb /dev/sdc /dev/sdd /dev/sdemdadm: layout defaults to n2mdadm: layout defaults to n2mdadm: chunk size defaults to 512K--------------------more---------------------C 参数代表创建一个 RAID 阵列卡；-v 参数显示创建的过程，同时在后面追加一个设备名称/dev/md0,这样/dev/md0就是创建后的RAID磁盘阵列的名称；-a yes 参数代表自动创建设备文件；-n 4 参数代表使用 4 块硬盘来部署这个RAID 磁盘阵列；-l 10 参数则代表 RAID 10 方案；最后再加上 4 块硬盘设备的名称就搞定了。将制作好的RAID磁盘阵列格式化为ext4格式[root@localhost ~]# mkfs.ext4 /dev/md0 mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: Linux--------------------more--------------------将制作好的磁盘挂载到目录，并查看属性信息[root@localhost ~]# mkdir RAID[root@localhost ~]# mount /dev/md0 RAID/[root@localhost ~]# df -h RAID/Filesystem Size Used Avail Use% Mounted on/dev/md0 40G 49M 38G 1% /root/RAID四个硬盘，每个20G，为什么size是40G呢？因为一半用来高速存储，一半用来数据备份了。查看/dev/md0 磁盘阵列的详细信息[root@localhost ~]# mdadm -D /dev/md0 /dev/md0: Version : 1.2 Creation Time : Tue Aug 13 15:37:47 2019 Raid Level : raid10--------------------more--------------------并把挂载信息写入到配置文件中，使其永久生效。[root@localhost ~]# echo \"/dev/md0 /root/RAID ext4 defaults 0 0\" &gt;&gt; /etc/fstab LVM部分摘录于相关文章： https://www.cnblogs.com/moox/p/11163229.html https://blog.51cto.com/13691477/2299707 https://blog.51cto.com/wuyelan/1540859 https://www.thegeekdiary.com/lvm-error-cant-open-devsdx-exclusively-mounted-filesystem/ http://www.liaojl.com/blog/device-devsdb-excluded-by-a-filter/ ​ 许多Linux使用者安装操作系统时都会遇到这样的困境：如何精确评估和分配各个硬盘分区的容量，如果当初评估不准确，一旦系统分区不够用时可能不得不备份、删除相关数据，甚至被迫重新规划分区并重装操作系统，以满足应用系统的需要。 ​ LVM是Linux环境中对磁盘分区进行管理的一种机制，是建立在硬盘和分区之上、文件系统之下的一个逻辑层，可提高磁盘分区管理的灵活性。RHEL5默认安装的分区格式就是LVM逻辑卷的格式，需要注意的是/boot分区不能基于LVM创建，必须独立出来。 原理解析要想理解好LVM的原理，我们必须首先要掌握4个基本的逻辑卷概念。 ①PE (Physical Extend) 物理拓展 ②PV (Physical Volume) 物理卷 ③VG (Volume Group) 卷组 ④LV (Logical Volume) 逻辑卷 1.将我们的物理硬盘格式化成PV(Physical Volume) ​ 我们看到，这里有两块硬盘，一块是sda，另一块是sdb，在LVM磁盘管理里，我首先要将这两块硬盘格式化为我们的PV(Physical Volume),也就是我们的物理卷，其实格式化物理卷的过程中LVM是将底层的硬盘划分为了一个一个的PE(Physical Extend),我们的LVM磁盘管理中PE的默认大小是4M大小，其实PE就是我们逻辑卷管理的最基本单位。比如说我有一个400M的硬盘，那么在将其格式化成PV的时候，其实际就是将这块物理硬盘划分成了100个的PE，因为PE默认的大小就是4M。这个就是我们的第一步操作。 2.创建一个VG(Volume Group) ​ 在将硬盘格式化成PV以后，我们第二步操作就是创建一个卷组，也就是VG(Volume Group),卷组在这里我们可以将其抽象化成一个空间池，VG的作用就是用来装PE的，我们可以把一个或者多个PV加到VG当中，因为在第一步操作时就已经将该硬盘划分成了多个PE，所以将多个PV加到VG里面后，VG里面就存放了许许多多来自不同PV中的PE，我们通过上面的图片就可以看到，我们格式化了两块硬盘，每个硬盘分别格式化成了3个PE，然后将两块硬盘的PE都加到了我们的VG当中，那么我们的VG当中就包含了6个PE，这6个PE就是两个硬盘的PE之和。通常创建一个卷组的时候我们会为其取一个名字，也就是该VG的名字。 3.基于VG创建我们最后要使用的LV(Logical Volume) ​ 【注意】PV以及VG创建好以后我们是不能够直接使用的，因为PV、VG是我们逻辑卷底层的东西，我们其实最后使用的是在VG基础上创建的LV(Logical Volume),所以第三步操作就是基于VG来创建我们最终要使用的LV。 ​ 当我们创建好我们的VG以后，这个时候我们创建LV其实就是从VG中拿出我们指定数量的PE，还是拿上图来说，我们看到我们此时的VG里面已经拥有了6个PE，这时候我们创建了我们的第一个逻辑卷，它的大小是4个PE的大小，也就是16M(因为一个PE的默认大小是4M)，而这4个PE有三个是来自于第一块硬盘，而另外一个PE则是来自第二块硬盘。当我们创建第二个逻辑卷时，它的大小就最多只有两个PE的大小了，因为其中的4个PE已经分配给了我们的第一个逻辑卷。 ​ 所以创建逻辑卷其实就是我们从VG中拿出我们指定数量的PE，VG中的PE可以来自不同的PV，我们可以创建的逻辑卷的大小取决于VG当中PE存在的数量，并且我们创建的逻辑卷其大小一定是PE的整数倍(即逻辑卷的大小一定要是4M的整数倍)。 4.将我们创建好的LV进行文件系统的格式化，然后挂载使用 ​ 在创建好LV以后，这个时候我们就能够对其进行文件系统的格式化了，我们最终使用的就是我们刚创建好的LV，其就相当于传统的文件管理的分区，我们首先要对其进行文件系统的格式化操作，然后通过mount命令对其进行挂载，这个时候我们就能够像使用平常的分区一样来使用我们的逻辑卷了。 ​ 我们在创建好LV以后，我们会在 /dev 目录下看到我们的LV信息，例如 /dev/vgname/lvname， 我们每创建一个VG，其会在/dev目录下创建一个以该VG名字命名的文件夹，在该VG的基础上创建好LV以后，我们会在这个VG目录下多出一个以LV名字命名的逻辑卷。 命令整理 命令 含义 fdisk 查看磁盘信息 pvcreate /dev/sdb1 /dev/sdc1 创建PV物理卷 pvdisplay 查看物理卷详细信息 pvs 查看物理卷摘要信息 vgcreate VG1 /dev/sdb1 /dev/sdc1 创建卷组（Volume vgdisplay 查看所有卷组的详细信息 vgs 查看卷组的摘要信息 lvcreate -n LV1 -L 1G VG1 创建逻辑卷 各参数含义： -n：表示创建逻辑卷名 -L ：表示分配逻辑卷的大小 VG1：表示在卷组VG1上创建逻辑卷LV1 命令 含义 lvs 显示逻辑卷的信息 lvdisplay 显示逻辑卷的详细信息 mke2fs -t ext4 /dev/VG1/LV1 格式化物理卷 mount /dev/VG1/LV1 /root/lvm1 挂载，可以再/etc/fstab中永久挂载 vgextend VG1 /dev/sdd1 扩容卷组容量，把物理卷加入卷组 lvextend -L +2G /dev/VG1/LV1 扩容逻辑卷LV1，增加2G容量 resize2fs /dev/VG1/LV1 确认增加容量 e2fsck -f /dev/VG1/LV1 强制检查LV1逻辑卷，需先卸载 resize2fs /dev/VG1/LV1 1G 缩减逻辑卷，-1G表示缩减1G大小，1G表示缩减到1G lvreduce -L 1G /dev/VG1/LV1 再进行逻辑卷的LV容量的缩减 pvmove /dev/sdb1 将sdb1磁盘分区的数据转移到其他盘上 vgreduce VG1 /dev/sdb1 把sdb1从VG1卷组中移除 pvremove /dev/sdb1 把sdb1分区从PV物理卷中释放出来 lvcreate -L 20M -n backup -s -p r /dev/V1/LV1 备份逻辑卷LV1 lvremove /dev/V1/backup 删除逻辑卷的备份 内核要求LVM1版本需要2.4及以后的内核支持；LVM2需要2.6及以后的内核版本支持。 [root@node1 LG]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core)[root@node1 LG]# uname -r3.10.0-1062.1.2.el7.x86_64 磁盘分区添加两块磁盘，分别为：/dev/sdb和/dev/sdc，分别对sdb和sdc进行分区。 sdb的分区是：两个主分区 sdc的分区是：一个主分区和一个扩展分区，其中扩展分区有分出了逻辑分区 第一块磁盘/dev/sdb分区：创建两个主分区 [root@node1 ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): p #主分区Using default response pPartition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): +5GPartition 1 of type Linux and of size 5 GiB is setCommand (m for help): nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): p #第一块磁盘划分两个主分区Using default response pPartition number (2-4, default 2): First sector (10487808-41943039, default 10487808): Using default value 10487808Last sector, +sectors or +size&#123;K,M,G&#125; (10487808-41943039, default 41943039): Using default value 41943039Partition 2 of type Linux and of size 15 GiB is set Command (m for help): t #做LVM管理，需要修改分区类型为Linux LVMPartition number (1,2, default 2): 1Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): tPartition number (1,2, default 2): Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): pDisk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xb7ee3c1b Device Boot Start End Blocks Id System/dev/sdb1 2048 10487807 5242880 8e Linux LVM/dev/sdb2 10487808 41943039 15727616 8e Linux LVMCommand (m for help): w #保存分区信息The partition table has been altered!#更新内核分区表[root@node1 ~]# partprobe /dev/sdb[root@node1 ~]# ls /dev/sdb*/dev/sdb /dev/sdb1 /dev/sdb2 第二块磁盘sdc的分区：创建一个主分区和一个逻辑分区，用来测试扩展分区和逻辑分区是否能够创建PV物理卷并加入VG卷组，实验证明，扩展分区是无法创建PV和加入VG，主分区和逻辑分区可以。 [root@node1 ~]# fdisk /dev/sdcWelcome to fdisk (util-linux 2.23.2).Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): p #主分区Using default response pPartition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): +5GPartition 1 of type Linux and of size 5 GiB is setCommand (m for help): nPartition type: p primary (1 primary, 0 extended, 3 free) e extended#扩展分区，要创建扩展分区之后，才能创建逻辑分区；#扩展分区只能创建一个，分区表支持创建最多四分主分区，#如果想要创建4个以上的分区，必须创建扩展分区，然后创建逻辑分区Select (default p): ePartition number (2-4, default 2): First sector (10487808-41943039, default 10487808): Using default value 10487808Last sector, +sectors or +size&#123;K,M,G&#125; (10487808-41943039, default 41943039): Using default value 41943039Partition 2 of type Extended and of size 15 GiB is setCommand (m for help): nPartition type: p primary (1 primary, 1 extended, 2 free) l logical (numbered from 5)Select (default p): l #创建逻辑分区Adding logical partition 5First sector (10489856-41943039, default 10489856): Using default value 10489856Last sector, +sectors or +size&#123;K,M,G&#125; (10489856-41943039, default 41943039): Using default value 41943039Partition 5 of type Linux and of size 15 GiB is setCommand (m for help): pDisk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x313b8a59 Device Boot Start End Blocks Id System/dev/sdc1 2048 10487807 5242880 83 Linux/dev/sdc2 10487808 41943039 15727616 5 Extended/dev/sdc5 10489856 41943039 15726592 83 LinuxCommand (m for help): t #修改分区类型Partition number (1,2,5, default 5): 1Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): tPartition number (1,2,5, default 5): 5Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): pDisk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x313b8a59 Device Boot Start End Blocks Id System/dev/sdc1 2048 10487807 5242880 8e Linux LVM/dev/sdc2 10487808 41943039 15727616 5 Extended/dev/sdc5 10489856 41943039 15726592 8e Linux LVMCommand (m for help): w #保存分区表信息The partition table has been altered![root@node1 ~]# partprobe /dev/sdc[root@node1 ~]# ls -l /dev/sdc*brw-rw---- 1 root disk 8, 32 Dec 25 06:31 /dev/sdcbrw-rw---- 1 root disk 8, 33 Dec 25 06:31 /dev/sdc1brw-rw---- 1 root disk 8, 34 Dec 25 06:31 /dev/sdc2brw-rw---- 1 root disk 8, 37 Dec 25 06:31 /dev/sdc5 创建PV、VG、LV报错 [root@node1 ~]# pvcreate /dev/sdb1 Can't open /dev/sdb1 exclusively. Mounted filesystem? Can't open /dev/sdb1 exclusively. Mounted filesystem? 可以尝试修改配置文件： /etc/lvm/lvm.conf 创建物理卷PV [root@localhost ~]# pvcreate /dev/sdc2 #sdc2是扩展分区，无法做成物理卷PV Device /dev/sdc2 not found (or ignored by filtering).[root@node1 ~]# pvcreate /dev/sdb1 #把sdb1做成物理卷PV，也可以用下面的写法，一次性把所有主分区或逻辑分区做成物理卷PV Physical volume \"/dev/sdb1\" successfully created.[root@node1 ~]# pvcreate /dev/sdb2 /dev/sdc1 /dev/sdc5 Physical volume \"/dev/sdb2\" successfully created. Physical volume \"/dev/sdc1\" successfully created. Physical volume \"/dev/sdc5\" successfully created.[root@node1 ~]# pvs#显示所有的物理卷 PV VG Fmt Attr PSize PFree /dev/sda2 centos lvm2 a-- &lt;19.00g 0 /dev/sdb1 lvm2 --- 5.00g 5.00g /dev/sdb2 lvm2 --- &lt;15.00g &lt;15.00g /dev/sdc1 lvm2 --- 5.00g 5.00g /dev/sdc5 lvm2 --- &lt;15.00g &lt;15.00g 创建卷组VG #创建卷组1，卷组的PV物理卷，可以是不同磁盘，即整合了所有磁盘分区做成资源池[root@node1 ~]# vgcreate V1 &#x2F;dev&#x2F;sdb1 &#x2F;dev&#x2F;sdc1 Volume group &quot;V1&quot; successfully created[root@node1 ~]# vgcreate V2 &#x2F;dev&#x2F;sdb2 &#x2F;dev&#x2F;sdc5 Volume group &quot;V2&quot; successfully created[root@node1 ~]# vgs VG #PV #LV #SN Attr VSize VFree V1 2 0 0 wz--n- 9.99g 9.99g V2 2 0 0 wz--n- 29.99g 29.99g centos 1 2 0 wz--n- &lt;19.00g 0 创建逻辑卷lv #-n表示创建逻辑卷名，-L表示分配逻辑卷的空间大小，VG1表示在卷组VG1上创建逻辑卷LVtest1[root@node1 ~]# lvcreate -n LV1 -L 1G V1 Logical volume \"LV1\" created.[root@node1 ~]# lvcreate -n LV2 -L 1G V2 Logical volume \"LV2\" created.[root@node1 ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert LV1 V1 -wi-a----- 1.00g LV2 V2 -wi-a----- 1.00g root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g [root@node1 ~]# ls -l /dev/V1total 0lrwxrwxrwx 1 root root 7 Dec 25 07:33 LV1 -&gt; ../dm-2 格式化逻辑卷LV #物理卷需要格式化之后才能使用，格式化为ext4格式[root@node1 ~]# mke2fs -t ext4 /dev/V1/LV1 mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks65536 inodes, 262144 blocks13107 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2684354568 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): doneWriting superblocks and filesystem accounting information: done 挂载逻辑卷 [root@node1 ~]# mkdir LG[root@node1 ~]# mount /dev/V1/LV1 LG/[root@node1 ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 475M 0 475M 0% /devtmpfs 487M 0 487M 0% /dev/shmtmpfs 487M 7.6M 479M 2% /runtmpfs 487M 0 487M 0% /sys/fs/cgroup/dev/mapper/centos-root 17G 2.1G 15G 12% //dev/sda1 1014M 176M 839M 18% /boottmpfs 98M 0 98M 0% /run/user/0/dev/mapper/V1-LV1 976M 2.6M 907M 1% /root/LG#永久挂载逻辑卷需要在/etc/fstab中设置 新增加一块硬盘，并将这块磁盘创建PV #通知系统重新搜索磁盘[root@node1 ~]# echo \"- - - \" &gt; /sys/class/scsi_host/host0/scan#按照之前的方法，将/dev/sdd分区并更改格式[root@node1 ~]# fdisk -l /dev/sdd | tail -n 2 Device Boot Start End Blocks Id System/dev/sdd1 2048 10487807 5242880 8e Linux LVM#创建物理卷PV[root@node1 ~]# pvcreate /dev/sdd1 Physical volume \"/dev/sdd1\" successfully created. #扩展VG卷组容量，把物理卷加入卷组[root@localhost ~]# vgextend VG1 /dev/sdd1 [root@node1 ~]# echo &quot;this is a test for LVM&quot;&gt; LG&#x2F;test#在挂载的逻辑卷里添加数据，用来测试在逻辑卷扩容是否会破坏原有数据[root@node1 ~]# cat LG&#x2F;test this is a test for LVM#扩容逻辑卷LV1，增加2G空间容量（从对应的卷组中划分空间容量）[root@node1 ~]# lvextend -L +2G &#x2F;dev&#x2F;V1&#x2F;LV1 Size of logical volume V1&#x2F;LV1 changed from 1.00 GiB (256 extents) to 3.00 GiB (768 extents). Logical volume V1&#x2F;LV1 successfully resized.[root@node1 ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert LV1 V1 -wi-ao---- 3.00g LV2 V2 -wi-a----- 1.00g root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g #使用resize2fs命令来进行确认增加容量，前面的步骤只是初步分配，还不能实际使用，#需要此步骤来确定实际分配使用[root@node1 ~]# resize2fs &#x2F;dev&#x2F;V1&#x2F;LV1 resize2fs 1.42.9 (28-Dec-2013)Filesystem at &#x2F;dev&#x2F;V1&#x2F;LV1 is mounted on &#x2F;root&#x2F;LG; on-line resizing requiredold_desc_blocks &#x3D; 1, new_desc_blocks &#x3D; 1The filesystem on &#x2F;dev&#x2F;V1&#x2F;LV1 is now 786432 blocks long.#xfs系统确认实际使用的命令#xfs_growfs &#x2F;dev&#x2F;VGtest1&#x2F;LVtest1#数据并没有受损[root@node1 ~]# cat LG&#x2F;test this is a test for LVM 缩减逻辑卷缩减逻辑卷的注意事项：1、查看逻辑卷使用空间状况2、不能在线缩减，得先卸载 切记3、确保缩减后的空间大小依然能存储原有的所有数据4、在缩减之前应该先强行检查文件，以确保文件系统处于一至性状态 #处于挂载状态的LV逻辑卷无法强制检查[root@node1 ~]# umount &#x2F;dev&#x2F;V1&#x2F;LV1 [root@node1 ~]# e2fsck -f &#x2F;dev&#x2F;V1&#x2F;LV1 e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information&#x2F;dev&#x2F;V1&#x2F;LV1: 12&#x2F;196608 files (0.0% non-contiguous), 21309&#x2F;786432 blocks#首先需要确定缩减逻辑卷到多大空间容量，-1G表示缩减1G大小，1G表示缩减至1G，再进行逻辑卷LV容量缩减[root@node1 ~]# lvreduce -L 1G &#x2F;dev&#x2F;V1&#x2F;LV1 WARNING: Reducing active logical volume to 1.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce V1&#x2F;LV1? [y&#x2F;n]: y Size of logical volume V1&#x2F;LV1 changed from 3.00 GiB (768 extents) to 1.00 GiB (256 extents). Logical volume V1&#x2F;LV1 successfully resized.#之后需要重新挂载逻辑卷 缩减磁盘空间发现物理磁盘空间使用不足，将其中一块硬盘或分区拿掉，避免磁盘浪费 1、pvmove /dev/sdb1 #将/dev/sdb1上存储的数据移到其它物理卷中 2、vgreduce VGtest /dev/sdb1 #将/dev/sdb1从VGtest卷组中移除 3、pvremove /dev/sdb1 #将/dev/sdb1从物理卷上移除 [root@node1 ~]# pvs PV VG Fmt Attr PSize PFree &#x2F;dev&#x2F;sda2 centos lvm2 a-- &lt;19.00g 0 &#x2F;dev&#x2F;sdb1 V1 lvm2 a-- &lt;5.00g &lt;4.00g &#x2F;dev&#x2F;sdb2 V2 lvm2 a-- &lt;15.00g &lt;14.00g &#x2F;dev&#x2F;sdc1 V1 lvm2 a-- &lt;5.00g &lt;5.00g &#x2F;dev&#x2F;sdc5 V2 lvm2 a-- &lt;15.00g &lt;15.00g &#x2F;dev&#x2F;sdd1 lvm2 --- 5.00g 5.00g #把sdb1磁盘分区的数据转移到其它磁盘上 [root@node1 ~]# pvmove &#x2F;dev&#x2F;sdb1 &#x2F;dev&#x2F;sdb1: Moved: 43.36% &#x2F;dev&#x2F;sdb1: Moved: 100.00% #把分区sdb1从VG卷组中移除[root@node1 ~]# vgreduce V1 &#x2F;dev&#x2F;sdb1 Removed &quot;&#x2F;dev&#x2F;sdb1&quot; from volume group &quot;V1&quot; #把sdb1分区从PV物理卷中释放出来[root@node1 ~]# pvremove &#x2F;dev&#x2F;sdb1 Labels on physical volume &quot;&#x2F;dev&#x2F;sdb1&quot; successfully wiped.[root@node1 ~]# cat LG&#x2F;testcat: LG&#x2F;test: No such file or directory#如果磁盘划分了多个分区，做成多个物理卷加入了卷组，那么可以能重复以上步骤，把所有的空间都从卷组和物理卷中释放，然后可以拿走这块磁盘做它用 重新把/dev/sdb1加入到V1中 [root@node1 ~]# pvcreate &#x2F;dev&#x2F;sdb1 Physical volume &quot;&#x2F;dev&#x2F;sdb1&quot; successfully created.[root@node1 ~]# vgs VG #PV #LV #SN Attr VSize VFree V1 1 1 0 wz--n- &lt;5.00g &lt;4.00g V2 2 1 0 wz--n- 29.99g 28.99g centos 1 2 0 wz--n- &lt;19.00g 0 [root@node1 ~]# vgextend V1 &#x2F;dev&#x2F;sdb1 Volume group &quot;V1&quot; successfully extended LVM快照[root@node1 LG]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 475M 0 475M 0% &#x2F;devtmpfs 487M 0 487M 0% &#x2F;dev&#x2F;shmtmpfs 487M 7.7M 479M 2% &#x2F;runtmpfs 487M 0 487M 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;mapper&#x2F;centos-root 17G 2.1G 15G 12% &#x2F;&#x2F;dev&#x2F;sda1 1014M 176M 839M 18% &#x2F;boottmpfs 98M 0 98M 0% &#x2F;run&#x2F;user&#x2F;0&#x2F;dev&#x2F;mapper&#x2F;V1-LV1 976M 2.6M 907M 1% &#x2F;appdata#利用LV1逻辑卷，快照形成一个备份的物理卷BackUp（逻辑卷快照功能）[root@node1 LG]# lvcreate -L 20M -n BackUp -s -p r &#x2F;dev&#x2F;V1&#x2F;LV1 Logical volume &quot;BackUp&quot; created.[root@node1 LG]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert LV1 V1 owi-aos--- 1.00g thirdBack V1 sri-aos--- 20.00m LV1 0.06 LV2 V2 -wi-a----- 1.00g root centos -wi-ao---- &lt;17.00g swap centos -wi-ao---- 2.00g [root@node1 LG]# mkdir &#x2F;tmp&#x2F;thirdUp [root@node1 LG]# mount &#x2F;dev&#x2F;V1&#x2F;thirdBack &#x2F;tmp&#x2F;thirdUp&#x2F; #把快照的逻辑卷挂载到目录上mount: &#x2F;dev&#x2F;mapper&#x2F;V1-thirdBack is write-protected, mounting read-only[root@node1 LG]# cat &#x2F;tmp&#x2F;thirdUp&#x2F;lvm this is the LVM test 删除LVM快照 [root@node1 ~]# lvremove &#x2F;dev&#x2F;V1&#x2F;backupDo you really want to remove active logical volume V1&#x2F;backup? [y&#x2F;n]: y Logical volume &quot;backup&quot; successfully removed 知识扩展知识扩展resize2fs命令resize2fs命令被用来增大或者收缩未加载的“ext2&#x2F;ext3”文件系统的大小。如果文件系统是处于mount状态下，那么它只能做到扩容，前提条件是内核支持在线resize。，linux kernel 2.6支持在mount状态下扩容但仅限于ext3文件系统。-d：打开调试特性；-p：打印已完成的百分比进度条；-f：强制执行调整大小操作，覆盖掉安全检查操作；-F：开始执行调整大小前，刷新文件系统设备的缓冲区如果是xfs文件系统，则需要使用xfs_growfs命令e2fsck命令e2fsck是检查ext2、ext3、ext4等文件系统的正确性。补充说明：e2fsck执行后的传回值及代表意义如下：0 没有任何错误发生。1 文件系统发生错误，并且已经修正。2 文件系统发生错误，并且已经修正。4 文件系统发生错误，但没有修正。8 运作时发生错误。16 使用的语法发生错误。128 共享的函数库发生错误。参 数：-a 不询问使用者意见，便自动修复文件系统。-b &lt;superblock&gt; 指定superblock，而不使用预设的superblock。-B &lt;区块大小&gt; 指定区块的大小，单位为字节。-c 一并执行badblocks，以标示损坏的区块。-C 将检查过程的信息完整记录在file descriptor中，使得整个检查过程都能完整监控。-d 显示排错信息。-f 即使文件系统没有错误迹象，仍强制地检查正确性。-F 执行前先清除设备的缓冲区。-l &lt;文件&gt; 将文件中指定的区块加到损坏区块列表。-L &lt;文件&gt; 先清除损坏区块列表，再将文件中指定的区块加到损坏区块列表。因此损坏区块列表的区块跟文件中指定的区块是一样的。-n 以只读模式开启文件系统，并采取非互动方式执行，所有的问题对话均设置以&quot;no&quot;回答。-p 不询问使用者意见，便自动修复文件系统。-r 此参数只为了兼容性而存在，并无实际作用。-s 如果文件系统的字节顺序不适当，就交换字节顺序，否则不做任何动作。-S 不管文件系统的字节顺序，一律交换字节顺序。-t 显示时间信息。-v 执行时显示详细的信息。-V 显示版本信息。-y 采取非互动方式执行，所有的问题均设置以&quot;yes&quot;回答。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[]},{"title":"Python爬虫大纲概述","slug":"Python_Crawler","date":"2019-10-21T04:37:03.000Z","updated":"2020-07-04T17:18:26.891Z","comments":true,"path":"2019/10/21/Python_Crawler/","link":"","permalink":"http://ymlog.cn/2019/10/21/Python_Crawler/","excerpt":"念两句诗天接云涛连晓雾，星河欲转千帆舞。仿佛梦魂归帝所，闻天语，殷勤问我归何处。","text":"念两句诗天接云涛连晓雾，星河欲转千帆舞。仿佛梦魂归帝所，闻天语，殷勤问我归何处。 基本原理爬虫的本质是：程序模拟浏览器，对服务器发起访问(requests请求过程)，服务器返回响应(response响应过程)。所以，一个简单的爬虫只有三步： 构造URL 对服务器发送请求 输出服务器返回内容 这里用一个实例，运行后可以看到输出了百度网页的源码(这里就不演示了)： import requests # requests是python爬虫最常用的请求库url = 'http://www.baidu.com' #1、指名要访问的网站response = requests.get(url) #2、使用requests的get方法请求网站信息print(response.text) #3、输出响应内容 所以，爬虫也都围绕这三步进行。1、构造URL，就是要爬的链接2、发起请求3、解析响应内容 构造URL可能有人会问，指定URL这么简单，为什么也要写，这里笔者给出一个实例说明：这是东方财富网的腾讯股票页面，如果我想要爬取这个页面的评价，那么我就需要知道评论的URL。 这个页面有94条评论地址，一共有196个这样的页，也就是我需要知道至少18,424‬个URL我才能把腾讯股票所有的评率全部爬下来，这显然是不现实的。那么我们是如何知道要爬页面的URL的呢？答案是：通过网站的内部逻辑构造URL。 通过Chrome开发者选项可以调出如下页面，指定一条评论链接，我们可以看到红圈画出来的内容:`/news,usaapl,880272132.html` 然后我们再点进去，看看这个站点的真正链接是什么。 可以看到，这个站点的真正链接是: http://guba.eastmoney.com/news,usaapl,880272132.html 而我们之前找到了/news,usaapl,880272132.html，这个站点的真正链接，就是在这段之前拼接：http://guba.eastmoney.com。 所以，我们只需要把一开始的网站爬下来，然后筛选出类似/news,usaapl,880272132.html这样的内容，然后再把它和http://guba.eastmoney.com拼接，就可以得到当前页面上所有评论的具体地址，这就是地址构造，也就是构造URL。 发起请求一个爬虫是否能成功将网页爬下来，完全取决于请求。现在网络上绝大部分的网站都有了反爬机制，能够拦截爬虫。 这里解释一下为什么要有反爬。爬虫抓取网页就相当于用户访问网页，在这期间，浏览器对服务器发起了一次访问。如果爬虫大量的抓取网页，比如在一分钟之内抓取了一万次网页，那么就相当于访问了服务器一万次，这样就会大量的占据服务器的资源，甚至大型分布式爬虫会使服务器崩溃。然而，人类是不可能做到10000次/min的访问量的(其实相当于一分钟内刷新一个网页10000次)。所以，越来越多的网站设计了反爬，将低访问量的人和高访问量的爬虫区别开来，让人能够正常访问，而爬虫则拒之门外。目前主要通过以下方式实现反爬： 识别用户的User-Agent 使用Ajax请求 使用JavaScript渲染内容 对IP进行访问控制 对URL进行加密处理 构造复杂的请求头(往往是请求头需要额外添加网站的其他参数，这些参数分布在网站的隐蔽角落，而且几乎毫无逻辑) 添加请求头这里笔者给出一个豆瓣电影榜的例子，首先用户需要先在浏览器中找到自己浏览器的请求头，具体操作如下： 打开浏览器 进入开发者模式，谷歌浏览器是按F12 Ctrl+R刷新页面 选择Network的选项 点击右边的任意一个 左边选择Headers，下拉可以看到User-Agent 将其复制到代码中即可，代码如下： import requestsurl = 'https://movie.douban.com/chart'# 添加请求头headers = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'&#125;response = requests.get(url,headers=headers) # 这里要把请求头送入到请求方法中print(response.text) 绝大多数网站，不加请求头，往往加载不了全部网页内容。 添加datadata和User-Agent的作用类似，都是用来伪装成用户的。服务器会根据有没有data和user-agent来判断是否是爬虫还是用户。 url='http://httpbin.org/get'data=&#123;'name':'germet','age':22&#125;response=requests.get(url,data=data)#或者是paramsprint(response.text) 克制Ajax和JavaScript使用selenium首先要安装selenium库，pip install selenium -i https://pypi.tuna.tsinghua.edu.cn/simple。其次，如果是用selenium打开Chrome，还需要安装ChromeDriver驱动。淘宝源ChromeDriver驱动链接，注意版本要和当前Chrome的版本一致。 http://npm.taobao.org/mirrors/chromedriver/ 目前Chrome支持的浏览器有Safari、FireFox、Chrome等，且都需要安装浏览器驱动。 selenium会自动打开浏览器，然后渲染出网页，再关闭浏览器，这样可以克制一切JavaScript渲染，如果想针对Ajax请求，可以用Selenium模拟点击效果，这里只介绍基础的用法。 from selenium import webdriverurl = 'https://movie.douban.com/chart'option = webdriver.ChromeOptions() # 添加Chrome打开的选项#option.add_argument('--headless') # 执行时不打开了浏览器，通常在没有面板的Linux服务器中会用到driver = webdriver.Chrome(options=option)driver.get(url) driver.close() #关闭浏览器 代理IP一个IP地址对服务器过于频繁的访问，会导致服务器屏蔽你的IP地址。爬虫通常使用代理IP池来处理自己IP被封的情况。 可以使用Github上已经写好的代理池 https://github.com/jhao104/proxy_pool url = 'https://movie.douban.com/chart'proxy=&#123; 'http':'http://127.0.0.1:9743', 'https':'https://127.0.0.1:9743'&#125;response=requests.get(url,proxies=proxy)print(response.status_code) 超时设置通常用于访问一些地方较远的网站，或者访问的网站当前过于繁忙，可以设置超时。一旦请求时间超过一定的值，服务器还没有返回响应，那么就直接退出。 import requestsfrom requests.exceptions import ReadTimeouttry: response = requests.get(url,timeout=0.2)except ReadTimeout: print('Timeout')print(response.status_code) 下载文件requests还可以用来下载各种文件，比如图片、音乐、视频等。这里用一个例子演示一下： 下载《雨幕》这首歌： import requestsurl='https://sharefs.yun.kugou.com/201910211352/d2b8f1ce854a7f4d01937583ee35b46e/G172/M00/0D/14/jJQEAF2hoIGATyZ4ADq0vjCqr7Q097.mp3'response = requests.get(url) # 这里要把请求头送入到请求方法中#保存到文件with open('雨幕.mp3','wb') as f: f.write(response.content) 解析网页解析网页一般用到的库有BeautifulSoup,PyQuery,re，BeautifulSoup又称之为bs4，要区别于之前的bs3。bs4和PyQuery类似，都是通过网页的节点(&lt;div&gt; …&lt;/div&gt; 这样的东西称之为结点)来定位内容的。 而re是直接匹配内容，更加灵活。下面是re匹配表，虽然多，但通常我们只需要用到 . * ?这三个符号。 re正则表达式，正则就是用一些具有特殊含义的符号组合到一起（称为正则表达式）来描述字符或者字符串的方法。或者说：正则就是用来描述一类事物的规则。（在Python中）它内嵌在Python中，并通过 re 模块实现。正则表达式模式被编译成一系列的字节码，然后由用 C 编写的匹配引擎执行。 元字符 匹配内容 \\w 匹配字母（包含中文）或数字或下划线 \\W 匹配非字母（包含中文）或数字或下划线 \\s 匹配任意的空白符 \\S 匹配任意非空白符 \\d 匹配数字 \\D 匹配非数字 \\A 从字符串开头匹配 \\z 匹配字符串的结束，如果是换行，只匹配到换行前的结果 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开始 $ 匹配字符串的结尾 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 匹配字符组中的字符 [^…] 匹配除了字符组中的字符的所有字符 * 匹配0个或者多个左边的字符。 + 匹配一个或者多个左边的字符。 ？ 匹配0个或者1个左边的字符，非贪婪方式。 {n} 精准匹配n个前面的表达式。 {n,m} 匹配n到m次由前面的正则表达式定义的片段，贪婪方式 () 匹配括号内的表达式，也表示一个组 [:alnum:] 字母和数字 [:alpha:] 字母 [:ascii:] ascii字符 [:blank:] 空白字符 [:cntrl:] 控制字符包括换行符、换页符、退格符 [:digit:] 数字 [:graph:] 非控制、非空格字符 [:lower:] 小写字母 [:print:] 可打印字符 [:punct:] 标点符号字符 [:space:] 空白字符 [:upper:] 大写字母 [:xdigit:] 十六进制数字 ^$ 匹配空行 &lt; 词首 &gt; 词尾 &lt;pattern&gt; 整个单词 重点 字符 含义 ？ 匹配0个或者1个左边的字符，非贪婪方式。 . 匹配任意字符，除了换行符。 * 匹配*号前的字符0次或多次。 .*? 的含义就是 非贪婪匹配前面任意字符 通常采用的组合 #re.complie写re表达式'''如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始。而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，在整体中进行匹配。'''parent = re.compile('&lt;div.*?页数:.*?&lt;/span&gt;(.*?)&lt;br/&gt;', re.S)#re.findall查找html的内容并和parent匹配，返回一个列表。result = re.findall(page_parent, html) 项目实战爬取豆瓣电影榜。这个会用到我们之前在发起请求 -- 添加请求头中写的内容，这里主要关注re解析的过程。 首选选中一个item，观察它在源码的什么位置，然后折叠源码。 折叠源码后，可以看到选中的这些都十分相似，判断一下可知，他们就是每一部电影的html源码。这样就得到了电影榜单的一般格式。 依次选取关键字，用来生成re表达式。我们选中了`table width,class=\"item\" class=\"nbg\" title`这些关键字。 所以，re表达式是： #用括号选出你需要的内容pattern = re.compile('table.*?class=\"item\".*?nbg.*?title=\"(.*?)\"',re.S) 选中的有些内容其实并不必要，我们就将它去除掉了。具体代码如下： import requestsimport reurl = 'https://movie.douban.com/chart'headers = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'&#125;#请求requestresponse = requests.get(url,headers=headers)html = response.text#解析pattern = re.compile('table.*?class=\"item\".*?nbg.*?title=\"(.*?)\"',re.S)result = re.findall(pattern,html)#打印print(result) 结果： 如果想要输出更美观，还可以添加一些字段处理等：","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://ymlog.cn/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"博客历史","slug":"History Of Blog","date":"2019-10-20T13:58:02.000Z","updated":"2020-07-08T12:28:28.475Z","comments":true,"path":"2019/10/20/History Of Blog/","link":"","permalink":"http://ymlog.cn/2019/10/20/History%20Of%20Blog/","excerpt":"念两句诗淡柔情于俗内，负雅志于高云。悲晨曦之易夕，感人生之长勤；同一尽于百年，何欢寡而愁殷！","text":"念两句诗淡柔情于俗内，负雅志于高云。悲晨曦之易夕，感人生之长勤；同一尽于百年，何欢寡而愁殷！ 在2019年10月20日之前，一直在使用叶落阁的主题。之后换到了Clic的主题，期间有一系列的报错导致Clic的主题不能部署在容器中，所以重构了网站结构，特此纪念。或许当某一天用不习惯Clic的主题，这篇文章就又会更新了。 叶落阁主题 https://github.com/yelog/hexo-theme-3-hexo 这个Hexo的内容是放在Linux主机中的，然后用NFS文件共享同步到Windows本地。只需在Windows本地编辑，即可上传。 Hexo容器生成命令： docker run -d --name my-hexo -p 80:4000 -v /Log/:/opt/hexo/ipple1986/source/_posts ipple1986/hexo 我还开启了weavescope监控，但由于端口暴露在外面，别人可以轻而易举的访问Linux主机和Docker容器，所以一般情况下选择禁用。 sudo curl -L git.io/scope -o /usr/local/bin/scopesudo chmod a+x /usr/local/bin/scopescope launch 文件传输模式 Clic主题 https://github.com/Siricee/hexo-theme-Chic#introduction 在使用Hexo这个主题时，我是将其部署在docker中，但docker中hexo的版本很低，没有办法，只好换了方式部署。 [root@~ipple1986]# hexo -vhexo: 3.3.7hexo-cli: 3.1.0node: 10.16.3 文件迁移过程： 现在是将hexo生成静态网页，然后用Nginx部署。在windows本地写博客，然后把写好的博客推送到Github上，然后在服务器端写一个脚本，每天凌晨一点半下载Github上的静态页面，然后存储到本地/usr/share/nginx/html/blog下。这样写有两点好处 一是直接访问Github托管的网站，用户速度会很慢，影响使用体验 而是可以用Nginx，对访问进行监管和记录，达到学习Nginx的目的。 拉取Github静态网站的脚本： git clone https://github.com/ArchKS/ArchKS.github.io.git blogrm /usr/share/nginx/html/blog -rfmv blog /usr/share/nginx/html/nginx -s reload 定时任务: [root@niki important]# crontab -l30 1 * * * bash &#x2F;root&#x2F;important&#x2F;blog.sh Pure主题2019年12月25日，圣诞节，换了个主题，以前用的Chic的主题不用了，换成了pure的主题，但工作原理和流程和上面的那个一样，这里就不过多赘述了。先上图纪念一下以前用的那个主题： 也打算精简一下我的博客内容了，以前是什么笔记都网上放，现在尽量放一些整理的东西。 Butterfly主题 可以留下自己的个性签名，当时用的是&lt;判天地之美，析万物之理，成一家之言&gt; 可以用自己的图标，每一条blog都可以配封面 整体不错，但用的时间长了，想换换口味 fun主题 比较简洁，喜欢它的时间线 很直观，没有太多的动画渲染 有top置顶功能","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[{"name":"history","slug":"history","permalink":"http://ymlog.cn/tags/history/"}]},{"title":"Vim快捷键","slug":"Vim_ShotCut","date":"2019-10-10T13:13:51.000Z","updated":"2020-07-04T17:18:09.468Z","comments":true,"path":"2019/10/10/Vim_ShotCut/","link":"","permalink":"http://ymlog.cn/2019/10/10/Vim_ShotCut/","excerpt":"念两句诗林花谢了春红，太匆匆。无奈朝来寒雨，晚来风。胭脂泪，相留醉，几时重。自是人生长恨，水长东。","text":"念两句诗林花谢了春红，太匆匆。无奈朝来寒雨，晚来风。胭脂泪，相留醉，几时重。自是人生长恨，水长东。 j：向下滚动一点 k：向上滚动一点 gg：到页面最底部 G：到页面最底部 d：向下翻一屏 u：向上翻一屏 常用命令 1、批量加注释ctrl + v，进入可视块模式 移动光标，选中的位置会有高亮显示 shift + i，进入 insert 模式 输入// esc2、批量解注释解注释 光标置于行首 ctrl + v，进入可视块模式 移动光标，选中的位置会有高亮显示 按d3、删除命令行模式：:%d 删除所有内容 末行模式：dG：删除光标下所有内容 dw：删除一个单词4、移动gg：光标移到第一行 G：光标移到最后一行 9k 向上移动9次，同理num hjkl5、退出ZZ 保存并退出，行末模式6、括号跳转%7、滚屏 CTRL-U：窗口向上滚动半屏CTRL-D：窗口向下滚动半屏CTRL-F：窗口向下滚动全屏CTRL-B：窗口向上滚动全屏zz ：窗口正中zt ：将最下面的窗口调到最上面zb ：将最上面的窗口调到最下面 8、查找/string #查找后 ‘#’ ：往上查找 ‘*’：往下查找 /the\\&gt; 精确查找，确保以&apos;the&apos;结尾。&apos;\\&lt;&apos;:开头，&apos;\\&gt;&apos;：结尾9、多屏编辑vim a.sh b.sh -O #垂直 Ctrl+w：跳转 qall!:前置退出所有10、替换s/{word1}/{word2}/g : 将光标所在行的所有word1替换为word2 %s/{word1}/{word2}/g : 将所有word1替换为word2 g表示全局替换 i表示大小写不敏感，I表示大小写敏感 如： %s/sudo/su/ig行末模式a 光标所在下一个位置插入 A 光标所在行末尾插入 i 光标所在位置插入 I 光标所在行首插入 o 光标所在下一行插入 O 光标所在上一行插入 y 复制 p 粘贴 dd 删除一行 u 撤销命令模式#设置行号 set nu #取消行号 set nonu #下划线 set cursorline #Tab=2个空格 set ts=2 #忽略大小写 set ignorecase #不忽略大小写 set noignorecase输入模式定制vim 配置文件：全局有效全局：/etc/vimrc个人：~/.vimrc行末：对当前进程有效 相关配置 行号： 显示：set nu 取消：set nonu括号匹配： 匹配：set showmatch 取消：set unshowmatch自动缩进： 启动 set ai 取消： set noai高亮搜索： 启动 set hlsearch 取消 set nohlsearch语法高亮 启动 syntax on 取消 syntax off忽略大小写 启动 set ic 取消 set noic获取帮助： help","categories":[],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"OS操作系统","slug":"Operation System","date":"2019-08-22T06:45:18.000Z","updated":"2020-07-04T17:18:50.506Z","comments":true,"path":"2019/08/22/Operation System/","link":"","permalink":"http://ymlog.cn/2019/08/22/Operation%20System/","excerpt":"念两句诗烟花巷陌，依约丹青屏障。幸有意中人，堪寻访。且恁偎红倚翠，风流事，平生畅。青春都一饷。忍把浮名，换了浅斟低唱。","text":"念两句诗烟花巷陌，依约丹青屏障。幸有意中人，堪寻访。且恁偎红倚翠，风流事，平生畅。青春都一饷。忍把浮名，换了浅斟低唱。 简介Operation System 是系统资源的管理者，在有限的资源内，通过算法，完成相对合理的分配。在复杂的硬件环境中，通过封装，完成动作指令的抽象化。这一切的基石，则是密集的数据结构和算法。 相对合理体现在： 调度算法实现的低用户响应时间和紧急事件处理 虚拟技术实现多用户登录 IO设备控制器尽可能减少CPU调度 文件目录系统屏蔽了数据写入物理块的底层细节 命令接口、图形接口的封装 相关概念 并发：在多台处理器上同时处理多个任务 并行：在一台处理器上宏观上同时处理多个任务，微观上一个时间段只处理一个任务 并发进程的制约关系：同步和互斥 同步：同步亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作。 互斥：互斥亦称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待, 当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。 异步：异步是进程之间彼此独立，在等待其他进程的运行时，本进程继续做自己的事，不需要等待其他进程完成后再工作。 临界资源：一次仅允许一个进程使用的资源 管程：管程在功能上和信号量及PV操作类似，属于一种进程同步互斥工具 符号链接：是文件共享的一种方式，允许一个文件或子目录有多个父目录，但其中仅有一个座位主父目录，但其他几个父目录都是通过符号链接方式与之相连。 索引结点实现文件共享：在文件目录中只设置文件名以及指向相应索引结点的指针，源文件删除后，会出现悬空指针。 工作集：是指在某段时间间隔 ∆ 里，进程实际要访问的页面的集合。 抖动：如果多道程度过高，页面在内存与外存之间频繁调度，以至于调度页面所需时间比进程实际运行的时间还多，此时系统效率急剧下降，甚至导致系统崩溃。这种现象称为颠簸或抖动(thrashing) 相关技术 虚拟技术 复用技术 中断技术 封装技术 相关算法 双标志后检查法 记录型信号量机制 先来先服务算法(First Come First Serve) 短作业优先(Shortest Job First) 高响应比优先(Highest Response Ratio Next) 时间片轮转调度(Round Robin) 优先级调度算法 多级反馈调度算法 一个进程从被创建到终止，其中不得不说的故事&emsp;&emsp; 当我们打开一个程序。这个程序就会被执行。因为CPU速度非常快，普通硬盘的读写速度跟不上CPU的速度，所以我们会把程序调入内存中执行，这样就产生了进程。 &emsp;&emsp; 如果我们同时打开多个应用，就会产生多个进程，在宏观上每一个进程在CPU内同时执行(并发)，微观上每个进程在CPU内交替执行，同一个处理机同一时间内只能执行一个进程(并行)。 &emsp;&emsp; 由于人们的需求不一样，希望有些应用执行的更快一点，就此产生了进程的优先级。但在处理机调度算法中，优先级只是决定一个进程能够被分到多少运行时间的指标之一，还有其他的指标，诸如：CPU利用率(CPU忙碌的时间 / 作业被处理所需要的总时间)，系统吞吐量(单位时间内完成作业的数量)，周转时间(作业从被提交给系统到最后完成所用时间)，响应时间(用户提出请求到首次响应所用的时间，简而言之，就是你点击一个应用，系统过了多个才给你打开)，这些也是衡量一个处理机调度算法优劣的指标。 &emsp;&emsp; 截止到现在，你还是只点了一下应用，电脑界面还什么都没有发生。当你点下鼠标的那一刻，该应用(下文全部用作业来代替)会被装入到内存，但是并不是全部被装入内存，比如打开英雄联盟，它只会将加载页面放入内存，而不会把对战地图放入内存，这样有一个好处就是，原本8G的League of Legends,现在只需要不到4G就可以带动了。 &emsp;&emsp;当一个作业被装入内存，会有模块链接的相关步骤，但现代操作系统一般采用运行时动态链接，即程序执行过程中需要改模块时，才对它进行链接。而在以前，则采用静态链接，即在程序运行之前，先将各个目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开。所以这一步不再是程序执行的第一步了，写到这，程序执行的第一步即将开始，那就是动态重定位装入。 &emsp;&emsp;装入就是将作业装入内存，其中涉及到很多东西，比如内存如何分配给作业、作业执行完之后如何回收内存、当作业太大时内存如何扩展等。先看最开始的——如何分配内存给作业。 &emsp;&emsp;现在操作系统一般采用离散分配的方式，就是将作业拆成很多块，同时将内存拆成很多块，按照非连续的方式，将作业放入内存。这样可以产生较少的空间碎片。一般的分配机制采取分页存储管理、分段存储管理或者段页存储管理。这时候，我们的LOL的一部分(可能是登录界面)，已经被拆成很多块，塞到内存页中了。下一步就是交给CPU执行了，但其实还缺少了一步——进程创建。我们一直在将它如何进入内存，却忘了给它创建进程，但现在也为时不晚。 &emsp;&emsp;进程创建首先要向操作系统申请空白的PCB(Process Control Block)，获得唯一标识符UID，然后是分配资源，毕竟进程是系统资源调度的最小单位，而线程则是处理机调度的最小单位。接着初始化PCB信息初始化处理机状态信息 ：使程序计时器指向程序的入口地址，使指针指向栈项，初始化处理机控制信息 ：设置进程状态为就绪或者静止就绪，优先级默认为最低。最后终于可以将进程插入就绪队列，只等处理机调度了。虽然程序已经做了这么多事，但现在用户还是什么也看不到，当用户第一次看到反应的时候，就是用户响应时间(前面提到过的处理机调度算法的指标) &emsp;&emsp;这个时候可以谈一谈处理机如何调度进程的，这个就是进程切换。得益于优秀的数据结构，处理机实现进程切换只需要把PCB(进程控制模块)中的相关数据进行修改。比如一个进程从运行态切换为阻塞态，处理机会根据进程标识符UID，读取进程状态，将进程PCB中的状态信息修改从运行修改为阻塞，同时将运行环境信息存入该进程的PCB中，再把该进程移到阻塞队列队尾，选择下一个就绪队列的进程，读取其PCB中CPU的运行环境，然后恢复运行环境，开始执行这个进程，类似同时和多个人聊微信时的状态。这里会产生一个问题，进程并不是平等的，操作系统会希望一些进程执行的更快，一些则无所谓。这就像同时和多个人聊微信，对女朋友所化的时间总是会比其他人多，因为有一些人、或是进程的优先级总是高于其他。这就涉及到了处理机调度算法，这里只介绍两种算法。 &emsp;&emsp;处理机调度算法是为了更高的I/O，更快的响应时间，以及更多的CPU利用率等等。 时间片轮转调度算法(Round Robin) &emsp;&emsp;这种算法把时间切片，比如在一分钟内有三个进程运行。处理机划分时间片为100ms，每隔100ms切换一次进程。 000~100ms：执行进程A1 100~200ms：执行进程A2 200~300ms：执行进程A3 300~400ms：执行进程A1 400~500ms：执行进程A2 500~600ms：执行进程A3 ........ 多级反馈调度算法 &emsp;&emsp;(说实话，写到这里我已经不想写了，为什么我们的程序还没执行) &emsp;&emsp;该算法划分了多个优先级就绪队列以及多种时间片大小，优先级越高，时间片越小。当一个进程产生时，先到优先级最高的就绪队列执行一个时间片，如果作业没有执行完，那么就进入下一个优先级次一级的队列，这时候进来的进程仍然送往第一优先级队列，执行一个时间片，然后送往第二优先级队列。如果此时没有进程，则执行第二优先级队列。如果作业还没有执行完，则放入第三优先级队列。 总结： 1、设置多级就绪队列，各级队列优先级从高到低、时间片从小到大 2、新进程到达时，先进入一级队列，运行结束后进入下一级队列队尾，到了最下一级，就重新放回该队列队尾 3、只有第k级为空，才会为k+1级队列分配时间片优点： 1、对各类进程相对公平（FCFS的优点） 2、每个进程到达都可以很快的得到响应（RR优点） 3、短进程只用较少的时间就可以完成（SPF优点） 4、不必实现估计进程的运行时间（避免用户作假） 5、灵活的调整对各类进程的偏好程度，I/O密集型进程（将因I/O阻塞的进程重新放回队列）&emsp;&emsp;我们的游戏此时还在就绪队列，可能就在多级反馈调度算法的第一个队列中。之后，该进程就会被安排上处理机执行。在执行的过程中还会发生一件事，比如你进入了游戏，需要加载地图界面，这时候，操作系统就会发生缺页中断，缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。缺页中断、请求调页和页面置换是实现分页请求功能的三个步骤。 请求分页也称为页式虚拟存储管理，是建立在基本分页基础上，为了能支持虚拟存储器功能而增加了请求调页功能和页面置换功能其基本思想是：在进程开始运行之前，不是装入全部页面，而是装入部分页面，之后根据进程运行的需要，动态装入其他页面，当内存空间已满，又需要装入新的页面时，根据某种算法淘汰某个页面，以便装进新的页面。&emsp;&emsp;实现请求分页，就需要解决两个问题——调出和调入。调出调哪里的页面？ 调出 现代操作系统一般采用可变分配全局置换，进程缺页时，只允许该进程在内存的页面中选择一页换出，这样就不会影响其他进程运行，如果该进程在运行过程中频繁的中断，系统再为该进程分配若干物理块。调入 将请求分页系统的外存分为两步分，用于存放文件区和用于存放对换页面的对换区。通常，对换区采取连续分配的方式。如果系统有足够的空间，可以全部从对换区调入所需页面。如果系统缺少足够的对换区空间，这时，凡是不会被修改的文件，都直接从文件区调入；而当换出这些页面时，由于未被修改，所以不必再将他们换出。对于那些会被修改的文件，则将他们调出时，便调到对换区，需要时，再从对换区调入。页面调入的过程 --程序所要访问的页面不在内存 --CPU发出缺页中断 --中断处理程序保留CPU环境，分析中断原因，转入中断处理 --查号页表，得到该页的外存地址 判断 IF {内存能容纳新页}: 启动I/O,将所缺页调入，并修改页表 ELSE {内存满了}: 按照某种置换算法，从内存中选取一页准备换出 判断 IF {准备换出的这一页没有被修改过}: 不必写入磁盘 ELSE {修改过}: 则必须写入磁盘 --然后把所缺页调入内存，并修改页表中相应的值。&emsp;&emsp;以上实现了操作系统的虚拟化存储，以便于去执行那些内存大的程序。当操作系统产生了一个作业的执行结果，它会将执行的结果通过I/O设备传输给用户，简而言之就是屏幕。那么操作系统是如何通过屏幕让用户看到的呢？而且我们玩的过程中所敲的QWERDF是如何被操作系统识别的呢？这个就设计到了操作系统的IO管理。I/O管理系统可以让我们不用关心一个当我们敲下一个字符的时候，计算机是怎么接受、怎么处理以及怎么显示在我们希望它显示的位置，但学习计算机一定会了解I/O管理系统。 &emsp;&emsp;一般I/O设备是不会直接和CPU进行通信的，因为这样会大量占用CPU的资源，总不可能你在键盘上输入一个字符，就直接通过I/O设备进入到CPU中。为了提高CPU的利用率，I/O系统在I/O设备和CPU通信之间设置了中间件，这就是设备控制器 &emsp;&emsp;键盘鼠标等输入输出设备现将内容传输给设备控制器的缓冲区，缓冲区积累一定的量之后，由设备控制器向CPU发送一个中断指令，CPU保存其运行环境，然后和设备控制器进行通信。至此，你所敲下的信息被操作系统所认知。接下来就是CPU将接受到的信息进行处理，将最终结果返还给用户，下面是处理过程。 &emsp;&emsp;操作系统是一个庞大的进程合集，一个进程需要将自己的数据传输给其他进程，比如说当你在网页上复制一段下载链接时，后台的迅雷就会自动跳出来。这就是进程间通信，通俗一点就是进程间信息的传递。进程通信存在同步(同步和互斥)和异步两种方式。而进程间通信的具体实现主要是以下三种方式： 1、共享存储 设置一个共享空间 互斥的访问共享空间 两种方式：基于数据结构、基于存储区的共享2、管道通信 设置一个特殊的共享文件（管道），其实就是一个缓冲区 一个管道只能实现半双工通信 实现双向同时通信要建立两个管道 各进程要互斥的访问管道 写满时，不能再写，读空时，不能再读 没写满，不能读，没读空，不能写3、消息传递 传递结构化的消息（消息头/消息体） 系统提供“发送/接受原语” 两种方式 直接通信方式：消息直接挂到接收方的消息队列里 间接（信箱）通信方式：消息先发到中间体（信箱） &emsp;&emsp;通过进程间通信，就可以将消息传递给其他程序，其他程序再讲消息传递给设备控制器，设备控制器将数据输出到屏幕，至此一个基本的操作系统成型。 &emsp;&emsp;最后一点是关于文件系统的，文件系统规定了文件存储的格式，其同样封装了文件存储在磁盘上的细节，只留给用户图形接口来对文件进行wrx等操作，其内部实现了对文件的共享和保护，常见的文件系统有ext3、NFS、exfat等。 &emsp;&emsp;文件目录是一种数据结构，用于表示系统中的文件以及其物理地址，供检索时使用。文件目录实现了“按名存取”，“提高了对文件的检索速度”，“实现了文件共享”，“允许文件重名”，这一切主要通过定义它的数据结构FCB来控制。 FCB主要信息： 基本信息：文件名、物理地址 存取控制类：存取权限 使用信息：建立时间、修改时间、打开文件的进程数&emsp;&emsp;文件描述信息单独形成一个称为索引结点的数据结构，在文件目录中，每个目录项仅由文件名和指向该文件名所对应的结点指针所构成，文件索引表： 文件名 指针 Name1 Point1 Name2 Point2 Name3 Point3 &emsp;&emsp;这些索引表最终构成了简单的文件目录，单级文件目录、两级文件目录、树形目录结构。我们的文件、程序、应用等一系列的数据就存放在由格式化的文件系统构成的目录下，当程序执行时，磁盘通过算法读取到相应的信息，然后是内存调入(地址映射，重定向，分页管理，页面置换)，接着被处理机(CPU)执行，其间会产生很多中断，当执行完成之后，操作系统通过IO管理系统将结果发送到屏幕。 &emsp;&emsp;然而，一切到这里才刚刚开始，这个操作系统的网络部分还没有浮出水面….. 文件管理系统应该实现按名存取 文件存储空间的管理 – 分配和回收 实现文件名到物理地址的映射 实现对文件的操作–建立、删除、读写、目录 实现文件共享和文件保护 提供操作文件的接口、包括命令、程序、菜单 Operation System安全机制 标识与鉴别 访问控制 最小权限管理 可信通路 安全审计 Questions！进程？ 什么是进程？ 进程的特性？ 如何控制和产生一个进程？ 如何控制和调度多个进程？ 进程死锁怎么办，怎么避免？ 进程状态转换的本质是什么，进程转换过程中做了哪些操作？ 进程有哪些状态？ 进程为什么会状态转换？ 怎样避免多个进程运行的时候不产生混乱？ 什么是临界资源？进程如何访问临界资源？ 进程互斥算法？ 两个或者多个进程间如何通信？ 为什么要产生线程？ 线程和进程的区别？ 线程有哪些好处？ 什么是管程？ 为什么要引入管程，管程有哪些好处？CPU？ 什么是CPU？CPU能干什么？ 什么是调度？调度有哪几种？ 什么时候进行调度？ 怎么调度？ 怎么评价一个调度算法的好坏？ 早起调度算法与交互式系统调度算法有什么区别？ 列举几种常见的CPU调度算法，并描述其实现机制？内存？ 什么是内存？内存有什么用？ 一台电脑内存4G是什么意思？ 内存管理是如何完成地址映射的？ 程序是如何进入内存的？ 内存是如何分配和回收空间的？ 内存分配回收空间有哪几种算法，各个的优缺点是什么？ 内存的连续分配和非连续分配是什么？ 分页存储的基本原理？ 分页存储和分段存储有什么不同？ 用什么样的数据结构记录系统已经分配的内存、以及系统剩余的内存？ 内存空间的扩展是如何实现的？ 内存保护是什么？有什么作用？怎么实现的？怎么产生的？虚拟存储机制？ 什么是虚拟存储？为什么会有虚拟存储？ 怎样实现虚拟存储？ 缺页中断是什么？ 页面是什么时候调入？ 页面是从哪里调入？ 如何评价一个页面置换算法的好坏？ 页面置换是如何置换的？ 页面置换的算法？ 什么是抖动和工作集？I/O系统？ 为什么要有输入输出系统？ 输入输出系统是怎么产生的？ I/O系统的层次结构模型是什么样的？ 设备控制器是什么？ 设备控制器有什么用？ 中断机构和中断处理程序？ 设备驱动程序是什么？ 缓冲区的引入有什么好处？ 有哪几种缓冲区？ 磁盘存储是什么？ 磁盘存放数据按照什么格式？机械硬盘是什么格式？固态硬盘是什么格式？ U盘存储原理？ 怎样衡量一个磁盘调度算法？ 有哪些是磁盘调度算法？如何实现？文件管理系统？ 为什么会产生文件系统？ 文件有什么数据结构？ 这些数据结构能支持文件完成哪些动作？ 什么是目录？ 为什么会产生目录？ 目录有什么样的数据结构？ 目录存放在磁盘的什么地方？ 文件和目录是怎么建立联系的？ 文件共享是如何实现的？ 文件保护是如何实现的？ 其他任何程序都必须满足结构性，以便于外部或内部对其rwx","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://ymlog.cn/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"禅","slug":"One Day For Zen","date":"2019-08-19T16:00:00.000Z","updated":"2020-07-04T17:16:54.219Z","comments":true,"path":"2019/08/20/One Day For Zen/","link":"","permalink":"http://ymlog.cn/2019/08/20/One%20Day%20For%20Zen/","excerpt":"念两句诗莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也无晴","text":"念两句诗莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也无晴 &emsp;&emsp; 释迦牟尼原名乔达摩·悉达多，是古印度迦毗罗卫国（今尼泊尔）的太子，悉达多太子天资聪慧，长到12岁时，就已经掌握了当时印度最高的学问，16岁时，娶了表妹耶输陀罗为妻。 &emsp;&emsp; 他有一次驾车出城游玩，在经过东、南、西三座城门时，分别见到了人类老、病、死的三种状态，于是认识到所有人都有不可逃避的痛苦。后来当他在经过北门，看到一位游行的苦行僧时，决定奉行这一修行方法，通过苦修摆脱命运的枷锁。 &emsp;&emsp; 然而现在却时常看到世人烧香拜佛，以求富贵长乐，殊不知，这正是佛所放弃的东西。 &emsp;&emsp; 释迦摩尼历经六年的苦修，身体骨瘦如柴，却依然没有找到解脱的方法。无奈中，释迦摩尼来到菩提迦耶的一棵毕波罗树下，经过数天苦思，终于获得了彻底的觉悟，立身成佛，号称释迦牟尼。明朝开始汉地还尊称他为如来佛祖或佛祖。 &emsp;&emsp;释迦摩尼在此后的一生一直在弘扬佛法，直到80岁涅槃于拘尸那城帕瓦村旁的小树林里。 &emsp;&emsp;大梵天王在灵鹫山请佛讲法，并赠佛一朵金色的波罗花。佛欣然答应，高升法座，却持花不语，众弟子正纳闷，唯有摩诃迦叶破颜微笑，佛祖随即宣布：我有正法眼藏，涅槃妙心，实相无相，微妙法门，附嘱摩诃迦叶。这就是禅宗所说的“拈花微笑”，摩诃迦叶也就成为了印度禅宗的初祖。 &emsp;&emsp;法脉迭传至第二十八祖菩提达摩祖师，达摩祖师秉承师父般若多罗尊者的嘱咐，来到中国弘法，成为中国禅宗初祖。之后便有梁武帝见达摩的那一段对话。 帝问曰：“朕即位以来，造寺写经，度僧不可胜纪，有何功德?” 祖曰：“并无功德” 帝曰：“何以无功德?” 祖曰：“此但人天小果有漏之因，如影随形，虽有非实。” 帝曰：“如何是真功德?” 祖曰：“净智妙圆，体自空寂，如是功德，不以世求。” 帝又问：“如何是圣谛第一义?” 祖曰：“廓然无圣”。 帝曰：“对朕者谁?” 祖曰：“不识”。 帝不领悟。祖知机不契，是月十九日，潜回江北。 翻译一下就是： 梁武帝问达摩：“我继位以来，修建了那么多寺庙超了那么多经书，帮助的僧人数都数不过来，我又没有什么功德？” 达摩：“并没有功德” 梁武帝说：“为什么没有功德？” 达摩：“这些只是世间的福德，做善事只有福德，没有功德，因此只能得到因果福报，倘若不能证明自己内心的自性，即是无功德。” 梁武帝：“什么才是真功德？” 达摩：“功德是自己修行的境界，不必向世间寻求” &emsp;&emsp;后来梁武帝没听懂，达摩知其没有机缘，便走了，达摩走后，梁武帝告知他的师父志公禅师，志公禅师立即对陛下说：达摩大师是个高人。梁武帝听师傅这么一说，立刻派众多兵马，急急追赶，一定要把达摩大师请回来，兵马追到江边，却见达摩大师抛出一根芦苇，掷在江中，脚踏芦苇渡江到了洛阳，住在嵩山少林寺，面壁九年，深入禅定。后来古人写了一付对联：“一苇渡江何处去，九年面壁待人来。”，这就是达摩一苇渡江的故事。 &emsp;&emsp;达摩在嵩山少林寺面壁期间，有很多信众请求达摩祖师收他们为徒，但达摩祖师一直没有收徒。有一天下了一夜的雪，达摩祖师早上醒来，推开房门，突然发现门前站立着一个人，地上的积雪已经没过那个人的膝盖。这个人叫神光，即将成为禅宗二祖。 达摩问：你怎么会在这里？ 神光：希望您能收下我，让我做您的弟子。 达摩：你这样是徒劳的，我不会收徒弟，你走吧。 神光没有离开，仍然苦苦哀求达摩 达摩忽然心念一动，对神光说：我可以收你为徒，但是要等到天降红雪的那一天。 但此时白雪纷飞，有哪里会有什么红雪。 神光问：只要天降红雪，你就会收我为徒？ &emsp;&emsp;达摩点点头，神光没再说一句话，慢慢拔出腰间的戒刀，从腋下向上用力砍下自己的左臂。一瞬间，他的左臂飞上天空，无数红色的血滴喷涌而出，把飞扬的雪花染得鲜红，落到地上。 “现在已经天降红雪，您可以收我为徒了吧！”神光在晕倒之前用尽最后一丝气力问道。 &emsp;&emsp;达摩祖师被神光的这一举动震惊了，也被他所感动，遂收下神光为徒。这就是“断臂求法”的故事。后来神光该法号为慧可，成为禅宗第二代祖师。 &emsp;&emsp;这些事件都发生在公元400年~公元600年，于此同时，还发生了一件不大也不小的事，却影响了后世千百年来僧人的饮食。那就是梁武帝禁止僧人食肉。 &emsp;&emsp;原本和尚是忌荤不忌腥的，荤在古代就是指葱、蒜、韭等有特殊气味的蔬菜，而腥就是肉类。这也是从印度带过来的传统，因为印度的和尚是需要化缘的，而不是自己做饭。可能有些人会觉得这是和尚懒，我也是这么觉得的，但佛经里面会给出两种解释： 一是通过化缘去除分别心，人因为有了分别心，就会去比较，有了比较就会有利害得失，有了利害得失就会产生烦恼。如果我们自己做饭，我们可以决定今天吃我们喜欢吃的东西，这就产生了分别心。如果是去化缘，别人给什么就吃什么，而且不管是山蒸海味还是粗茶淡饭吃到嘴里都是一个样，不会因为今天吃得好而高兴，也不会因为今天吃的差而埋怨，内心永远有一种长存的喜悦，不应外部世界的改变而改变。 二是佛教讲究布施，就是帮助别人。不仅仅是自己帮助别人，还要让别人能够帮助别人，人人助人为乐。化缘也就给别人一个帮助他们的机会。&emsp;&emsp;梁武帝颁布法令禁止僧人食肉，给出的理由是佛教应当反对杀生，但实际上是因为财政负担太重，吃不起。僧人不需要种田，所以就没有赋税，国家从他们身上捞不到钱，每年修建寺庙还要倒贴钱，又怎么会让这些僧人吃顿好的。也正是因为和尚不用交赋税以及其提倡的众生平等，导致佛教和皇权的矛盾愈发激烈，但又因为统治者希望通过佛教来稳定人心，让世人都变成不会作乱的傻瓜，故而又和佛教十分亲密。如此不难理解，历史上皇权与佛教之间种种的爱恨别离。 滚滚长江东逝水，浪花淘尽英雄。是非成败转头空。青山依旧在，几度夕阳红。 白发渔樵江渚上，惯看秋月春风。一壶浊酒喜相逢。古今多少事，都付笑谈中。&emsp;&emsp;随着佛教矛盾和皇权矛盾的激烈，唐代禅师百丈怀海对禅宗进行了教规改革，制定清规（后称《百丈清规》）。提倡劳动，亲自躬耕，力行倡导“一日不作，一日不食”，把印度僧侣托钵乞食的传统，改为中国式的自食其力。这也是中国禅宗禅院的诞生，百丈怀海也是慧能的三世法孙，禅宗的第四代宗师。 清晨入古寺，初日照高林。 曲径通幽处，禅房花木深。 山光悦鸟性，潭影空人心。 万籁此都寂，但余钟磬音。 &emsp;&emsp;怀海禅师年事已高，有一次，弟子体谅怀海禅师年迈，将怀海禅师的锄头等耕田工具藏起来，怀海禅师那天被迫无法工作，而当天，怀海禅师也拒绝进餐。从此，再也没有人敢阻止怀海禅师工作了。 &emsp;&emsp;如果说其他佛教的分支是对佛，对西方净土，或者是自己的皈依和醒悟，那么禅宗则更加看重现实的世间。六组慧能也曾说： 佛法在世间，不离世间觉， 离世觅菩提，恰如求兔角。布袋和尚有诗言： 手捏青苗种福田，低头便见水中天。 六根清净方成稻，原来退步是向前。和尚种水稻亦能参悟佛法，这不就是佛法在世间，不离世间觉吗。 船子和尚有诗言： 千尺丝纶直下垂，一波才动万波随。 夜静水寒鱼不食，满船空载明月归。&emsp;&emsp;及时没有钓到鱼，心情依然很好，虽是一无所获，却是满载而归。这是别人的注释，我才疏学浅，不知道他满载而归悟道了什么佛法，然虽不知意，心向往之，此为迷信。 &emsp;&emsp;没有了解佛教，没有明白什么是佛法而去相信的，我们称之为迷信，这个适用于任何事，比如一个“专家”说了吃什么什么好，但你并不知道为什么吃这个身体就会变好，此也为迷信。还有一种，没有了解佛教，就说佛教怎么怎么糊弄人，此为不信。就像是你没有接触过一个人，只凭社会对他的评价，就说这个人怎么怎么样，此为乌合之众。 细细碎碎初祖达摩，二祖慧可，三祖僧璨，四祖道信、五祖弘忍、六祖慧能 《丛林要则》 丛林以无事为兴盛。修行以念佛为稳当。 精进以持戒为第一。疾病以减食为汤药。 烦恼以忍辱为菩提。是非以不辩为解脱。 留众以老成为真情。执事以尽心为有功。 语言以减少为直截。长幼以慈和为进德。 学问以勤习为入门。因果以明白为无过。 老死以无常为警策。佛事以精严为切实。 待客以至诚为供养。山门以耆旧为庄严。 凡事以预立为不劳。处众以谦恭为有理。 遇险以不乱为定力。济物以慈悲为根本。 ——百丈禅师 百丈清规偈 旋岚偃岳而常静，野马飘风而不鼓。 山河竞注而不流，日月历天而不周。 空手把出头，步行骑水牛。 人在桥上过，桥流水不流。 似僧有发，似俗脱尘。 做梦中梦，悟身外身。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://ymlog.cn/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Python实现ARP欺骗屏蔽局域网","slug":"Python_ARP_SPoof","date":"2019-07-27T12:20:53.000Z","updated":"2020-07-04T17:18:31.606Z","comments":true,"path":"2019/07/27/Python_ARP_SPoof/","link":"","permalink":"http://ymlog.cn/2019/07/27/Python_ARP_SPoof/","excerpt":"念两句诗我报路长嗟日暮，学诗谩有惊人句。九万里风鹏正举。风休住，蓬舟吹取三山去。","text":"念两句诗我报路长嗟日暮，学诗谩有惊人句。九万里风鹏正举。风休住，蓬舟吹取三山去。 Arp欺骗 ---- Python实现 ## 简介 1、ARP是地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。 2、当计算机知道IP地址和MAC地址，就会向局域网中发送信息，默认发给默认网关，如果是发到局域网外的信息，则用源主机IP+目的 这两点是构造ARP毒化攻击的基本原理。 ---- ARP毒化攻击可以干什么？ ARP毒化可以让局域网内的消息都发往你指定的网关，简而言之就是让本地局域网全部断网，让连接同一个WiFi的设备都上不了网。 如何做到的？ 计算机、手机、Ipad上网的数据传输发包格式为： 源IP--自己的IP 源MAC--自己的物理地址 目的IP--如180.101.49.12 == www.baidu.com 目的MAC--本地局域网的默认网关MAC 1、目标主机通过ARP广播(由此可见ARP是用UDP协议实现)得到默认网关MAC地址 2、攻击者通过不断地发送(默认网关IP+非默认网关MAC)的形式，更改目标主机中的ARP缓存表 3、目标主机向默认路由发送消息 4、消息在局域网内传播，但不会通过MAC地址流入默认路由器，故默认路由器也不会转发目标主机的消息，目标主机断网。 即通过ARP毒化，让目标主机不能通过ARP协议，完成正确的地址映射。 攻击者如何向目标主机发送(默认网关IP+非默认网关MAC)？ 通过Python3的Scapy库来实现。1、Scapy工具介绍scapy官方文档 https://scapy.readthedocs.io/en/latest/](https://scapy.readthedocs.io/en/latest/) 安装 pip install scapyScapy可用于构造、发送、解析各类数据包。可以用来扫描，跟踪路由，探测，单元测试，攻击或网络发现。 默认包：以太网头部/IP头部/TCP头部 pkg=Ehter()/IP()/TCP() pkg.show()默认以太网头部 ###[ Ethernet ]### dst= ff:ff:ff:ff:ff:ff src= 00:00:00:00:00:00 type= IPv4默认IP头部 ###[ IP ]### version= 4 ihl= None tos= 0x0 len= None id= 1 flags= frag= 0 ttl= 64 proto= tcp chksum= None src= 127.0.0.1 dst= 127.0.0.1 \\options\\默认TCP头部 ###[ TCP ]### sport= ftp_data //默认20 dport= http //默认80 seq= 0 ack= 0 dataofs= None reserved= 0 flags= S window= 8192 chksum= None urgptr= 0 options= []2、ARP协议简介ARP协议实现IP（32bit）地址到MAC（48bit）地址之间的动态映射（由操作系统完成，用户不必关注），多路访问都会用到IP地址 实现的具体过程 源主机发送ARP广播报文段，在报文段中填入自己的IP地址，目标的IP地址，以及自己的MAC地址 同一个局域网内的主机都接受该报文段，并与自己的IP地址相比较 如果相同，则发送ARP响应报文，在响应报文中填入自己的MAC地址等 如果不同，则丢弃 源主机接收到目标主机发出的ARP响应报文，放入ARP缓存表scapy包结构 ###[ ARP ]### hwtype= 0x1 //硬件类型 1：Ethernet ptype= IPv4 hwlen= None plen= None op= who-has hwsrc= 00:0c:29:ab:65:55 //hardware source 硬件源地址 psrc= 192.168.3.37 //源IP地址 hwdst= None //hardware destination 硬件目的地址 pdst= None //目的IP地址 3、Scapy实现ARP扫描&apos;&apos;&apos; sr() 发一个，也可以接受好几个包 sr1() 发一个包，可能会收到很多包，但我只接受第一个 srp() 发多个，收多个，p代表工作在二层（以太网层） send() 只管发 sendp() 需要手动填以太网的信息 &apos;&apos;&apos;最基本的ARP请求响应 localmac='00:0c:29:ab:65:55'localip='192.168.3.37'destip='192.168.3.31'destmac=destmacpkg=srp(Ether(src=localmac,dst='FF:FF:FF:FF:FF:FF')/ARP(op=1,hwsrc=localmac,hwdst='00:00:00:00:00:00'),iface='ens32',verbose=False,timeout=1)# op=1:ARP Request# iface：网卡# timeout:设置等待时间# verbose：不打印输出 ARP响应的解析—Scapy——ARP数据结构分析 &gt;&gt;&gt;pkg# (&lt;Results: TCP:0 UDP:0 ICMP:0 Other:1&gt;, &lt;Unanswered: TCP:0 UDP:0 ICMP:0 Other:0&gt;) //元祖&gt;&gt;&gt;pkg[0] //选择响应的ARP包# &lt;Results: TCP:0 UDP:0 ICMP:0 Other:1&gt;&gt;&gt;&gt;pkg[0].res //生成收发包的清单#用列表容纳收发队列组成的元祖，对应一组计算机[第一个收发( # 发送的包&lt;Ether dst=FF:FF:FF:FF:FF:FF src=00:0c:29:ab:65:55 type=ARP |&lt;ARP op=who-has hwsrc=00:0c:29:ab:65:55 psrc=192.168.3.37 pdst=192.168.3.31 |&gt;&gt;, # 接受的包&lt;Ether dst=00:0c:29:ab:65:55 src=58:00:e3:d7:d5:ef type=ARP |&lt;ARP hwtype=0x1 ptype=IPv4 hwlen=6 plen=4 op=is-at hwsrc=58:00:e3:d7:d5:ef psrc=192.168.3.31 hwdst=00:0c:29:ab:65:55 pdst=192.168.3.37 |&lt;Padding load='\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' |&gt;&gt;&gt;)]# 元祖--包含了收发的所有包&gt;&gt;&gt;pkg[0].res[0] //选择第一个收发的包#就对应一个计算机(&lt;Ether dst=FF:FF:FF:FF:FF:FF src=00:0c:29:ab:65:55 type=ARP |&lt;ARP op=who-has hwsrc=00:0c:29:ab:65:55 psrc=192.168.3.37 pdst=192.168.3.31 |&gt;&gt;,&lt;Ether dst=00:0c:29:ab:65:55 src=58:00:e3:d7:d5:ef type=ARP |&lt;ARP hwtype=0x1 ptype=IPv4 hwlen=6 plen=4 op=is-at hwsrc=58:00:e3:d7:d5:ef psrc=192.168.3.31 hwdst=00:0c:29:ab:65:55 pdst=192.168.3.37 |&lt;Padding load='\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00' |&gt;&gt;&gt;)&gt;&gt;&gt;pkg[0].res[0][1] //选择响应的那一部分&gt;&gt;&gt;pkg[0].res[0][1][0].fields//选择响应的那一部分的以太网头部#&#123;'dst': '00:0c:29:ab:65:55', 'src': '58:00:e3:d7:d5:ef', 'type': 2054&#125;&gt;&gt;&gt;pkg[0].res[0][1][1].fields //选择响应的那一部分的ARP头部'''&#123; 'hwtype': 1, 'ptype': 2048, 'hwlen': 6, 'plen': 4, 'op': 2, 'hwsrc': '58:00:e3:d7:d5:ef', 'psrc': '192.168.3.31', 'hwdst': '00:0c:29:ab:65:55', 'pdst': '192.168.3.37'&#125;'''&gt;&gt;&gt;pkg[0].res[0][1][1].fields['hwsrc'] //提取目标mac地址，也就是当前目标发包的源mac地址&gt;&gt;&gt;pkg[0].res[0][1][1].fields['psrc'] 源码： https://github.com/ArchKS/Python/tree/master/ArpSpoof 4、Scapy监听ARP异常 建立正确的IP地址和MAC地址的映射数据库 import logginglogging.getLogger('scapy.runtime').setLevel(logging.ERROR)#清除报错from scapy.all import *from ARP_Table import ARP_Table # 导入合法的IP-MAC映射关系def arp_monitor_callback(pkt): if ARP in pkt and pkt[ARP].op in (1,2):#找到ARP数据包中操作码为1（who-has）或者2（is-at）的数据包） if ARP_Table.get(pkg[ARP].psrc): if ARP_Table[pkt[ARP].psrc] == pkt[ARP].hwsrc: print('IP地址：&#123;0&#125; MAC地址：&#123;1&#125; 匹配'.format(pkt[ARP].psrc,pkt[ARP].hwsrc)) else: print('IP地址：&#123;0&#125; MAC地址：&#123;1&#125; 不匹配'.format(pkt[ARP].psrc,pkt[ARP].hwsrc)) else: print('IP地址：&#123;0&#125; MAC地址：&#123;1&#125; 未找到条码'.format(pkt[ARP].psrc,pkt[ARP].hwsrc)) #捕获数据包，通过arp_monitor_callback方法进行处理，filter过滤arp数据包，store=0，不保存数据，iface指定接口 sniff(prn=arp_monitor_callback,filter='arp',store=0,iface='ens32') 5、Scapy实现ARP的毒化攻击原理： 所以，只需要修改A中的ARP缓存表，将与B对应的MAC修改。于是，发给A的ARP响应报文格式应为： 目的IP：A目的MAC：A源IP：B源MAC：C 就能实现上图功能。紧接着，如果B要发消息给A，那么A中的ARP表可能会调整回正确的，于是可以向B发送ARP报文，格式为： 目的IP：B目的MAC：B源IP：A源MAC：C 这样，B发往A的数据包也会走向C了，A，B双方的通信都将被C截获。通常，B往往是路由器，所以B的IP地址一般是默认网关。 ''' 源IP为默认网关的IP 源MAC为默认网关的MAC 目的IP为需要毒化主机的IP 目的MAC为需要毒化主机的MAC'''pkgtoHost=Ether(src=localmac,dst=tgmac)/ARP(op=2,hwsrc=localmac,psrc=gatewayip,hwdst=tgmac,pdst=tgip)gatewayMac=getmacbyip(gatewayip)''' 源IP为被攻击主机的IP 源MAC为本机MAC 目的IP为默认网关的IP 目的MAC为默认网关的MAC'''pkgtoGateway=Ether(src=localmac,dst=gatewayMac)/ARP(hwdst=gatewayMac,pdst=gatewayip,psrc=tgip,hwsrc=localmac,op=2) 源码： https://github.com/ArchKS/Python/tree/master/ArpSpoof","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"ARP协议","slug":"ARP协议","permalink":"http://ymlog.cn/tags/ARP%E5%8D%8F%E8%AE%AE/"}]},{"title":"玩转Linux","slug":"Play Good Linux","date":"2019-07-18T04:53:27.000Z","updated":"2020-07-04T17:18:40.312Z","comments":true,"path":"2019/07/18/Play Good Linux/","link":"","permalink":"http://ymlog.cn/2019/07/18/Play%20Good%20Linux/","excerpt":"念两句诗天边金掌露成霜，云随雁字长。绿杯红袖趁重阳，人情似故乡。兰佩紫，菊簪黄，殷勤理旧狂。欲将沉醉换悲凉，清歌莫断肠。","text":"念两句诗天边金掌露成霜，云随雁字长。绿杯红袖趁重阳，人情似故乡。兰佩紫，菊簪黄，殷勤理旧狂。欲将沉醉换悲凉，清歌莫断肠。 数据库客户端yum -y install python3-pippip3 install myclimycli -uroot -pxxxxx# tab键补齐mariadb root@localhost:(none)&gt; show databases; databases create database procedure status 字符浏览器yum -y install lynx w3m links Linux历史命令一般使用history列出所有历史命令，也可以用Ctrl+r直接搜索 # 输入docker就可以搜索到之前打过有关docker的命令(reverse-i-search)`docker': systemctl enable docker 网络测速git clone https://github.com/sivel/speedtest-cli.gitcd speed* &amp;&amp; python speedtest.py#后接`--share`,可以生成分享链接#测试服务器性能wget -qO- git.io/superbench.sh | bash 中文man手册#!/bin/bashwget https://src.fedoraproject.org/repo/pkgs/man-pages-zh-CN/manpages-zh-1.5.1.tar.gz/13275fd039de8788b15151c896150bc4/manpages-zh-1.5.1.tar.gztar xf manpages-zh-1.5.1.tar.gzcd manpages-zh*./configure --disable-zhtw --prefix=/usr/local/zhmanmake &amp;&amp; make installcd ~echo \"alias cman='man -M /usr/local/zhman/share/man/zh_CN' \" &gt;&gt;.bash_profilesource .bash_profileecho \"USE CMAN TO GET HELP\" xshell快捷键+--------------------------------------+ | alt+r 透明模式 | alt+s 简单版模式 | ctrl+alt+f 文件传输 | ctrl+shift+alt+[/]：增大或减小字体 +--------需要自定义---------------------+ | ctrl + q：水平排列 | ctrl + w：垂直排列 | ctrl + e：合并所有 +--------------------------------------+命令行改密码echo &quot;password&quot; | passwd --stdin usernamescript 记录面板script -a log.txt do... exit 将程序执行结果和命令放入文件,需要exit退出宝塔面板CentOS7一键安装： yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh 一键卸载： wget http://download.bt.cn/install/bt-uninstall.sh &amp;&amp; sh bt-uninstall.sh虚拟机配置两张网卡首先在虚拟机设置中，选择添加，再添加一个网络适配器，之后进入虚拟机 执行ip a 如果发现没有网卡，则在/etc/sysconfig/network-scripts/ 目录下，复制你已有的网卡，如果是DHCP模式，则不需要修改IP cp ifcfg-ens32 ifcfg-ens35 删除ifcfg-ens35中的UUID #UUID只能是唯一编号 systemctl restart networkEpel源yum -y install mlocate vim zip unzip tree bash-completion htop lrzszyum -y install wgetwget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repoyum clean allyum makecache 关闭防火墙systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i 's\\SELINUX=enforcing\\SELINUX=disabled\\' /etc/selinux/config 脚本#加速，可不下wget https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh &amp;&amp; bash tcp.sh#安装wget https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; bash ssr.sh#加速+安装 kcp协议wget --no-check-certificate -O kcptun_for_ss_ssr.sh https://git.io/fN2EO centos8 alternatives --set python /usr/bin/python3wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.shsysctl -w net.ipv4.tcp_congestion_control=bbrsystemctl stop firewalld Kali连接ssh一、修改配置文件 vi /etc/ssh/sshd_config 将#PasswordAuthentication no的注释去掉，并且将NO修改为YES //kali中默认是yes 二、启动SSH服务命令为： /etc/init.d/ssh start 查看SSH服务状态是否正常运行，命令为： /etc/init.d/ssh status三、设置系统自动启动SSH服务 update-rc.d ssh enable //系统自动启动SSH服务 update-rc.d ssh disabled // 关闭系统自动启动SSH服务终端光标漂移键CTRL + U -剪切光标前的内容 CTRL + K -剪切光标至行末的内容 CTRL + Y -粘贴 CTRL + E -移动光标到行末 CTRL + A -移动光标到行首","categories":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/tags/Linux/"}]},{"title":"Matplotlib图标绘制摘要","slug":"Matplotlib_Draw","date":"2019-05-03T00:18:25.000Z","updated":"2020-07-04T17:18:58.308Z","comments":true,"path":"2019/05/03/Matplotlib_Draw/","link":"","permalink":"http://ymlog.cn/2019/05/03/Matplotlib_Draw/","excerpt":"念两句诗贵逼人来不自由，龙骧凤翥势难收。满堂花醉三千客，一剑霜寒十四州。鼓角揭天嘉气冷，风涛动地海山秋。东南永作金天柱，谁羡当时万户侯。","text":"念两句诗贵逼人来不自由，龙骧凤翥势难收。满堂花醉三千客，一剑霜寒十四州。鼓角揭天嘉气冷，风涛动地海山秋。东南永作金天柱，谁羡当时万户侯。 目录 散点图：用于描述两个变量的相关性—–scatter折线图：多用于描述变量随时间的变化—–plot条形图:比较多个项目分类的数据大小直方图：表示数据的分布情况（连续）饼状图：显示各项大小与总和的比例箱型图：上边缘，上四分位数，中位数，下四分位数，下边缘，异常值 散点图：用于描述两个变量的相关性—–scatterscatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None,vmin=None, vmax=None,alpha=None, linewidths=None, verts=None,edgecolors=None, , data=None, *kwargs) import numpy as np import matplotlib.pyplot as plt #随机正相关 m=np.random.randn(1000) n=m+np.random.randn(1000)*0.5 plt.scatter(m,n) plt.show() import numpy as np import matplotlib.pyplot as plt #随机不相关 x=np.random.randn(1000) y=np.random.randn(1000) plt.scatter(x,y) plt.show() 界面定制： #s:点的面积 #c：颜色 #marker：标志形状 #alpha：透明度 plt.scatter(x,y,s=100,c=&apos;r&apos;,marker=&apos;X&apos;,alpha=0.5) #marker的种类：https://matplotlib.org/api/markers_api.html?highlight=marker#module-matplotlib.markers折线图：多用于描述变量随时间的变化—–plot def plot_date(x, y, fmt=’o’, tz=None, xdate=True, ydate=False, ,data=None, *kwargs) #def plot(*args, scalex=True, scaley=True, data=None, **kwargs) import numpy as np import matplotlib.pyplot as plt #折线图 #生成从-10~10平均等分的100个数 x=np.linspace(-10,10,100) y=x**2 plt.plot(x,y) plt.show() 文件中有日期的折线图： 1、converters={0:mdate.strpdate2num(‘%Y’)} 2、plt.plot_date() import numpy as np import matplotlib.pyplot as plt import matplotlib.dates as mdate #北京房价折线图 date,beijing,tianjing,shijiazhuang=np.loadtxt(&apos;demo.csv&apos;,delimiter=&apos;,&apos;,converters={0:mdate.strpdate2num(&apos;%Y&apos;)},skiprows=1,usecols=(0,1,2,3),unpack=True,encoding=&apos;GBK&apos;) #skiprows:从第几行开始导入 #usecols:导入第几列 #unpack:False-从左往右形成一行，True-从上往下形成一行 #delimiter:csv中每个数据的分隔符 plt.plot_date(date,beijing,linestyle=&apos;-&apos;,marker=&apos;o&apos;,color=&apos;red&apos;) plt.plot_date(date,tianjing,linestyle=&apos;-&apos;,marker=&apos;o&apos;,color=&apos;blue&apos;) plt.plot_date(date,shijiazhuang,linestyle=&apos;-&apos;,marker=&apos;o&apos;,color=&apos;black&apos;) #linestyle:直线、虚线 plt.show() import numpy as np import matplotlib.pyplot as plt #画出正弦函数的图像 x=np.linspace(-10,10,100) y=np.sin(x) plt.plot(x,y) plt.show() 条形图:比较多个项目分类的数据大小import numpy as np import matplotlib.pyplot as plt #def bar(x, height, width=0.8, bottom=None, *, align=&apos;center&apos;,data=None, **kwargs): N=5 #并列 y=[22,55,33,42,60] index=np.arange(N) x=plt.bar(x=index,height=y,width=0.4,color=&apos;red&apos;) plt.show() import numpy as np import matplotlib.pyplot as plt N=5 #并列 y=[22,55,33,42,60] index=np.arange(N) x=plt.barh(y=index,width=y,color=&apos;red&apos;) plt.show() import numpy as np import matplotlib.pyplot as plt N=5 #并列 y1=[22,55,33,42,60] y2=[21,20,45,10,54] bar_width=0.3 index=np.arange(N) plt.bar(x=index,height=y1,color=&apos;red&apos;,width=0.3) plt.bar(x=index+bar_width,height=y2,color=&apos;blue&apos;,width=0.3) plt.show() import numpy as np import matplotlib.pyplot as plt N=5 #层叠-就是将下层图像置为上层的buttom y1=[22,55,33,42,60] y2=[21,20,45,10,54] index=np.arange(N) plt.bar(index,y1,0.2,color=&apos;red&apos;) plt.bar(index,y1,0.2,y1,color=&apos;blue&apos;) #不能写x=index，height=y1等 plt.show() 直方图：表示数据的分布情况（连续）#直方图 import numpy as np import matplotlib.pyplot as plt mu=100 #mean of the distrubution sigma=20 #standard deviation of distribution x=np.random.randn(2000) plt.hist(x,bins=10,color=&apos;red&apos;,density=False,edgecolor=&apos;k&apos;) #bins：多少块 #density :是否标准化，标准化之后为频组 #edgecolor：颜色分割线 plt.show() #双变量直方图 import numpy as np import matplotlib.pyplot as plt x=np.random.randn(2000)+2 y=np.random.randn(2000)+3 plt.hist2d(x,y,bins=50) plt.show() 饼状图：显示各项大小与总和的比例#饼状图 import numpy as np import matplotlib.pyplot as plt labels=&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos; fraces=[15,30,25,10] explode=[0,0,0,0.05] plt.pie(x=fraces,labels=labels,autopct=&apos;%0.f%%&apos;,explode=explode,shadow=True) #autopct:显示百分比 #explode:突出显示 #shadow:加阴影 plt.show() 箱型图：上边缘，上四分位数，中位数，下四分位数，下边缘，异常值#箱型图 import numpy as np import matplotlib.pyplot as plt np.random.seed(1) data=np.random.normal(size=1000,loc=0,scale=1) plt.boxplot(data,sym=&apos;x&apos;,whis=1.5) #sym:符号 #whis:异常值的区域 plt.show() #多箱型图 import numpy as np import matplotlib.pyplot as plt np.random.seed(1) data=np.random.normal(size=(1000,4),loc=0,scale=1) labels=[&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos;] plt.boxplot(data,sym=&apos;x&apos;,whis=1.5) plt.show()","categories":[{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://ymlog.cn/tags/Matplotlib/"}]}],"categories":[{"name":"报错","slug":"报错","permalink":"http://ymlog.cn/categories/%E6%8A%A5%E9%94%99/"},{"name":"容器","slug":"容器","permalink":"http://ymlog.cn/categories/%E5%AE%B9%E5%99%A8/"},{"name":"运维","slug":"运维","permalink":"http://ymlog.cn/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/categories/Linux/"},{"name":"编程","slug":"编程","permalink":"http://ymlog.cn/categories/%E7%BC%96%E7%A8%8B/"},{"name":"数据库","slug":"数据库","permalink":"http://ymlog.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"路由技术","slug":"路由技术","permalink":"http://ymlog.cn/categories/%E8%B7%AF%E7%94%B1%E6%8A%80%E6%9C%AF/"},{"name":"中间件","slug":"中间件","permalink":"http://ymlog.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://ymlog.cn/tags/Docker/"},{"name":"VsCode","slug":"VsCode","permalink":"http://ymlog.cn/tags/VsCode/"},{"name":"快捷键","slug":"快捷键","permalink":"http://ymlog.cn/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"NFS","slug":"NFS","permalink":"http://ymlog.cn/tags/NFS/"},{"name":"KVM","slug":"KVM","permalink":"http://ymlog.cn/tags/KVM/"},{"name":"WebSocket","slug":"WebSocket","permalink":"http://ymlog.cn/tags/WebSocket/"},{"name":"NodeJS","slug":"NodeJS","permalink":"http://ymlog.cn/tags/NodeJS/"},{"name":"Vue","slug":"Vue","permalink":"http://ymlog.cn/tags/Vue/"},{"name":"Redis","slug":"Redis","permalink":"http://ymlog.cn/tags/Redis/"},{"name":"Django","slug":"Django","permalink":"http://ymlog.cn/tags/Django/"},{"name":"MySQL","slug":"MySQL","permalink":"http://ymlog.cn/tags/MySQL/"},{"name":"Switch","slug":"Switch","permalink":"http://ymlog.cn/tags/Switch/"},{"name":"Ansible","slug":"Ansible","permalink":"http://ymlog.cn/tags/Ansible/"},{"name":"OSPF协议","slug":"OSPF协议","permalink":"http://ymlog.cn/tags/OSPF%E5%8D%8F%E8%AE%AE/"},{"name":"LVS","slug":"LVS","permalink":"http://ymlog.cn/tags/LVS/"},{"name":"Keepalived","slug":"Keepalived","permalink":"http://ymlog.cn/tags/Keepalived/"},{"name":"小型路由协议","slug":"小型路由协议","permalink":"http://ymlog.cn/tags/%E5%B0%8F%E5%9E%8B%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"},{"name":"爬虫","slug":"爬虫","permalink":"http://ymlog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"history","slug":"history","permalink":"http://ymlog.cn/tags/history/"},{"name":"随笔","slug":"随笔","permalink":"http://ymlog.cn/tags/%E9%9A%8F%E7%AC%94/"},{"name":"ARP协议","slug":"ARP协议","permalink":"http://ymlog.cn/tags/ARP%E5%8D%8F%E8%AE%AE/"},{"name":"Linux","slug":"Linux","permalink":"http://ymlog.cn/tags/Linux/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://ymlog.cn/tags/Matplotlib/"}]}